---
title: "Тестирование статистических гипотез"
author: "Марина Варфоломеева, Юта Тамберг, Вадим Хайтов"
subtitle: ""
output:
  ioslides_presentation:
    css: assets/my_styles.css
    widescreen: yes
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```
```{r libs-funs, include = FALSE, cache = FALSE, purl = FALSE}
library(ggplot2)
library(gridExtra)
dt_limit <- function(x, alph = 0.05, df = 18, sides = 2, ncp = 0, what = "alpha") {
  #' Function to generate data for plotting with ggplot
  #' (non)central t distribution
  #' with shaded areas for alpha, beta and power
  #' Authors: Marina Varfolomeeva, Vadim Khaitov
  #' Usage inside stat_function:
  #' stat_function(fun = dt_limit,
  #'               args = list(alph = alpha, df = df, sides = sides),
  #'               geom = "area", fill = "red", alpha = 0.7)
  if(sides == 1) alph <- alph
  if(sides == 2) alph <- alph/2
  t_cr <- abs(qt(p = alph, df = df))

  if(what == "alpha"){
    y <- dt(x, df, ncp = ncp)
    y[!(x < -t_cr | x > t_cr)] <- NA
  }
  if(what == "beta"){
    y <- dt(x, df, ncp = ncp)
    y[!(x >= -t_cr & x <= t_cr)] <- NA
  }
  if(what == "power"){
    y <- dt(x, df, ncp = ncp)
    y[!(x < -t_cr | x > t_cr)] <- NA
  }
  return(y)
}

dnorm_limit <- function(x, alph = 0.05, mu = 0, sig = 1, sides = 2, what = "alpha") {
  #' Function to generate data for plotting with ggplot
  #' (non)central normal distribution
  #' with shaded areas for alpha, beta and power
  #' Authors: Marina Varfolomeeva, Vadim Khaitov
  #' Usage inside stat_function:
  #' stat_function(fun = dnorm_limit,
  #'               args = list(alph = alpha, mu = mu, sig = sig, sides = sides),
  #'               geom = "area", fill = "red", alpha = 0.7)
  if(sides == 1) alph <- alph
  if(sides == 2) alph <- alph/2
  z_cr <- abs(qnorm(p = alph, mean = mu, sd = sig))

  if(what == "alpha"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x <= -z_cr | x >= z_cr)] <- NA
  }
  if(what == "beta"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x >= -z_cr & x <= z_cr)] <- NA
  }
  if(what == "power"){
    y <- dnorm(x, mean = mu, sd = sig)
    y[!(x < -z_cr | x > z_cr)] <- NA
  }
  return(y)
}
```

## Тестирование гипотез

- Стандартное нормальное распределение
- Как устроено тестирование гипотез
- t-статистика
- Применение t-теста
- Статистическая значимость

# Стандартное нормальное распределение

## Стандартизация (Z-преобразование)

Стандартизованная величина (Z-оценка) --- показывает, на сколько стандартных отклонений значение отличается от среднего

<div class="columns-2">

```{r echo=FALSE, purl=FALSE, fig.height=5, fig.width=4.5}
Xi <- rnorm(n = 100000, mean = 50, sd = 7)
Mu <- mean(Xi)
SD <- sd(Xi)
Zi <- (Xi - Mu) / SD
Z <- data.frame(Xi, Zi)

gg_sample <- ggplot(data = Z, aes(x = Xi)) + geom_histogram(binwidth = 2, fill = "lightblue", color = "black") + labs(title = "Normal Distribution, \nmu = 50, sd = 7") + geom_vline(xintercept = mean(Xi), colour = "red", size = 1)

gg_z <- ggplot(data = Z, aes(x = Zi)) + geom_histogram(binwidth = 0.3, fill = "steelblue", color = "black", alpha = 0.5) + labs(title = "Standard Normal Distribution, \nmu = 0, sd = 1") + geom_vline(xintercept = mean(Zi), colour = "red", size = 1)

grid.arrange(gg_sample, gg_z, ncol = 1)
```

$$z_i=\frac{x_i - \bar{x}}{SD}$$

После **стандартизации** получается стандартное нормальное распределение

<br/>

**После стандартизации всегда**:

- среднее $\mu = 0$
- стандартное отклонение $\sigma = 1$

<br/>

Для стандартного нормального распределения легко можно посчитать вероятность (площадь под кривой)

</div>

## Вероятности --- это площади под кривой распределения случайной величины.

Вся площадь под кривой распределения будет равна 1 (суммарная вероятность всех возможных значений равна 1)

Мы не можем узнать вероятность конкретного значения, т.к. конкретное значение --- это точка, а под точкой нет площади.

Зато, мы можем узнать вероятность того, что случайная величина, взятая из данного распределения, попадет в конкретный диапазон значений...

```{r probability-curve, purl=FALSE, echo=FALSE, fig.width=10}
mu <- 5; sig <- 1.5; X1 <- 3; X2 <- 6
dfr <- data.frame(x = seq(0, 10, length.out = 1000))

gg_all <- ggplot(dfr, aes(x = x)) +
  scale_x_continuous(name = "Значение случайной величины", breaks = 1:9,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "area", fill = "steelblue", alpha = 0.5) +
    stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  annotate(geom = "text", label = "P[group('(',list(-infinity, infinity),')')] == 1", x = 5, y = 0.15, parse = TRUE)
  
gg_3 <- ggplot(dfr, aes(x = x)) +
  scale_x_continuous(name = "Значение случайной величины", breaks = 1:9,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
    stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  annotate("segment", x = 3, y = 0, xend = 3, yend = dnorm(3, mean = 5, sd = sig)) +
  annotate("point", x = 3, y = dnorm(3, mean = 5, sd = sig), colour = "steelblue", fill = "lightblue", shape = 21, size = 3) +
    annotate(geom = "text", x = 3, y = dnorm(3, mean = 5, sd = sig), label = "P[group('[',3,']')] == 0", parse = TRUE, hjust = 1.1)

grid.arrange(gg_all, gg_3, nrow = 1)

```

## Интергрирование вероятностей

Внимание! Мы умеем интегрировать только "влево" от заданного значения, т.е. мы можем непосредственно вычислить только вероятность того, что случайное значение окажется __меньше__ заданного. 

```{r snail-curve, purl=FALSE, echo=FALSE}
mu <- 5; sig <- 1.5; X1 <- 3; X2 <- 6
dfr <- data.frame(x = seq(0, 10, length.out = 1000))
dfr$y1 <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y1[!(dfr$x < X1)] <- NA
dfr$y2 <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y2[!(dfr$x < X2)] <- NA

ggplot(dfr, aes(x = x)) +
  scale_x_continuous(name = "Значение случайной величины", breaks = 1:9,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
    geom_area(aes(x = x, y = y2), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X2, colour = "steelblue", linetype = "dashed") +
    geom_area(aes(x = x, y = y1), fill = "steelblue", alpha = 0.6) +
  geom_vline(xintercept = X1, colour = "steelblue4", linetype = "dashed") +
    stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue")
  
```

Поскольку вся площадь под кривой вероятностей равна 1, то вероятность оказаться __больше__ заданного значения --- это 1 минус вероятность оказаться __меньше__.



## Пример: Размеры улиток

В выборке улиток средний диаметр раковины 5 см со стандартным отклонением 1.5 см.

- Какова вероятность того, что случайно выбранная улитка окажется __меньше 3 см__?
- Какова вероятность того, что случайно выбранная улитка окажется __больше 6 см__?
- Какова доля улиток с размером раковины __в пределах 3--6 см__?

![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)


<small>tres caracoles by Alberto Villen on Freeimages.com</small>


## Вероятность встретить значение меньше заданного размера

В выборке улиток средний диаметр раковины 5 см со стандартным отклонением 1.5 см.

### Какова вероятность того, что случайно выбранная улитка окажется __меньше 3 см__? 

```{r}
Z_1 <- (3 - 5) / 1.5
pnorm(Z_1)
```

```{r snail-small, purl=FALSE, echo=FALSE, fig.height=2}
mu <- 5; sig <- 1.5; X1 <- 3; X2 <- 6
dfr <- data.frame(x = seq(0, 10, length.out = 1000))
dfr$y <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y[!(dfr$x < X1)] <- NA

ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Диаметр", breaks = 1:9,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X1, colour = "red3", linetype = "dashed")
```

## Вероятность встретить значение больше заданного размера

В выборке улиток средний диаметр раковины 5 см со стандартным отклонением 1.5 см.

### Какова вероятность того, что случайно выбранная улитка окажется __больше 6 см__?

Мы умеем интегрировать только влево от выбранного значения, поэтому

- выясняем вероятность встретить значение меньше заданного $p$
- находим комплементарную вероятность $1 - p$

```{r}
Z_2 <- (6 - 5) / 1.5
1 - pnorm(Z_2)
```

```{r snail-large, purl=FALSE, echo=FALSE, fig.height=2}
dfr <- data.frame(x = seq(0, 10, length.out = 1000))
dfr$y <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y[!(dfr$x > X2)] <- NA
ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Диаметр", breaks = 1:8,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X2, colour = "red3", linetype = "dashed")
```

## Вероятность встретить значение в заданных пределах

В выборке улиток средний диаметр раковины 5 см со стандартным отклонением 1.5 см.

### Какова доля улиток с размером раковины __в пределах 3--6 см__?

```{r}
pnorm(Z_2) - pnorm(Z_1) 
```

```{r snail-medium, purl=FALSE, echo=FALSE, fig.height=2}
dfr <- data.frame(x = seq(0, 10, length.out = 1000))
dfr$y <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y[!(dfr$x > X1 & dfr$x < X2)] <- NA
ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Диаметр", breaks = 1:9,
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X1, colour = "red3", linetype = "dashed") +
  geom_vline(xintercept = X2, colour = "red3", linetype = "dashed")
```

## Задача:

Предположим, что средний рост мужчин в России 176 см со стандартным отклонением 7 см. В пилоты берут только с ростом от 160 до 190 см (по приказу Минтранса).

- Какова вероятность того, что случайно выбранный мужчина окажется __ниже 160 см__?

- Какова вероятность того, что случайно выбранный мужчина окажется  __больше 190 см__?

- Какова доля мужчин, не подходящих по росту в пилоты, т.е. __меньше 160 и больше 190 см__?

## Решение

Предположим, что средний рост мужчин в России 176 см со стандартным отклонением 7 см. В пилоты берут только с ростом от 160 до 190 см (по приказу Минтранса).

### Какова вероятность того, что случайно выбранный мужчина окажется __ниже 160 см__?

```{r purl=FALSE}
Z_short <- (160 - 176) / 7
pnorm(Z_short)
```

```{r men-short, purl=FALSE, echo=FALSE}
mu <- 176; sig <- 7; X1 <- 160; X2 <- 190
dfr <- data.frame(x = seq(150, 200, length.out = 1000))
dfr$y <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y[!(dfr$x < X1)] <- NA
ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Рост",
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X1, colour = "red3", linetype = "dashed")
```

## Решение

Предположим, что средний рост мужчин в России 176 см со стандартным отклонением 7 см. В пилоты берут только с ростом от 160 до 190 см (по приказу Минтранса).

### Какова вероятность того, что случайно выбранный мужчина окажется  __больше 190 см__?

```{r purl=FALSE}
Z_tall <- (190 - 176) / 7
1 - pnorm(Z_tall)
```

```{r men-tall, purl=FALSE, echo=FALSE}
dfr$y <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y[!(dfr$x > X2)] <- NA
ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Рост",
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X2, colour = "red3", linetype = "dashed")
```


## Решение

Предположим, что средний рост мужчин в России 176 см со стандартным отклонением 7 см. В пилоты берут только с ростом от 160 до 190 см (по приказу Минтранса).

### Какова доля мужчин, не подходящих по росту в пилоты, т.е. __меньше 160 и больше 190 см__?


```{r purl=FALSE}
pnorm(Z_short) + (1 - pnorm(Z_tall))
```

```{r men-not-pilots, purl=FALSE, echo=FALSE}
dfr$y1 <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y1[!(dfr$x < X1)] <- NA
dfr$y2 <- dnorm(dfr$x, mean = mu, sd = sig)
dfr$y2[!(dfr$x > X2)] <- NA

ggplot(dfr, aes(x = x)) +
  stat_function(fun = dnorm, args = list(mean = mu, sd = sig), size = 2, geom = "line", colour = "steelblue") +
  scale_x_continuous(name = "Рост",
                     sec.axis = sec_axis(~(. - mu)/sig, name = "Z-оценка", breaks = -4:4)) +
  labs(y = "Плотность вероятности") + 
  geom_area(aes(x = x, y = y1), fill = "steelblue", alpha = 0.5) +
  geom_area(aes(x = x, y = y2), fill = "steelblue", alpha = 0.5) +
  geom_vline(xintercept = X1, colour = "red3", linetype = "dashed") +
  geom_vline(xintercept = X2, colour = "red3", linetype = "dashed")
```


# Как устроено тестирование гипотез

## Сравнение выборок

Различия между выборками не всегда видны невооружённым глазом.

<br/>


![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg) ![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)


<small>tres caracoles by Alberto Villen on Freeimages.com</small>

## Гипотезы: нулевая и альтернативная

Первый шаг в сравнении – формулировка нулевой гипотезы.

Вместе с нулевой гипотезой рождается альтернативная гипотеза.

![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg) ![](images/tres-caracoles-by-Alberto-Villen-on-freeimages.com.jpg)

<small>tres caracoles by Alberto Villen on Freeimages.com</small>

>- Нулевая гипотеза $H_0$ чаще всего формулируется как **отсутствие различий** между сравниваемыми объектами. Например: Улитки из обеих популяций одинакового размера

>- Альтернативная гипотеза $H_A$ формулируется как **присутствие различий**, она обратна нулевой гипотезе, т.е. включает все остальные случаи. Например: Улитки из обеих популяций разного размера.

## Нулевая и альтернативная гипотезы --- это "два мира"

Вне зависимости от нас, реальность может находиться в одном из двух состояний:

- $H_0$ верна, улитки одинаковы
- $H_0$ неверна, улитки различаются 

|$H_0$ верна |	$H_0$ неверна |
|:-----:|:-----:|

<br />После статистического теста мы принимаем решение о том, принять или отвергнуть $H_0$. Но это решение не обязательно окажется верным. Возможно четыре исхода:

В мире где улитки одинаковы ($H_0$ верна) мы можем:  
- принять $H_0$ (верное решение),  
- отвергнуть $H_0$ (ошибка).

Аналогично, в мире где улитки различаются ($H_A$ верна), мы можем:  
- принять $H_0$ (ошибка),  
- либо отвергнуть $H_0$ (верное решение).

## Верные и неверные решения

<div class="columns-2">

**Ошибка I рода: нашли то, чего нет**

**Ошибка II рода: не нашли то, что было**

</div>

| 	|$H_0$ верна |	$H_0$ неверна |
|:-----:|:-----:|:-----:|
| Отклонить H0 | Ошибка I рода с вероятностью <span class="orange">&alpha;</span></br>Ложно-положительный результат | 	Верно |
| Сохранить H0 | Верно | Ошибка II рода с вероятностью <span class= "blue">&beta;</span> </br> Ложно-отрицательный результат |


## Тестирование гипотез: Тестовые статистики

Гипотезы выражаются математически в виде тестовых статистик. 

По нашим реальным данным мы вычисляем __эмпирическое значение тестовой статистики__.

Дальше мы должны ответить на вопрос:

### Насколько вероятно получить _такое или более экстремальное_ эмпирическое значение, если верна нулевая гипотеза  $H_0$?

Ответить на этот вопрос можно, построив __теоретическое распределение тестовой статистики__ для случая, когда верна $H_0$


## Пример тестовой статистики: Z-тест для разницы средних (для больших выборок)

$H_0: \bar x_1 - \bar x_2 = 0$, $H_A: \bar x_1 - \bar x_2 \ne 0$

$$Z = \frac{\bar x_1 - \bar x_2}{SE}$$
<small>
$\bar x_1 - \bar x_2$ --- разница средних; $SE = SD / \sqrt{n}$ --- стандартная ошибка
</small>

__Для больших выборок__ (больше 100) выборочная оценка стандартизованной разницы средних значений  распределена практически нормально. Поэтому для тестирования гипотез можно использовать стандартное нормальное распределение. 

```{r hypoth, echo = FALSE, purl = FALSE, fig.height=2.2}
th <- theme_bw() #+ theme(axis.line.y = element_blank(), axis.text = element_blank(), panel.grid = element_blank())
z_df <- data.frame(z = seq(-6, 6, length.out = 1000))
gg_norm_h0 <- ggplot(data = z_df, aes(x = z)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), 
                size = 1, geom = "line", aes(colour = "H0")) +
  # stat_function(fun = dnorm, 
                # args = list(mean = 1.5, sd = 1), 
                # geom = "line", aes(colour = "Ha"), size = 1) + 
  scale_colour_manual("Гипотеза", values = c("red3")) +
  labs(x = "Z", 
       y = "Плотность\nвероятности") + th
gg_norm_h0
```

Одни значения тестовой статистики будут встречаться часто, другие --- редко.

## Доверительная вероятность (p-value)

Площадь под любым участком этой кривой соответствует вероятности получения значений тестовой статистики в этом интервале (при условии справедливости $H_0$).

Вероятность получить _такое или более экстремальное_ эмпирическое значение (при условии справедливости $H_0$) --- это __доверительная вероятность__ (p-value)

Обычно нам все равно, в какой из хвостов теоретического распределения попадает наше значение тестовой статистики, поэтому мы обычно учитываем оба

$$P = P(z_{observed} < |z_0|~и~z_{observed} > |z_0|)$$

```{r hypoth-p, echo = FALSE, purl = FALSE, fig.width=10, fig.height=2.5}
# |z|
Z_large <- 1.5 
Z_small <- 2.3

gg_large_p <- gg_norm_h0 +
  # p
  stat_function(fun = dnorm_limit, 
                args = list(alph = 2*pnorm(-abs(Z_large))), 
                geom = "area", fill = "grey", alpha = 0.7) + 
  # limits
  geom_vline(xintercept = Z_large, size = 1, linetype = "dotted") +
  geom_vline(xintercept = -Z_large, size = 1, linetype = "dotted") +
    annotate(geom = "text", x = -Z_large, y = 0.1, hjust = 1.3,
           label = "P(z[obs] <= -z[0])", parse = TRUE) +
      annotate(geom = "text", x = Z_large, y = 0.1, hjust = -0.3,
           label = "P(z[obs] >= z[0])", parse = TRUE) +
      annotate(geom = "text", x = 0, y = 0.41, hjust = 0.5,
           label = "group('|',z[0],'|') == 1.5", parse = TRUE) +
  theme(legend.position = "none") +
  labs(title = paste("Большая доверительная вероятность\nP =", round(2*pnorm(-abs(Z_large)), 2)))

gg_small_p <- gg_norm_h0 + 
  # p
  stat_function(fun = dnorm_limit, 
                args = list(alph = 2*pnorm(-abs(Z_small))), 
                geom = "area", fill = "grey", alpha = 0.7) + 
  # limits
  geom_vline(xintercept = Z_small, size = 1, linetype = "dotted") +
  geom_vline(xintercept = -Z_small, size = 1, linetype = "dotted") +
    annotate(geom = "text", x = -Z_small, y = 0.1, hjust = 1.1,
           label = "P(z[obs] <= -z[0])", parse = TRUE) +
      annotate(geom = "text", x = Z_small, y = 0.1, hjust = -0.1,
           label = "P(z[obs] >= z[0])", parse = TRUE) +
      annotate(geom = "text", x = 0, y = 0.41, hjust = 0.5,
           label = "group('|',z[0],'|') == 2.3", parse = TRUE) +
  labs(title = paste("Небольшая доверительная вероятность\nP =", round(2*pnorm(-abs(Z_small)), 2)))

grid.arrange(gg_large_p, gg_small_p, nrow = 1, widths = c(0.47, 0.53))
```

## Уровень значимости $\alpha$

Считается, что если вероятность получить конкретное значение тестовой статистики в условиях справедливой $H_0$ достаточно мала, то такую нулевую гипотезу можно отвергнуть.

__Уровень значимости $\alpha$ --- это вероятность ошибочно отвергнуть справедливую нулевую гипотезу__. Т.е. это вероятность найти различия там, где их нет (__вероятность ошибки I рода__). Обычно выбирают уровень значимости $\alpha = 0.05$, реже $0.01$

Для z-теста  $\alpha$ --- это вероятность ошибочно сделать вывод о том, что средние выборок различаются __при условии, что эти выборки получены из одной генеральной совокупности__.

```{r alpha, echo = FALSE, purl = FALSE, fig.height=3, fig.width=10}
gg_norm_h0 +
  # alpha
  stat_function(fun = dnorm_limit, 
                args = list(alph = 0.05), 
                geom = "area", fill = "red", alpha = 0.2) +
  geom_vline(xintercept = 1.96*c(-1, 1), size = 1, linetype = "dashed", colour = "red3") +
  annotate(geom = "text", x = -1.96, y = 0.04, hjust = 1.6,
           label = "alpha/2", parse = TRUE) +
      annotate(geom = "text", x = 1.96, y = 0.04, hjust = -0.6,
           label = "alpha/2", parse = TRUE) +
  labs(title = "Тестирование гипотез при помощи z-теста") + 
  # редкие
  annotate(geom = "text", x = -4, y = 0.1, label = "Редкие значения\nP ≤ α, отвергаем H0") + 
  annotate(geom = "text", x = 4, y = 0.1, label = "Редкие значения\nP ≤ α, отвергаем H0") + 
  annotate(geom = "text", x = 0, y = 0.1, label = "Обычные значения\nP > α, сохраняем H0") + 
    annotate(geom = "text", x = 0, y = 0.42, hjust = 0.5, 
           label = "-z и z при alpha 0.05")
```

## Тестирование гипотез: Как принять решение?

### Алгоритм действий

1. Для конкретных данных получаем значение тестовой статистики
2. Сравниваем его с теоретическим распределением (распределением при условии, что $H_0$ верна) и находим вероятность найти более экстремальное значение тестовой статистики
3. Решаем, отвергнуть ли $H_0$:
    + Если $P \le \alpha$, отвергаем $H_0$
    + Если $P > \alpha$, сохраняем $H_0$

```{r hypoth-p-alpha, echo = FALSE, purl = FALSE, fig.width=10, fig.height=3}
gg_large_p_alpha <- gg_large_p +
  # alpha
  stat_function(fun = dnorm_limit, 
                args = list(alph = 0.05), 
                geom = "area", fill = "red", alpha = 0.2) +
  # geom_vline(xintercept = 1.96*c(-1, 1), size = 1, linetype = "dashed", colour = "red3") +
  annotate(geom = "text", x = -1.96, y = 0.04, hjust = 1.6,
           label = "alpha/2", parse = TRUE) +
      annotate(geom = "text", x = 1.96, y = 0.04, hjust = -0.6,
           label = "alpha/2", parse = TRUE) +
    labs(title = "P > α, сохраняем H0")

gg_small_p_alpha <- gg_small_p + 
  # alpha
  stat_function(fun = dnorm_limit, 
                args = list(alph = 0.05), 
                geom = "area", fill = "red", alpha = 0.2) +
  # geom_vline(xintercept = 1.96*c(-1, 1), size = 1, linetype = "dashed", colour = "red3") +
    annotate(geom = "text", x = -1.96, y = 0.04, hjust = 1.6,
           label = "alpha/2", parse = TRUE) +
      annotate(geom = "text", x = 1.96, y = 0.04, hjust = -0.6,
           label = "alpha/2", parse = TRUE) +
    labs(title = "P ≤ α, отвергаем H0")


grid.arrange(gg_large_p_alpha, gg_small_p_alpha, nrow = 1, widths = c(0.47, 0.53))
```

## Доверительная вероятность (p-value).

### Ещё раз, другими словами

Допустим, мы сравнили выборки и получили $р = 0.03$

$p = 0.03$ --- __это не значит__, что $H_0$ верна с вероятностью 3%!

$p = 0.03$ --- __это значит__, что если выборки одинаковы, а $H_0$ верна, шанс получить результат, который мы получили составляет 3%.

Уже мы сами решаем, кажется ли нам такая вероятность приемлемой (сравниваем с выбранным уровнем значимости $\alpha$)


<!-- ## Операции с распределениями -->

<!-- Давайте познакомимся с тремя полезными функциями для работы с распределениями: `r, q, p` -->

<!-- ### r = random number generation. -->

<!-- С помощью этой функции можно смоделировать взятие выборки из генеральной совокупности с заданными параметрами. -->

<!-- Например: `rnorm(1000, mean = 20, sd = 2)` сгенерирует выборку в 1000 случайных значений из нормального распределения. -->


<!-- ### q = quantile function. -->

<!-- С ее помощью можно получить квантиль (точнее персентиль) - то значение переменной, которое отсекает заданную часть распределения. -->

<!-- Например: `qnorm(0.5, mean = 20, sd = 2)` вернет среднюю, т.к. ровно 50% значений в нормальном распределении $< \mu$ -->

<!-- `qnorm(0.025, mean = 20, sd = 2)` вернет то значение X, которое делит распределение на куски в 2.5% и 97.5%, т.е. 2.5% всех значений будут меньше, а 97.5% - больше него. -->

<!-- ### p = probability distribution function -->

<!-- С ее помощью можно рассчитать вероятность того, что случайная величина, взятая из данного распределения, окажется меньше заданного нами значения. -->

<!-- Эта операция принципиально обратна тому, что делает `q`. -->

<!-- Например: `pnorm(20, mean = 20, sd = 2)` вернет вероятность 0.5, или 50%, поскольку мы передали ей в качестве аргумента среднюю -->

<!-- Эта функция работает кумулятивно: -->

<!-- ```{r} -->
<!-- round(pnorm(c(0, 15, 20, 25, 40), 20, 2), 3) -->
<!-- ``` -->

# t-статистика


## Z-тест непригоден для проверки равенства средних в малых выборках

$H_0: \bar x_1 - \bar x_2 = 0$, $H_A: \bar x_1 - \bar x_2 \ne 0$

Для малых выборок нельзя использовать Z-тест для проверки $H_0: \bar x_1 - \bar x_2 = 0$, поскольку в этом случае стандартизованная разница средних уже не подчиняется нормальному распределению


## t-статиктика Стьюдента (t-критерий)

Гипотезы: $H_0: \bar{x}_1 = \bar{x}_2$, $H_A: \bar{x}_1 \ne \bar{x}_2$

Двухвыборочный тест Стьюдента (Student, 1908) используется для проверки значимости различий между средними значениями двух нормально распределенных величин.

$$t=\frac{\bar{x}_1 - \bar{x}_2}{SE}$$

Условия применимости:

- Выборки случайны и независимы друг от друга
- Величины нормально распределены
- __Дисперсии в группах одинаковы__

- $\bar x_1 - \bar x_2$ --- это разность между двумя средними значениями  
- $SE = \sqrt{\frac{s_1^2(n_1-1) +s_2^2(n_2-1)}{n_1+n_2-2}\Big(\frac{1}{n_1} + \frac{1}{n_2}\Big)}$ --- Обобщенное стандартная ошибка разности двух средних
- $df = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2$ --- число степеней свободы

## t-тест Уэлча --- это модификация теста Стьюдента __для случая разных дисперсий__

$$t=\frac{\bar{x}_1 - \bar{x}_2}{SE}$$

Условия применимости:

- Выборки случайны и независимы друг от друга
- Величины нормально распределены


$$SE = \sqrt{\frac {s_1^2} {n_1} + \frac {s_2^2} {n_2}}$$

Приблизительное число степеней свободы рассчитывается по уравнению Уэлча-Саттеруэйта 

$$df_{ Welch–Satterthwaite} \approx \frac {\Big(\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}\Big)^2} {\frac {s_1^4} {n^2_1 \cdot df_1} + \frac {s_2^4} {n^2_2 \cdot df_1}}$$


## t-распределение --- распределение разницы средних для выборок из одной совокупности

t-статистика подчиняется t-распределению.

Иными словами, если много раз взять выборки __из одной__ совокупности (т.е. при условии, что $H_0$ верна) и посчитать между ними разницу, то она будет подчиняться t-распределению. 

Форма t-распределения зависит только от одного параметра --- числа степеней свободы $df = n_1 + n_2 - 2$

При больших объемах выборок форма t-распределения приближается к нормальному


```{r gg-t, echo=FALSE, purl=FALSE}
t_df <- data.frame(t = seq(-6, 6, length.out = 1000))

gg_t <- ggplot(data = t_df, aes(x = t)) +
    labs(x = "Стандартизованная разница средних", 
       y = "Плотность\nвероятности", 
       title = "t-распределение")

gg_t + 
  stat_function(fun = dt, args = list(df = 2), size = 1, geom = "line", aes(colour = "2")) + 
  stat_function(fun = dt, args = list(df = 4), size = 1, geom = "line", aes(colour = "4")) +   stat_function(fun = dt, args = list(df = 10), size = 1, geom = "line", aes(colour = "10")) + 
  stat_function(fun = dt, args = list(df = 100), size = 1, geom = "line", aes(colour = "100")) + 
  scale_colour_manual("df", values = c("2" = "#bd0026", "4" = "#f03b20", "10" = "#fd8d3c", "100" = "#fed976"), breaks = c("2", "4", "10", "100"))
```

## Уровень значимости $\alpha$

Для t-теста  $\alpha$ --- это вероятность ошибочно сделать вывод о том, что средние выборок различаются __при условии, что эти выборки получены из одной генеральной совокупности__.

```{r gg-tcrit, echo=FALSE, purl=FALSE}
alpha <- 0.05
df <- 18
sides <- 2
p_cut <- abs(qt(p = alpha/sides, df = df))
gg_t + 
  # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom = "area", fill = "red", alpha = 0.7) + 
  stat_function(fun = dt, args=list(df=df), 
                geom = "line", colour = "darkred") +
  labs(title = "Тестирование гипотез при помощи t-теста") + 
  # редкие
  annotate(geom = "text", x = -4, y = 0.1, label = "Редкие значения\nP ≤ α, отвергаем H0") + 
  annotate(geom = "text", x = 4, y = 0.1, label = "Редкие значения\nP ≤ α, отвергаем H0") + 
  annotate(geom = "text", x = 0, y = 0.1, label = "Обычные значения\nP > α, сохраняем H0") + 
  geom_vline(xintercept = p_cut, size = 1, linetype = "dotted") +
  geom_vline(xintercept = -p_cut, size = 1, linetype = "dotted") +
    annotate(geom = "text", x = -p_cut, y = 0.4, hjust = 1.1, 
           label = "-t и t при alpha 0.05") 
```

## Тестирование гипотезы о равенстве двух средних при помощи t-теста

### Алгоритм действий

1. Для конкретных данных считаем значение t-критерия
2. Сравниваем его с теоретическим распределением t (распределением при условии, что $H_0$ верна) при данном числе степеней свободы df. Находим p --- вероятность найти более экстремальное значение тестовой статистики.
3. Решаем, отвергнуть ли $H_0$:
    + Если $P \le \alpha$, отвергаем $H_0$
    + Если $P > \alpha$, сохраняем $H_0$

```{r gg-tcrit-h, echo=FALSE, purl=FALSE, fig.width=10}
# |t|
T_large <- 1.5 
T_small <- 2.3
  
gg_t_large_p_alpha <- gg_t +
    stat_function(fun = dt, args = list(df = df), 
                geom = "line", colour="darkred", size = 1, aes(colour = "H0")) +
# p
stat_function(fun = dt_limit, 
              args = list(alph = 2*pt(-abs(T_large), df = df)), 
              geom = "area", fill = "grey", alpha = 0.7) + 
  # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom = "area", fill = "red", alpha = 0.2) +
  
    # limits
  geom_vline(xintercept = T_large, size = 1, linetype = "dotted") +
  geom_vline(xintercept = -T_large, size = 1, linetype = "dotted") +
  annotate(geom = "text", x = -T_large, y = 0.1, hjust = 1.3,
           label = "P(t[obs] <= -t[0])", parse = TRUE) +
  annotate(geom = "text", x = T_large, y = 0.1, hjust = -0.3,
           label = "P(t[obs] >= t[0])", parse = TRUE) +
  annotate(geom = "text", x = 0, y = 0.41, hjust = 0.5,
           label = "group('|', t[0], '|') == 1.5", parse = TRUE) +
  theme(legend.position = "none") +
# tails
  annotate(geom = "text", x = qt(0.025, df = 18), y = 0.04, hjust = 1.6,
           label = "alpha/2", parse = TRUE) +
      annotate(geom = "text", x = qt(0.975, df = 18), y = 0.04, hjust = -0.6,
           label = "alpha/2", parse = TRUE) +
    labs(title = "P > α, сохраняем H0")

gg_t_small_p_alpha <- gg_t + 
    stat_function(fun=dt, args=list(df=df), 
                geom="line", colour="darkred", size = 1, aes(colour = "H0")) +
  # p
stat_function(fun = dt_limit, 
              args = list(alph = 2*pt(-abs(T_small), df = df)), 
              geom = "area", fill = "grey", alpha = 0.7) + 
  # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom = "area", fill = "red", alpha = 0.2) +
    # limits
  geom_vline(xintercept = T_small, size = 1, linetype = "dotted") +
  geom_vline(xintercept = -T_small, size = 1, linetype = "dotted") +
  annotate(geom = "text", x = -T_small, y = 0.1, hjust = 1.1,
           label = "P(t[obs] <= -t[0])", parse = TRUE) +
  annotate(geom = "text", x = T_small, y = 0.1, hjust = -0.1,
           label = "P(t[obs] >= t[0])", parse = TRUE) +
  annotate(geom = "text", x = 0, y = 0.41, hjust = 0.5,
           label = "group('|', t[0], '|') == 2.3", parse = TRUE) +
  # tails
  annotate(geom = "text", x = qt(0.025, df = 18), y = 0.04, hjust = 1.6,
           label = "alpha/2", parse = TRUE) +
      annotate(geom = "text", x = qt(0.975, df = 18), y = 0.04, hjust = -0.6,
           label = "alpha/2", parse = TRUE) +
    labs(title = "P ≤ α, отвергаем H0")


grid.arrange(gg_t_large_p_alpha, gg_t_small_p_alpha, nrow = 1, widths = c(0.47, 0.53))
```


# Применение t-теста

## Пример: Снотворное

В датасете `sleep` содержатся данные об увеличении продолжительности сна по сравнению с контролем после применения двух снотворных препаратов (Cushny, Peebles, 1905, Student, 1908)

```{r}
data(sleep)
head(sleep)
# str(sleep)
```

## Двухвыборочный t-критерий

Сравним увеличение продолжительности сна при помощи двухвыборочного t-критерия.

```{r}
tt <- t.test(extra ~ group, sleep)
tt
```

Результаты можно описать, например, так:

- Различия изменения продолжительности сна при применении двух препаратов были недостоверны ($t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, eps = 0.01)`$)


## Что спрятано в результатах?

Как называются отдельные элементы результатов можно узнать посмотрев их структуру при помощи функции `str()`

```{r}
str(tt)
```

## Можно получить элементы результатов в виде отдельных цифр

```{r purl=FALSE}
tt$parameter # степени свободы
tt$p.value # доверительная вероятность
tt$statistic # значение t-критерия
```

## Задание

Файл `aml.csv` содержит данные о влиянии регулярной химиотерапии на продолжительность ремиссии.

Прочитаем эти данные
```{r}
rem <- read.csv(file = "data/aml.csv", header = TRUE)
str(rem)
```

- В переменной `time` представлена продолжительность ремиссии в днях.
- `group` указывает, к какой экспериментальной группе принадлежал пациент. В группе 1 проводилась регулярная химиотерапия, в группе 2 - нет.

Ваша задача сравнить эти группы с помощью t-теста.

## Решение

```{r purl=FALSE}
t.test(data = rem, time ~ group)
```

Или так:

```{r purl=FALSE, results="hide"}
t.test(rem$time[rem$group == 1], rem$time[rem$group == 2])
```

# Статистическая значимость

## Статистическая значимость

Статистическая значимость бывает только одна, и она говорит о том, в каких отношениях состоят, обнаруженные нами эмпирически различия с $\alpha$.

- Если мы отвергаем $H_0$ --- значит, имеются различия
- Если мы не отвергаем $H_0$ --- значит, все одинаково

Пожалуйста, никаких "недостоверных различий"! Если различия есть, то они достоверны. Если различия не достоверны, то их нет.

А что делать, если сердцем чувствуешь, что что-то должно быть, но тест не дает нужного ответа? Собрать выборки побольше, и посчитать заново. С уже проведенным тестом спорить не надо.

## Take-home messages

- Стандартизация --- преобразование данных в отклонения от среднего значения, измеренные в стандартных отклонениях
- Стандартное нормальное распределение удобно для расчетов вероятностей
- Вероятность попадания случайной величины в произвольный интервал можно получить в результате интегрирования кривой распределения на этом интервале
- При тестировании нулевой гипотезы оценивают вероятность получения данного или более экстремального значения тестовой статистики при условии справедливости нулевой гипотезы. Если эта вероятность меньше выбранного уровня значимости, то нулевую гипотезу отвергают
- Для сравнения выборочных средних в независимых выборках лучше использовать t-критерий Уэлча, который учитывает, что дисперсии в выборках могут быть разными

## Дополнительные ресурсы

- OpenIntro: Statistics
- Quinn, Keough, 2002
- Sokal, Rohlf, 1995
- Zar, 1999


