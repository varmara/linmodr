---
title: "Линейные модели для счетных данных"
author: Марина Варфоломеева, Вадим Хайтов
output:
  ioslides_presentation:
    widescreen: yes
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE, cache = FALSE)
```


## Мы рассмотрим 

+ Варианты анализа для случаев, когда зависимая перменная --- счетная величина (целые неотрицательные числа)

###  Вы сможете

+ Объяснить особенности разных типов распределений, принадлежащих экспоненциальному семейству. 
+ Построить пуасоновскую и квази-пуассоновскую линейную модель
+ Объяснить проблемы, связанные с избыточностью дисперсии в модели
+ Построить модель, основанную на отрицательном биномиальном распределении


# Статистические распределения

## Основные распределения для непрерывных данных

- Нормальное распределение (уже знакомо)
- Гамма-распределение

## Нормальное распределение

$$f(y;\mu, \sigma)= \frac {1}{\sigma \sqrt{2 \pi}} e^{-\frac{(y-\mu)^2}{2\sigma^2}}$$


<div class="columns-2">

```{r, echo=FALSE, fig.width=5, fig.height=5, warning=FALSE, purl=FALSE}
library(ggplot2)
mu1 <- 10
mu2 <- 20
sigma1 <- 5
sigma2 <- 10
y <- -20:50

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dnorm(y, mu1, sigma1), dnorm(y, mu1, sigma2), 
         dnorm(y, mu2, sigma1), dnorm(y, mu2, sigma2)), 
  mu = rep(c(mu1, mu2), each = 2*length(y)), 
  sigma = rep(c(sigma1, sigma2, sigma1, sigma2), each = length(y)) )

ggplot(pi, aes(x = y, y = pi)) + 
  geom_line(stat = "identity") + 
  facet_grid(mu~sigma, labeller = label_both, scales = "free_y") + 
  ggtitle("Нормальное распределение \nпри разных параметрах") + 
  ylab("Плотность вероятности (f)")
```

### Два параметра ($\mu$, $\sigma$)

Среднее: &emsp; $E(Y)  = \mu$

Дисперсия: $var(Y) = \sigma^2$

### Пределы варьирования   

$-\infty \le Y \le +\infty$    

</div>

## Гамма-распределение

$$f(y; \mu, \nu) = \frac{1}{\Gamma(\nu)}\times (\frac{\nu}{\mu})^{\nu} \times y^{\nu-1} \times e^{\frac{y \times \nu}{\mu}}$$

<div class="columns-2">

```{r, fig.width=5, fig.height=5, echo=FALSE, fig.align='right', purl=FALSE}
mu1 <- 1
mu2 <- 0.1
nu1 <- 0.1
nu2 <- 2
y <- 0:30

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dgamma(y, nu1, mu1), dgamma(y, nu1, mu2), 
         dgamma(y, nu2, mu1), dgamma(y, nu2, mu2)), 
  mu = rep(c(mu1, mu2), each = 2*length(y)), 
  nu = rep(c(nu1, nu2, nu1, nu2), each = length(y)) )

ggplot(pi, aes(x = y, y = pi)) + 
  geom_line(stat = "identity") + 
  facet_grid(mu~nu, labeller = label_both, scales = "free_y") + 
  ggtitle("Гамма распределение при разных параметрах") + 
  ylab("Плотность вероятности (f)")

```

### Два параметра ($\mu$, $\nu$)

Среднее: $E(Y)  = \mu$

Дисперсия: $var(Y) = \frac {\mu^2}{\nu}$

Параметр $\nu$ определяет степень избыточности дисперсии

### Пределы варьирования

$0 < Y \le +\infty$

Внимание! $Y$ строго больше 0

</div>

## Распределения для дискретных данных

- Биномиальное распределение (знакомство было в прошлый раз)
- Распределение Пуассона
- Отрицательное биномиальное распределение


## Биномиальное распределение

$$f(y; N, \pi) = \frac{N!}{y! \times (N-y)!} \times \pi^y \times (1 - \pi)^{N-y}$$

<div class="columns-2">

```{r, echo=FALSE, fig.width=5, fig.height=5, purl=FALSE}
mu1 <- 0.1
mu2 <- 0.5
N1 <- 10
N2 <- 30
y <-seq(0, 30, 1)

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dbinom(y, size = N1, prob = mu1), 
         dbinom(y,  size = N2, prob = mu1), 
         dbinom(y,  size = N1, prob = mu2), 
         dbinom(y,  size = N2, prob = mu2)),  
  mu = rep(c(mu1, mu2), each = 2*length(y)), 
  N = rep(c(N1, N2, N1, N2), each = length(y)))

ggplot(pi, aes(x = y, y = pi)) + 
  geom_bar(stat = "identity") + 
  facet_grid(N~mu,  scales = "free_y", labeller = label_both) + 
  ggtitle("Биномиальное распрделение \n при разных параметрах") + 
  ylab("Плотность вероятности (f)")
```


### Два параметра ($N$, $\pi$)

Среднее: &emsp;&emsp; $E(Y)  = N \times \pi$

Дисперсия: $var(Y) = N \times \pi \times (1-\pi)$

Параметр $N$ определяет количество объектов в испытании

Параметр $\pi$ - вероятность события ($y = 1$)

### Пределы варьирования

$0 \le Y \le +\infty$, &emsp; $Y$ **целочисленные**

</div>


## Распределение Пуассона 

$$f(y;\mu)= \frac{\mu^y \times e{-\mu}}{y!}$$

<div class="columns-2">

```{r, echo=FALSE, warning=FALSE, fig.width=5, fig.height=5, purl=FALSE}
mu1 <- 1
mu2 <- 5
mu3 <- 10
mu4 <- 20
y <- 0:30

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dpois(y, mu1), dpois(y, mu2), dpois(y, mu3), dpois(y, mu4)), 
  mu = rep(c(mu1, mu2, mu3, mu4), each = length(y))
)

ggplot(pi, aes(x = y, y = pi)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~ mu, nrow = 2, scales = "free_y", labeller = label_both) + 
  ggtitle("Распределение Пуассона \nпри разных параметрах") + 
  ylab("Плотность вероятности (f)")
```

### Один параметр ($\mu$)

Среднее: &emsp; $E(Y)  = \mu$

Дисперсия: $var(Y) = \mu$

**Важное свойство**: При увеличении значения $\mu$ увеличивается размах варьирования

### Пределы варьирования

$0 \le Y \le +\infty$, $Y$ **целочисленные**

</div>


## Отрицательное биномиальное распределение

$$f(y; k, \mu) = \frac{\Gamma(y + k)}{\Gamma(k) \times \Gamma(y+1)} \times (\frac{k}{\mu + k})^k \times (1 - \frac{k}{\mu + k})^y$$

<div class="columns-2">


```{r, echo=FALSE, fig.width=5, fig.height=5, purl=FALSE}
mu1 <- 1
mu2 <- 10
k1 <- 0.1
k2 <- 1000000
y <- 0:30

pi <- data.frame(
  y = rep(y, 4), 
  pi = c(dnbinom(y, size = k1, mu = mu1), 
         dnbinom(y, size = k1, mu = mu2), 
         dnbinom(y, size = k2, mu = mu1), 
         dnbinom(y, size = k2, mu = mu2)), 
  mu = rep(c(mu1, mu2), each = 2*length(y)), 
  k = rep(c(k1, k2, k1, k2), each = length(y)) )

ggplot(pi, aes(x = y, y = pi)) + 
  geom_bar(stat = "identity") + 
  facet_grid(mu~k, labeller = label_both, scales = "free_y") + 
  ggtitle("Отрицательное биномиальное распределение \nпри разных параметрах") + 
  ylab("Плотность вероятности (f)")
```

Это смесь Пуассоновского и Гамма распределений: $Y$ подчиняется распределению Пуассона с Гамма-распределенным $\mu$.

### Два параметра ($\mu$, $k$)

Среднее: &emsp; $E(Y)  = \mu$

Дисперсия: $var(Y) = \mu + \frac {\mu^2}{k}$

Параметр $k$ определяет степень избыточности дисперсии.

**Свойство**: Приближается к распр. Пуассона при очень больших $k$.

### Пределы варьирования

$0 \le Y \le +\infty$, &emsp; $Y$ **целочисленные**

</div>


# Распределение зависимой переменной и линия регрессии

## Связующая функция (Link function)

Предсказаные значения, т.е. $E(Y_i) = \mu_i$, лежат на линии регрессии.   

Для линейных моделей с нормальным распределением отклика связь между $E(Y_i)$ и предикторами линейна. 

Для других типов распределений эта связь нелинейна.

Функция, при помощи которой удается линеаризовать связь между $E(Y_i)$ и предикторами называется *связующей функцией*. (Иными словами, связующая функция описывает связь между $\mu_i$ и значениями предикторов в виде линейной функции).

## Наиболее распространенные (канонические) связующие функции

Характер величин | Распределение | Связующая функция (link function)   
|-------------|-------------|-------------|  
Непрерывные величины, потенциально варьирующие в пределах $-\infty , + \infty$ | Гауссовское (Нормальное) | identity  $X\beta = \mu$   
Бинарные величины (1; 0), или количество (доля) объектов, относящихся к одному из двух классов |  Биномиальное распределение  | logit $X\beta = ln(\frac{\mu}{1 - \mu})$    
Счетные величины (0, 1, 2, 3...)  |  Распределение Пуассона или Отрицательное биномиальное распределение  |log $X\beta = ln(\mu)$  


Есть и другие, неканонические связующие функции


```{r, echo=FALSE, fig.height=4.5, fig.width=8, warning=FALSE, message=FALSE, purl=FALSE}
library(gridExtra)

theme_set(theme_bw())

# Регрессия с нормальным распределением 
xy <- data.frame(X = rep(1:10, 3))
xy$Y <- 10*xy$X + rnorm(30, 0, 10)

Mod <- lm(Y ~ X, data = xy)

xy$predicted <- predict(Mod)

xy$predicted2 <- xy$predicted/0.8

rand_df <- matrix(rep(NA,100000), ncol = 10)
for(i in 1:10) rand_df[,i] <- rnorm(10000, xy$predicted[i], summary(Mod)$sigma)

rand_df <- data.frame(X = rep(xy$X, each = 10000), Y = as.vector(rand_df))



Plot_Norm <- ggplot(xy, aes(x = X, y = Y)) + geom_violin(data = rand_df, aes(x = factor(X)), adjust = 5) + geom_point() + geom_smooth(method = "lm", se = F) + geom_point(data = xy, aes(x = X, y = predicted), color = "red", size = 3) + labs(x = "Предиктор", y = "Зависимая переменная") + ggtitle("Нормальное распределение") 




#Регрессия с биномиальным распределением

#Нсходящая
xy <- data.frame(X = rep(seq(1,50, 5), 3))
p <- -0.2*xy$X + 5
p <- exp(p) / (1 + exp(p))

Size = length(xy$X)

xy$Y <- rbinom(30, Size, p)/Size

Mod <- glm(Y ~ X, data = xy, family = "binomial")



xy$predicted <- predict(Mod, type = "response")


rand_df <- matrix(rep(NA,100000), ncol = 10)



for(i in 1:10) rand_df[,i] <- rbinom(10000, Size, xy$predicted[i]) / Size

rand_df <- data.frame(X = rep(xy$X, each = 10000), Y = as.vector(rand_df))

pred_df <- data.frame(X = unique(xy$X))
pred_df$predicted <- predict(Mod, type = "response", newdata = pred_df)

Plot_Binom1 <-  ggplot(data = xy, aes(x = factor(X), y = Y)) + geom_violin(data = rand_df, aes(x = factor(X)), adjust = 10) + geom_point(data = xy, aes(x = factor(X), y = Y)) + geom_path(data = pred_df, aes(x = factor(X), y = predicted, group = 1), color = "blue", size = 1) + geom_point(data = xy, aes(x = factor(X), y = predicted), color = "red", size = 3) + labs(x = "Предиктор", y = "Зависимая переменная \n(доля положительных исходов)") + ggtitle("Биномиальное распределение")


#Восходящая

xy <- data.frame(X = rep(seq(1,50, 5), 3))
p <- 0.2*xy$X - 5
p <- exp(p) / (1 + exp(p))

Size = length(xy$X)

xy$Y <- rbinom(30, Size, p)/Size

Mod <- glm(Y ~ X, data = xy, family = "binomial")



xy$predicted <- predict(Mod, type = "response")


rand_df <- matrix(rep(NA,100000), ncol = 10)



for(i in 1:10) rand_df[,i] <- rbinom(10000, Size, xy$predicted[i]) / Size

rand_df <- data.frame(X = rep(xy$X, each = 10000), Y = as.vector(rand_df))

pred_df <- data.frame(X = unique(xy$X))
pred_df$predicted <- predict(Mod, type = "response", newdata = pred_df)

Plot_Binom2<-  ggplot(data = xy, aes(x = factor(X), y = Y)) + geom_violin(data = rand_df, aes(x = factor(X)), adjust = 10) + geom_point(data = xy, aes(x = factor(X), y = Y)) + geom_path(data = pred_df, aes(x = factor(X), y = predicted, group = 1), color = "blue", size = 1) + geom_point(data = xy, aes(x = factor(X), y = predicted), color = "red", size = 3) + labs(x = "Предиктор", y = "Зависимая переменная \n(доля положительных исходов)") + ggtitle("Биномиальное распределение")





# Регрессия с пуассоновским распределением

xy <- data.frame(X = rep(seq(1,50, 5), 3))
p <- 2*xy$X + 5

# p <- exp(p)

xy$Y <- rpois(30, p)

Mod <- glm(Y ~ X, data = xy, family = "poisson")



xy$predicted <- predict(Mod, type = "response")


rand_df <- matrix(rep(NA,100000), ncol = 10)



for(i in 1:10) rand_df[,i] <- rpois(10000, xy$predicted[i]) 

rand_df <- data.frame(X = rep(xy$X, each = 10000), Y = as.vector(rand_df))

pred_df <- data.frame(X = unique(xy$X))
pred_df$predicted <- predict(Mod, type = "response", newdata = pred_df)

Plot_Poiss <-  ggplot(data = xy, aes(x = factor(X), y = Y)) + geom_violin(data = rand_df, aes(x = factor(X)), adjust = 5) + geom_point(data = xy, aes(x = factor(X), y = Y)) + geom_path(data = pred_df, aes(x = factor(X), y = predicted, group = 1), color = "blue", size = 1) + geom_point(data = xy, aes(x = factor(X), y = predicted), color = "red", size = 3) + labs(x = "Предиктор", y = "Зависимая переменная") + ggtitle("Пуассоновское распределение")


```

##Связующая функция (Link function)

В случае с нормальным распределением, предсказанные значения лежат на прямой линии, связывающей значения предиктора $x_i$ и предсказанное значение $\mu_i$. 

Т.к. зависимость и так линейная, то связующая функция не выполняет никакой работы --- описывает идентичность (`link = "identity"`).

```{r, echo=FALSE, fig.height=4.5, purl=FALSE}
Plot_Norm
```

##Связующая функция (Link function)

В случае с биномиальным распределением, предсказанные значения лежат на логистической кривой, связывающей значения предиктора $x_i$ и предсказанное значение $\mu_i$.  

Связующая функция логит (`link = "logit"`) линеаризует эту зависимость.

```{r, echo=FALSE, fig.height=4.5, purl=FALSE}
grid.arrange(Plot_Binom1, Plot_Binom2, ncol = 2)
```


##Связующая функция (Link function)

В случае с пуассоновским распределением, предсказанные значения лежат на экспоненциальной кривой, связывающей значения предиктора $x_i$ и предсказанное значение $\mu_i$.

Связующая функция логарифм (`link = "log"`) линеаризует эту зависимость.

```{r, echo=FALSE, fig.height=4.5, purl=FALSE}
Plot_Poiss
```


# Пример

## Пример: Гадючий лук, копеечник и визиты опылителей

[Гадючий лук](https://ru.wikipedia.org/wiki/Гадючий_лук_хохлатый) (_Leopoldia comosa_, сем. спаржевые) --- представитель родной флоры острова Менорка (Балеарские острова, Средиземное море). В 18-19вв на остров завезли [копеечник венечный](https://ru.wikipedia.org/wiki/Копеечник_венечный) (_Hedysarum coronarium_, сем. бобовые), который быстро натурализовался. Оба вида цветут одновременно и нуждаются в опылении насекомыми.

Как зависит опыление гадючьего лука от присутствия вида-вселенца и разнообразия флоры в ближайшей окрестности (Montero-Castaño, Vilà, 2015)?

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Muscari_comosum_08-05-2010_%281%29.JPG/265px-Muscari_comosum_08-05-2010_%281%29.JPG" alt="Leopoldia comosa" style="height: 275px;"/>
<img src="images/Montero-Castaño, Vilà M, 2015_fig.2.png" alt="Fig.2" style="height: 275px;"/>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Hedysarum_coronarium_%28plant%29.jpg/265px-Hedysarum_coronarium_%28plant%29.jpg" alt="Hedysarum coronarium" style="height: 275px;"/>


<small>
Muscari à toupet (Muscari comosum), Dordogne, France --- Père Igor  
Fig.2 из [Montero-Castaño, Vilà, 2015](https://doi.org/10.1371/journal.pone.0128595)  
French-honeysuckle. Close to Santadi Basso, Sardinia, Italy --- Hans Hillewaert  
</small>


## Данные {.smaller}

- `Visits` --- число визитов всех опылителей на цветок _Leopoldia_
- `Treatment` ---   `Invaded` --- _Leopoldia_ в смеси с видом-вселенцем _Hedysarum_;  `Removal` --- _Leopoldia_ в смеси с видом-вселенцем с удаленными цветками; `Control` --- _Leopoldia_ без вида вселенца
- `DiversityD_1` --- Разнообразие флоры --- $exp(H’)$,  где $H'$ --- индекс Шеннона, расчитанный с использованием натурального логарифма
- `Flowers` --- число цветков _Leopoldia_
- `Hours` --- продолжительность наблюдений


```{r data}
library(readxl)
pol <- read_excel("data/Pollinators_Montero-Castano, Vila, 2015.xlsx", sheet = 1)
head(pol)
```

<small>[Montero-Castaño A., Vilà M. 2015](https://doi.org/10.1371/journal.pone.0128595)</small>

## Знакомство с данными

Есть ли пропущенные значения?

```{r}
sum(is.na(pol))
```

Сколько площадок в каждом тритменте?
```{r}
table(pol$Treatment)
```

## Знакомство с данными

Как распределено число визитов насекомых?

```{r}
library(ggplot2)
ggplot(pol, aes(x = Visits)) + geom_histogram()
```

## Знакомство с данными

Нет ли выбросов?

```{r}
gg_dot <- ggplot(pol, aes(y = 1:nrow(pol))) + geom_point()
library(gridExtra)
grid.arrange(gg_dot + aes(x = DiversityD_1),
             gg_dot + aes(x = Flowers),
             gg_dot + aes(x = Hours),
             nrow = 1)
```

>- Выбросов нет


# Простая линейная модель

## GLM с Гауссовым распределением отклика

$Visits_i \sim N(\mu_i, \sigma)$

$E(Visits_i) = mu_i$, $var(Visits_i) = \sigma$

Функция связи --- идентичность, т.е.

$\mu_i = b_0 + b_1 TreatmentInvaded + b_2 TreatmentRemoval +$  
$+ b_3 DiversityD1 + b_4 Flowers + b_5 Hours$


## Что будет, если мы (ошибочно) подберем простую линейную модель? {.smaller}

```{r}
M0 <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol)
## Результаты
summary(M0)
```


## Анализ девиансы для гауссовой модели {.smaller}

К какому бы мы пришли выводу, глядя на этот анализ?

```{r}
library(car)
Anova(M0)
```

>- Число визитов опылителей на цветки гадючьего лука 
    - НЕ зависит от присутствия вида вселенца и его цветов
    - НЕ зависит от разнообразия флоры на участке
    - зависит от числа цветов самого гадючьего лука
    
>- Можем ли мы доверять этим результатам? Пока не известно.

## Визуализируем предсказания простой линейной модели

```{r, m0-viz, eval=TRUE, echo=FALSE, fig.height=5, fig.width=10}
library(plyr)
NewData <- ddply(
  .data = pol, .variables = .(Treatment), .fun = summarise,
  DiversityD_1 = seq(min(DiversityD_1), max(DiversityD_1), length = 100))
NewData$Flowers = mean(pol$Flowers)
NewData$Hours = mean(pol$Hours)
# модельная матрица
X <- model.matrix(~ Treatment + DiversityD_1 + Flowers + Hours, data = NewData)
# коэффициенты
betas <- coef(M0)
# предсказанные значения
NewData$mu <- X %*% betas  # в масштабе функции связи
NewData$fit <- NewData$mu  # в масштабе значений отклика
# стандартные ошибки
NewData$SE <- sqrt(diag(X %*% vcov(M0) %*% t(X)))
# доверительный интервал
NewData$upr <- NewData$mu + 1.96 * NewData$SE
NewData$lwr <- NewData$mu - 1.96 * NewData$SE
# график предсказаний
ggplot(NewData, aes(x = DiversityD_1, y = fit, group = Treatment)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = Treatment), alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```


## Код для графика {.smaller}

```{r, m0-viz, eval=FALSE, tidy=TRUE, tidy.opts=list(width=50), purl=FALSE}
```

## Задание 1

Постройте график пирсоновских остатков этой модели.

Какие нарушения условий применимости вы на нем увидите?

Дополните код

```{r eval=FALSE}
# Данные для анализа остатков
M0_diag <- data.frame(.fitted = ,
                      .pears_resid = )
# График остатков
ggplot(M0_diag, aes(x=, y = )) + 
  geom_ + geom_(yintercept = 0) + 
  geom_(se = FALSE, method = "loess")
```

## Решение

```{r fig.height=2.4}
# Данные для анализа остатков
M0_diag <- data.frame(.fitted = predict(M0, type = "response"),
                      .pears_resid = residuals(M0, type = "pearson"))
# График остатков
ggplot(M0_diag, aes(x=.fitted, y = .pears_resid)) + 
  geom_point() + geom_hline(yintercept = 0) + 
  geom_smooth(se = FALSE, method = "loess")
```

>- Гетерогенность дисперсий остатков
>- Отрицательные предсказания

## Два способа решения проблем с моделью

1. Плохой способ: провести логарифмирование зависимой переменной и построить модель для логарифмированных величин. 
2. Лучше построить модель, основанную на распределении Пуассона.


# GLM с Пуассоновским распределением отклика

## GLM с Пуассоновским распределением отклика

$Visits_i \sim Poisson(\mu_i)$

$E(Visits_i) = mu_i$, $var(Visits_i) = mu_i$

Функция связи --- логарифм, т.е.

$\ln(\mu_i) = b_0 + b_1 TreatmentInvaded + b_2 TreatmentRemoval +$  
$+ b_3 DiversityD1 + b_4 Flowers + b_5 Hours$

## GLM с Пуассоновским распределением отклика {.smaller}

```{r}
M1 <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol,  family = "poisson")
## Результаты
summary(M1)
```

## Уравнение модели с Пуассоновским распределением отклика

$Visits_i ~ Poisson(\mu_i)$

$E(Visits_i) = mu_i$, $var(Visits_i) = mu_i$

$\ln(\mu_i) = -2.66 + 0.71 TreatmentInvaded - 0.22 TreatmentRemoval -$  
$- 0.46 DiversityD1 + 0.04  Flowers + 4.69 Hours$


## Анализ девиансы для Пуассоновской модели

К какому бы мы пришли выводу, глядя на этот анализ?

```{r}
Anova(M1)
```

>- Число визитов опылителей на цветки гадючьего лука
    - зависит от присутствия вида вселенца и его цветов
    - зависит от разнообразия флоры на данном участке
    - зависит от числа цветов самого гадючьего лука
    
>- Можем ли мы доверять этим результатам? Пока не известно.

## Задание 2

Постройте график предсказаний модели

```{r eval=FALSE, purl=TRUE}
NewData <- ddply(
  .data = , .variables = .(), .fun = summarise,
  DiversityD_1 = seq(min(), max(), length = 100))
NewData$Flowers = mean(pol$Flowers)
NewData$Hours = mean(pol$Hours)
# модельная матрица
X <- model.matrix(, data = NewData)
# коэффициенты
betas <- 
# предсказанные значения
NewData$mu <-       # в масштабе функции связи
NewData$fit <-  # в масштабе значений отклика
# стандартные ошибки
NewData$SE <- sqrt(diag(X %*% vcov(M1) %*% t(X)))
# доверительный интервал в масштабе значений отклика
NewData$upr <- (NewData$mu + 1.96 * NewData$SE)
NewData$lwr <- (NewData$mu - 1.96 * NewData$SE)
# график предсказаний
ggplot(NewData, aes(x = , y = , group = Treatment)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = ), alpha = 0.3) +
  geom_line(aes(colour = )) + 
  geom_hline(yintercept = 0)
```

## Визуализируем предсказания модели с Пуассоновским распределением отклика

```{r, m1-viz, eval=TRUE, echo=FALSE, fig.height=5, fig.width=10, purl=FALSE}
NewData <- ddply(
  .data = pol, .variables = .(Treatment), .fun = summarise,
  DiversityD_1 = seq(min(DiversityD_1), max(DiversityD_1), length = 100))
NewData$Flowers = mean(pol$Flowers)
NewData$Hours = mean(pol$Hours)
# модельная матрица
X <- model.matrix(~ Treatment + DiversityD_1 + Flowers + Hours, data = NewData)
# коэффициенты
betas <- coef(M1)
# предсказанные значения
NewData$mu <- X %*% betas      # в масштабе функции связи
NewData$fit <- exp(NewData$mu) # в масштабе значений отклика
# стандартные ошибки
NewData$SE <- sqrt(diag(X %*% vcov(M1) %*% t(X)))
# доверительный интервал
NewData$upr <- exp(NewData$mu + 1.96 * NewData$SE)
NewData$lwr <- exp(NewData$mu - 1.96 * NewData$SE)
# график предсказаний
ggplot(NewData, aes(x = DiversityD_1, y = fit, group = Treatment)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = Treatment), alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```

## Код для графика {.smaller}

```{r, m1-viz, eval=FALSE, tidy=TRUE, tidy.opts=list(width=50), purl=FALSE}
```

## Диагностика модели

### График остатков

```{r}
M1_diag <- data.frame(.fitted = predict(M1, type = "response"),
                      .pears_resid = residuals(M1, type = "pearson"))
ggplot(M1_diag, aes(x=.fitted, y = .pears_resid)) + geom_point() +
  geom_hline(yintercept = 0) + geom_smooth(se = FALSE, method = "loess")

```

## Проблема избыточности дисперсии (overdispersion)

Если данные подчиняются распределению Пуассона, то

- Среднее: &emsp; $E(Y)  = \mu$
- Дисперсия: $var(Y) = \mu$

То есть, дисперсия должна быть равна среднему значению.

Если это нарушается, то мы не можем доверять результатам, так как модель, основанная на Пуассоновском распределении, применяется к данным, которые не подчиняются этому распределению. 

## Проверка на сверхдисперсию

```{r}
pear_res <- resid(M1, type = "pearson") # Пирсоновские остатки
p <- length(coef(M1))                   # число параметров в модели  
N <- nrow(model.frame(M1)) # объем выборки
df <- N - p       # число степеней свободы
Overdisp <- sum(pear_res^2) / df

Overdisp
```

>- Избыточность дисперсии есть! Дисперсия в `r round(Overdisp, 1)` раза выше среднего

## Если есть избыточность дисперсии, то 

### Доверительные интервалы будут занижены

Если предполагать, что данные подчиняются распределению Пуассона (среднее $E(Y)  = \mu$, дисперсия --- $var(Y) = \mu$), то $var(\bar Y) = {\mu} / n$ и доверительный интервал к среднему будет оценен как $\bar Y \pm z_{\alpha/2}\sqrt {var(\bar Y)}$.

Если на самом деле дисперсия в $\varphi$ раз больше среднего ($\varphi > 1$): $var^*(Y) = \varphi\mu$

Тогда на самом деле $var(\bar Y) = {\varphi\mu} / n$, а доверительный интервал к среднему должен быть в $\sqrt\varphi$ раз больше:  $\bar Y \pm z_{\alpha/2}\sqrt {\varphi~var(\bar Y)}$.

### Стандартные ошибки будут занижены

(аналогично предыдущему пункту)

### Тесты, основанные на сравнении правдоподобий будут давать смещенные результаты

Т.к. на самом деле соотношение девианс будет подчиняться не $\chi^2$-распределению, а масштабированному $\chi^2$-распределению



## Причины избыточности дисперсии 

1. Мнимая избыточность дисперсии
    + Наличие выбросов
    + В модель не включен важный предиктор или взаимодействие предикторов
    + Наличие внутригрупповых корреляций (нарушение независимости выборок)
    + Нелинейный характер взаимосвязи между ковариатами и зависимой переменной
    + Неверно выбрана связывающая функция
    + Количество нулей больше, чем предсказывает выбранное распределение (Zero inflation) 
2. Истинная избыточность дисперсии, как следствие природы данных

## Как бороться с избыточностью дисперсии

Если избыточнсть дисперсии *мнимая*, то ее надо устранить, введя в модель соответствующие изменения

Если избыточность дисперсии *истинная*, то необходима более серьезная коррекция модели:

- Можно построить квази-пуассоновскую модель
- Можно построить модель, основанную на отрицательном биномиальном распределении

# Квазипуассоновская модель

## Квази-пуассоновские модели

Единственное отличие от пуассоновской модели в том, что в квази-пуассоновских моделях вводится поправка для связи дисперсии и среднего

- Среднее: $E(Y) = \mu$
- Дисперсия: $var(Y) =  \varphi \times \mu$

<br>

Величина $\varphi$ показывает во сколько раз дисперсия превышает среднее

Вот такой вариант оценки используется в R (рекомендован McCullagh, Nelder, 1989):

$$\varphi =  \frac{var(Y)}{\mu}=\frac {\frac{\sum{(\epsilon_i)^2}}{N - p}}  {\mu} =  \frac{\sum{(\epsilon_{pearson})^2}}{N - p}$$



Квазипуассоновская модель, по сути, по-прежнему пуассоновская, но стандартные ошибки оценок параметров домножаются на $\sqrt{\varphi}$

## Особенности работы с квази-моделями

<!-- По лекции Марка Ирвина. TODO: нужны ссылки -->

1.В тестах параметров используются $t$-тесты (и $t$-распределение) вместо $z$ тестов (и стандартного нормального распределения)

2.Для квази-пуассоновских моделей не определена функция максимального правдоподобия, поэтому нельзя вычислить AIC (но иногда считают квази-AIC = QAIC)

3.Для тестов изменения девиансы используются $F$-тесты

$$F = \frac{\Delta/d} {\varphi}$$
Эта $F$-статистика подчиняется $F$-распределению со степенями свободы $d$ и $df$

- $\Delta$ --- разница девианс
- $d$ --- разница числа параметров сравниваемых моделей
- $df$ --- остаточное число степеней свободы для более полной модели 


## Квазипуассоновская модель {.smaller}

```{r}
M2 <- glm(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol, family = "quasipoisson")
## Результаты
summary(M2)
```

## Анализ девиансы для квази-пуассоновской модели {.smaller}

К какому бы мы пришли выводу, глядя на этот анализ?

```{r}
Anova(M2, test = "F")
```

>- Число визитов опылителей на цветки гадючьего лука 
    - зависит от присутствия вида вселенца и его цветов
    - зависит от разнообразия флоры на данном участке
    - зависит от числа цветов самого гадючьего лука
    
>- Можем ли мы доверять этим результатам? Это приблизительные результаты. Доверительным вероятностям близким к 0.05 не стоит доверять.


# GLM с отрицательным биномиальным распределением отклика

## GLM с отрицательным биномиальным распределением отклика

$Visits_i \sim NB(\mu_i, k)$

$E(Visits_i) = mu_i$, $var(Visits_i) = mu_i + \frac{\mu_i^2}{k}$

Функция связи --- логарифм, т.е.

$\ln(\mu_i) = b_0 + b_1 TreatmentInvaded + b_2 TreatmentRemoval +$  
$+ b_3 DiversityD1 + b_4 Flowers + b_5 Hours$

## GLM с отрицательным биномиальным распределением отклика {.smaller}

```{r}
library(MASS)
M3 <- glm.nb(Visits ~ Treatment + DiversityD_1 + Flowers + Hours, data = pol, link = "log")
## Результаты
summary(M3)
```

## Уравнение модели с отрицательным биномиальным распределением отклика

$Visits_i \sim NB(\mu_i, 1.936)$

$E(Visits_i) = mu_i$, $var(Visits_i) = mu_i + \frac{\mu_i^2}{1.936}$

Функция связи --- логарифм, т.е.

$\ln(\mu_i) = -1.97 + 0.57 TreatmentInvaded - 0.11 TreatmentRemoval -$  
$- 0.49 DiversityD1 + 0.03 Flowers + 4.10 Hours$

## Анализ девиансы для модели с отрицательным биномиальным распределением отклика {.smaller}

К какому бы мы пришли выводу, глядя на этот анализ?

```{r}
Anova(M3)
```

>- Число визитов опылителей на цветки гадючьего лука
    - НЕ зависит от присутствия вида вселенца и его цветов
    - зависит от разнообразия флоры на данном участке
    - зависит от числа цветов самого гадючьего лука
    
>- Можем ли мы доверять этим результатам? Да, теперь можем


## Диагностика модели

### График остатков

```{r}
M3_diag <- data.frame(.fitted = predict(M3, type = "response"),
                      .pears_resid = residuals(M3, type = "pearson"))
ggplot(M3_diag, aes(x = .fitted, y = .pears_resid)) + geom_point() + 
  geom_hline(yintercept = 0) + geom_smooth(se = FALSE, method = "loess")
```

## Проверка на сверхдисперсию

Обратите внимание, у моделей с отрицательным биномиальным распределением добавляется еще один параметр

```{r}
pear_res <- resid(M3, type = "pearson") # Пирсоновские остатки
p <- length(coef(M3))  + 1             # число параметров в модели
N <- nrow(model.frame(M3))             # объем выборки
df <- N - p                            # число степеней свободы
Overdisp <- sum(pear_res^2) / df

Overdisp
```

>- Избыточности дисперсии нет

## Задание 3

Визуализируйте предсказания модели, основанной на отрицательном биномиальном распределении 

```{r eval=FALSE, purl=TRUE}
NewData <- ddply(
  .data = , .variables = .(), .fun = summarise,
  DiversityD_1 = )
NewData$Flowers = mean(pol$Flowers)
NewData$Hours = mean(pol$Hours)
# предсказанные значения
Predictions <- predict()
NewData$fit <- Predictions$fit
# стандартные ошибки
NewData$SE <- Predictions$se.fit
# доверительный интервал
NewData$upr <- NewData$fit + 1.96 * NewData$SE
NewData$lwr <- NewData$fit - 1.96 * NewData$SE

ggplot(NewData, aes(x = , y = , group = )) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.3) +
  geom_line() + 
  geom_hline(yintercept = 0)
```

## Визуализируем предсказания модели

```{r, m3-viz, eval=TRUE, echo=FALSE, fig.height=5, fig.width=10, purl=FALSE}
NewData <- ddply(
  .data = pol, .variables = .(Treatment), .fun = summarise,
  DiversityD_1 = seq(min(DiversityD_1), max(DiversityD_1), length = 100))
NewData$Flowers = mean(pol$Flowers)
NewData$Hours = mean(pol$Hours)
# предсказанные значения
Predictions <- predict(M3, newdata = NewData, se.fit = TRUE, type = "response")
NewData$fit <- Predictions$fit
# стандартные ошибки
NewData$SE <- Predictions$se.fit
# доверительный интервал
NewData$upr <- NewData$fit + 1.96 * NewData$SE
NewData$lwr <- NewData$fit - 1.96 * NewData$SE

ggplot(NewData, aes(x = DiversityD_1, y = fit, group = Treatment)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = Treatment), alpha = 0.3) +
  geom_line(aes(colour = Treatment)) + 
  geom_hline(yintercept = 0)
```

## Код для графика {.smaller}

```{r, m3-viz, eval=FALSE, tidy=TRUE, tidy.opts=list(width=50), purl=FALSE}
```


## Таким образом

1. Модели, основанные на неподходящем типе распределения, могут давать нереалистичные предсказанные значения.
2. В зависимости от того, как сконструирована модель, можно получить результаты, которые позволят сформулировать принципиально разные биологические выводы.

# Выбор оптимальной модели

## Какие факторы определяют супружескую неверность?


```{r}
data(Affairs, package = "AER")
af <- Affairs
```

Оригинальная работа:
Fair, R.C. (1978). A Theory of Extramarital Affairs. Journal of Political Economy, 86, 45–61.

<div class="columns-2">
`affairs` - Количество внебрачных свзяей за последний год   
`gender` - пол   
`age` - возраст  
`yearsmarried` - сколько ле в браке   
`children` - наличие детей   
`religiousness` - уровеь религиозности   
`education` - уровень образования   
`rating` - самооценка ощущений от брака 

</div>



## Задание 4

1. Постройте оптимальную модель, описывающую зависимость количества внебрачных связей в зависимости от пола, времени, проведенного в браке, наличия детей, уровня религиозности и уровня образованности.  
2. Проверьте валидность данной модели

## Решение {.smaller}

```{r, tidy=TRUE, tidy.opts=list(width = 60), purl=FALSE}
Mod <- glm(affairs ~ gender + yearsmarried + children + religiousness + education, data = af, family = "poisson")
# Результаты
summary(Mod)
```

## Проверка на избыточность дисперсии

```{r purl=FALSE}
# Проверка на избыточность дисперсии
pear_res <- resid(Mod, type = "pearson") # Пирсоновские остатки
p <- length(coef(Mod))                   # число параметров в модели  
N <- nrow(model.frame(Mod)) # объем выборки
df <- N - p       # число степеней свободы
Overdisp <- sum(pear_res^2) / df

Overdisp
```

## Можно построить квази-пуассоновскую модель {.smaller}

Это грубое приближение

```{r, tidy=TRUE, tidy.opts=list(width = 60),purl=FALSE}
Mod1 <- glm(affairs ~ gender + yearsmarried + children + religiousness + education, data = af, family = "quasipoisson")
# Результаты
summary(Mod1)
```

## Строим модель, основанную на отрицательном биномиальном распределении {.smaller}

```{r, tidy=TRUE, tidy.opts=list(width = 60), purl=FALSE}
Mod_nb <- glm.nb(affairs ~ gender + yearsmarried + children + religiousness + education, data = af)
Anova(Mod_nb)
```


## Подбираем оптимальную модель {.smaller}

```{r, eval=FALSE, purl=FALSE}
Mod_nb_final <- step(Mod_nb, direction = "backward", trace = 0)
summary(Mod_nb_final)
```

## Диагностика модели

```{r, warning=FALSE, message=FALSE, purl=FALSE}
Mod_nb_diag <- data.frame(
  af,
  .fitted = predict(Mod_nb_final), 
  .pears_resid = residuals(Mod_nb, type = "pearson"))

ggplot(Mod_nb_diag, aes(x = .fitted, y = .pears_resid)) + geom_point() +
  geom_smooth(se = FALSE)
```

## Графики остатков от предикторов в модели и нет

```{r, warning=FALSE, message=FALSE, purl=FALSE}
gg_res <- ggplot(Mod_nb_diag, aes(y = .pears_resid))
grid.arrange(gg_res + geom_point(aes(x = yearsmarried)),
             gg_res + geom_point(aes(x = religiousness)),
             gg_res + geom_point(aes(x = gender)),
             gg_res + geom_point(aes(x = children)),
             gg_res + geom_point(aes(x = education)),
             gg_res + geom_point(aes(x = occupation)),
             gg_res + geom_point(aes(x = education)),
             nrow = 3)
```

## Проверим на избыточность дисперсии

```{r, purl=FALSE}
# Проверка на избыточность дисперсии
pear_res <- resid(Mod_nb_final, type = "pearson") # Пирсоновские остатки
p <- length(coef(Mod_nb_final)) + 1               # число параметров в модели  
N <- nrow(model.frame(Mod_nb_final)) # объем выборки
df <- N - p       # число степеней свободы
Overdisp <- sum(pear_res^2) / df

Overdisp
```



## Визуализируем предсказание модели

```{r af-viz, echo=FALSE, fig.height=5}
NewData <- expand.grid(
  yearsmarried = seq(min(af$yearsmarried), max(af$yearsmarried)), 
  religiousness = seq(min(af$religiousness), max(af$religiousness), length.out = 3))

# предсказанные значения
Predictions <- predict(Mod_nb_final, newdata = NewData, se.fit = TRUE, type = "response")
NewData$fit <- Predictions$fit
# стандартные ошибки
NewData$SE <- Predictions$se.fit
# доверительный интервал
NewData$upr <- NewData$fit + 1.96 * NewData$SE
NewData$lwr <- NewData$fit - 1.96 * NewData$SE
# график предсказаний модели
ggplot(NewData, aes(x = yearsmarried, y = fit, group = religiousness)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = religiousness), alpha = 0.2) +
  geom_line(aes(colour = religiousness), size = 1.5) + 
  geom_hline(yintercept = 0) +
  scale_color_gradient(low = "yellow2", high = "red") + 
  scale_fill_gradient(low = "yellow2", high = "red")
```

## Код для графика {.smaller}

```{r af-viz, eval=FALSE, tidy=TRUE, tidy.opts=list(width = 50)}
```


## Summary

>- В случае счетных зависимых перменных (неотрицательных целочисленных величин) применяются модели, основанные на распределении Пуассона или отрицательном биномиальном распределении.   
>- Важным ограничением применения этих моделей является отсутствие избыточности дисперсии.  
>- Избыточность дисперсии может быть истинной и мнимой.   
>- При истинной избыточности дисперсии модель можно скорректировать, поcтроив квази-пуассоновскую модель (вводятся поправки для ошибок оценок коэффициентов модели).
>- Другой подход --- построение моделей, основанных на отрицательном биномиальном распределении. 

## Что почитать
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014.
+ Zuur, A.F. et al. 2009. Mixed effects models and extensions in ecology with R. Statistics for biology and health. Springer, New York, NY. 


