# Качество шоколадных кексов #############################

# Провели эксперимент, чтобы определить, от чего
# зависит качество шоколадных кексов, выпекаемых
# по одному из трех рецептов.
# По каждому из трех рецепто вначале приготовили
# 15 независимых замесов теста (батчей), достаточных для
# приготовления 6 кексов.
# Каждый из 6 кексов из соответствующего
# замеса выпекали при разной температуре.

# Качество кексов оценивали по углу при котором кекс разламывается.

# От чего зависит качество кексов?

# Данные исходно из книги Cochran W. and Cox G.
# (1992) Experimental Designs, 2nd Edition Wiley
# Мы их возьмем из пакета faraway  --- Faraway J.
# (2016). faraway: Functions and Datasets for
# Books by Julian Faraway. R package version
# 1.0.7.

# Переменные:
# `recipe` - Рецепт
# `batch` - замес теста
# `temp` - Температура выпекания кекса, градусы Цельсия
# `breakang` - Угол разлома

## Задание -------------------------------------

# Постройте модель, предсказывающую угол
# разламывания кексов,в зависимости от рецепта и
# температуры выпекания с учетом эффекта
# замеса теста.
# Проверьте валидность данной модели.
# Нарисуйте график предсказаний модели.
# Протестируйте значимость влияния предикторов.
# Запишите уравнение модели

library(faraway)
data("choccake")

library(lme4)
library(car)
library(ggplot2)
library(cowplot)
theme_set(theme_bw())

# Знакомство с данными ###########################

head(choccake)
str(choccake)

colSums(is.na(choccake))

# Температура выпекания кексов
unique(choccake$temp)

# По каждому рецепту 15 замесов, из каждого замеса 6 кексов
with(choccake, table(recipe, batch))
# Вот они
with(choccake, table(temp, batch, recipe))

# ВНИМАНИЕ, это важно! --------------------------

# Видно, что батчи называются одинаково для каждого рецепта.
# Но мы знаем, что батч №1 по первому рецепту, это не то же самое что батч №1 по второму рецепту. Т.е. у нас не 15 батчей всего, а целых 45!
# Поэтому нужно перекодировать batch. Сделать так, чтобы каждый конкретный батч имел свое собственное имя.
choccake$batch_ID <- paste('R', choccake$recipe, 'B', choccake$batch, sep = '_')

# Три рецепта, мы хотим получить групповые предсказания.
# Линии для трех рецептов могут быть параллельны друг другу или нет.
# Возможные модели для фиксированной части
# breakang ~ recipe + temp
# breakang ~ recipe * temp
ggplot(data = choccake, aes(x = temp, y = breakang)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  facet_wrap(~ recipe)

# Но мы должны учесть эффект замеса!

# Вот как выглядят данные с учетом замеса.
ggplot(data = choccake, aes(x = temp, y = breakang, colour = batch_ID)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  facet_wrap(~ recipe)

# Видно, что поведение кексов варьирует между 15 замесами для каждого рецепта.
# Мы не можем игнорировать этот эффект:
# breakang ~ recipe + temp + (1 | batch_ID)
# breakang ~ recipe * temp + (1 | batch_ID)

# Видно, что прямые непараллельны.
# Но мы не сможем подобрать такие модели:
# breakang ~ recipe + temp (1 + temp | batch_ID)
# breakang ~ recipe * temp + (1 + temp| batch_ID)
# Т.к. для каждого рецепта свой набор батчей.

# Итог: Две возможные модели.

# Нет ли коллинеарности?
vif(lm(breakang ~ recipe + temp, data = choccake))

# Модель со случайным интерсептом ################

# Нас интересует, как влияет рецепт и температура на качество выпекания
# Но мы не можем игнорировать замес

# Возможные модели:
# (mod1) - модель без взаимодействия, batch_ID - случайный эффект
# Моделируем параллельные прямые для зависимости breakang ~ temp
mod1 <- lmer(breakang ~ recipe + temp + (1 | batch_ID), data = choccake)
mod1
# ВНИМАНИЕ: groups:  batch_ID, 45
# Это правильно!

# (wrong1) - модель без взаимодействия, batch - случайный эффект
# Если бы мы не дали batch уникальные названия, то была бы подобрана неправильная модель
wrong1 <- lmer(breakang ~ recipe + temp + (1 | batch), data = choccake)
wrong1
# ВНИМАНИЕ: groups:  batch, 15
# Это неправильно!

# (mod2) - модель со взаимодействием, batch_ID - случайный эффект
mod2 <- lmer(breakang ~ recipe * temp + (1 | batch_ID), data = choccake)


# Адекватна ли модель? Диагностика полной модели #######

mod2_diag <- fortify(mod2)
head(mod2_diag)
ggplot(mod2_diag, aes(x = .fitted, y = .scresid)) + geom_point() + geom_smooth(method = 'loess')
# ОК

# Остатки от переменных в модели
# Рецепт
ggplot(mod2_diag, aes(x = recipe, y = .scresid)) + geom_boxplot()
# Температура.
ggplot(mod2_diag, aes(x = temp, y = .scresid)) + geom_point()
# Лучше температура, как фактор
ggplot(mod2_diag, aes(x = factor(temp), y = .scresid)) + geom_boxplot()

# Упрощение модели ##################################

# Можно оставить как есть и интерпретировать результаты.
# А можно попытаться сократить модель.
# Есть два альтернативных подхода к упрощению модели:
# (A) - тесты
# (Б) - информационные критерии


# (А) - Упрощение при помощи LRT ------------------------

# (ай-ай, множественное тестирование гипотез, но здесь это не страшно)
# Для начала нужно понять, значимо ли взаимодействие,
# или его можно удалить из модели.

# ВНИМАНИЕ:
# Для тестирования значимости фиксированных эффектов нужно, чтобы модели были подобраны ML
# Нынешняя версия anova.merMod() сама об этом позаботится. Все переподберет с помощью ML

# ?anova.merMod
anova(mod1, mod2, test = 'Chi')

# Взаимодействие не значимо. Дальше будем работать без него.

# (Б) - Упрощение при помощи AIC -----------------------

# Модель без взаимодействие лучше по AIC
AIC(mod1, mod2)

# Диагностика модели без взаимодействия ##############

mod1_diag <- fortify(mod1)
head(mod1_diag)
ggplot(mod1_diag, aes(x = .fitted, y = .scresid)) + geom_point() + geom_smooth(method = 'loess')
# ОК

# Остатки от переменных в модели
# Рецепт
ggplot(mod1_diag, aes(x = recipe, y = .scresid)) + geom_boxplot()
# Температура.
ggplot(mod1_diag, aes(x = factor(temp), y = .scresid)) + geom_boxplot()

# Тестирование гипотез ################################

# LRT для фиксированных эффектов ---------------------

# Не будем делать вручную при помощи anova(), а сделаем drop1()
drop1(mod1, test = 'Chi')
# Температура влияет, рецепт - нет.

# LRT для случайных эффектов (не надо так делать бездумно) ---------

# Эффект замеса - данность, с ним придется жить.
# Его значимость проверить возможно, но лучше так
# не делать, если это часть дизайна эксперимента.

# Вот, что пишет Бен Болкер по этому поводу:
# "Consider not testing the significance of random
# effects. If the random effect is part of the
# experimental design, this procedure may be
# considered ‘sacrificial pseudoreplication’
# (Hurlbert 1984)."
# https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects

# Но если мы-таки решили тестировать значимость
# случайных эффектов, то можно это сделать так.
# В этом примере нам нужно сравнить модель со
# случайным эффектом и без него. Модель без
# случайного эффекта не подобрать REML (метод не
# реализован). Поэтому придется сравнивать две модели, подобранные ML

mod1_ml <- lmer(breakang ~ recipe + temp + (1 | batch_ID), data = choccake, REML = FALSE)
mod1_fix_ml <- glm(breakang ~ recipe + temp, data = choccake)

anova(mod1_ml, mod1_fix_ml, test = 'Chi')
# От выбрасывания случайного эффекта модель ухудшается


# Коэффициент внутриклассовой корреляции ----------------

# Мы можем оценить силу случайного эффекта при помощи
# коэффициента внутриклассовой корреляции.

VarCorr(mod1)

# Groups   Name        Std.Dev.
# batch_ID (Intercept) 6.4651
# Residual             4.5505

# Очень сильная внутриклассовая корреляция.
# Такой случайный эффект нельзя игнорировать.
6.4651^2 / (6.4651^2 + 4.5505^2)


# Для самостоятельной проработки: ####################

# Уравнение модели -----------------------------------

# График модели --------------------------------------

# Бутстреп - для сильных духом ########################

