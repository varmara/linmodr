---
title: "Сравнение линейных моделей"
author: Марина Варфоломеева, Вадим Хайтов
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

## Мы рассмотрим

- Вложенные модели
- Тестирование значимости отдельных предикторов при помощи частного F-критерия
- Принципы отбора моделей
- Упрощение моделей


### Вы сможете

- Определять, какие модели являются вложенными
- Сравнивать вложенные модели при помощи частного F-критерия
- Объяснить связь между качеством описания существующих данных и краткостью модели
- Объяснить, что такое "переобучение" модели
- Упростить линейную модель при  помощи частного F-критерия, следуя обратному пошаговому алгоритму


```{r, echo=FALSE, message=FALSE, purl=FALSE}
library(ggplot2)
theme_set(theme_bw())
library(gridExtra)
```

# Модель множественной линейной регрессии с прошлой лекции

## Пример: птицы в лесах Австралии

От каких характеристик лесного участка зависит обилие птиц в лесах юго-западной Виктории, Австралия (Loyn, 1987)

Переменных много, мы хотим из них выбрать __оптимальный небольшой__ набор.

<div class="columns-2">

![forest in Victoria, Australia](images/vict_m.jpg)
<small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small>



56 лесных участков:

- ABUND - обилие птиц
- AREA - площадь участка
- YRISOL - год изоляции участка
- DIST - расстояние до ближайшего леса
- LDIST - расстояние до ближайшего большого леса
- GRAZE - пастбищная нагрузка (1-5)
- ALT - высота над уровнем моря

</div>

<small>Пример из кн. Quinn, Keugh, 2002, данные из Loyn, 1987)</small>

## Модель из прошлой лекции

```{r}
bird <- read.csv("data/loyn.csv")
bird$logAREA <- log(bird$AREA)
bird$logDIST <- log(bird$DIST)
bird$logLDIST <- log(bird$LDIST)
mod2 <- lm(ABUND ~ logAREA + YRISOL + logDIST + logLDIST + ALT, data = bird)
```

$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

- Проверим еще одним способом, влияют ли предикторы.
- Разберемся, можно ли оптимизировать модель.

# Вложенные модели (nested models)

## Вложенные модели (nested models)

Две модели являются _вложенными_, если одну из них можно получить из другой путем удаления некоторых предикторов.   

Удаление предиктора  - коэффициент при данном предикторе равен нулю. 

### Полная модель (full model)

М1: $y _i = b _0 + b _1 x _{1i} + b _2 x _{2i} + e _i$

### Неполные модели (reduced models)

М2: $y _i = b _0 + b _1 x _{1i} + e _i$   

М3: $y _i = b _0 + b _2 x _{2i} + e _i$

M2 вложена в M1   
M3 вложена в M1   
M2 и M3 не вложены друг в друга

### Нулевая модель (null model), вложена в полную (M1) и в неполные (M2, M3)

$y _i = b _0 + e _i$

## Задание

Для тренировки запишем вложенные модели для данной полной модели

(1)$y _i = b _0 + b _1 x _{1i} + b _2 x _{2i} + b _3 x _{3i} + e _i$

## Решение

Для тренировки запишем вложенные модели для данной полной модели

(1)$y _i = b _0 + b _1 x _{1i} + b _2 x _{2i} + b _3 x _{3i} + e _i$

<div class="columns-2">

Модели:

- (2)$y _i = b _0 + b _1 x _{1i} + b _2 x _{2i} + e _i$
- (3)$y _i = b _0 + b _1 x _{1i} + b _3 x _{3i} + e _i$
- (4)$y _i = b _0 + b _2 x _{2i} + b _3 x _{3i} + e _i$
- (5)$y _i = b _0 + b _1 x _{1i} + e _i$
- (6)$y _i = b _0 + b _2 x _{2i} + e _i$
- (7)$y _i = b _0 + b _3 x _{3i} + e _i$
- (8)$y _i = b _0 + e _i$<br /><br />

Вложенность:

- (2)-(4)- вложены в (1)<br /><br /><br />
- (5)-(7)- вложены в (1), при этом 
   - (5)вложена в (1), (2), (3); 
   - (6)вложена в (1), (2), (4); 
   - (7)вложена в (1), (3), (4)<br /><br />
- (8)- нулевая модель - вложена во все

</div>

# Частный F-критерий

## Сравнение вложенных линейных моделей при помощи F-критерия

### Полная модель (со всеми предикторами)

$y _i = b _0 + b _1 x _{1i} + \ldots + b _k x _{ki} + b _{l} x _{li} + e _i$

$SS_{r, full}$, $df _{r, full} = p - 1$

$SS_{e, full}$, $df _{e, full} = n - p$

\column{0.50\textwidth}

### Уменьшенная модель с $(p - 1)$ параметрами (например, без предиктора $b _{l} x _{li}$)

$y _i = b _0 + b _1 x _{1i} + \ldots + b _k x _{ki} + e _i$  

$SS_{r, reduced}$, $df _{r, reduced} = (p - 1) - 1$

$SS _{e, reduced}$, $df _{e, reduced} = n - (p - 1)$


## Полная модель всегда будет лучше

$SS_{r, full} > SS _{r, reduced}$

или то же самое:

$SS_{e, full} < SS _{e, reduced}$


<br/>

Можно оценить, насколько именно полная модель лучше уменьшенной

(= или насколько уменьшенная модель хуже полной).

## Частный F-критерий оценивает разницу объясненной дисперсии между моделями


$$F = \frac {(SS_{e, reduced} - SS _{e, full})/(df _{e, reduced} - df _{e, full})}{SS _{e, full} / df _{e, full}}$$

__Если модель значимо ухудшается от удаления предиктора, то влияние этого предиктора значимо.__


## Краткое обозначение частного F-критерия

Чтобы проверить значимость предиктора `ALT`, нам нужно сравнить две модели

`ABUND ~ logAREA + YRISOL + logDIST + logLDIST + ALT`  
`ABUND ~ logAREA + YRISOL + logDIST + logLDIST`

Это можно обозначить 

$F_{(\text{ALT | logAREA, YRISOL, logDIST, logLDIST})}$

А разницу остаточных сумм квадратов $SS_{e, reduced} - SS _{e, full}$, которую мы тестируем, можно обозначить

$SS_{(\text{ALT | logAREA, YRISOL, logDIST, logLDIST})}$

## Частный F-критерий в R `anova(модель_1, модель_2)`

Если высота над уровнем моря входит в модель после учета влияния остальных предикторов, то его влияние не значимо ($F = 1.84$, $p = 0.18$).

$F_{(\text{ALT | logAREA, YRISOL, logDIST, logLDIST})}$

```{r}
mod2_reduced <- update(mod2, . ~ . - ALT)
anova(mod2_reduced, mod2)
```

## Результаты F- и t-тестов эквивалентны

$t^2 = F$

$t^2$ равен значению частной F-статистики для этого фактора, __когда он входит в модель последним__.

```{r}
F_val <- anova(mod2, mod2_reduced)[2, 'F']
F_val
t_val <- coef(summary(mod2))['ALT', 't value']
t_val^2
```


## Характер влияния предиктора зависит от состава модели (и значит зависит от порядка тестирования)

Если высота над уровнем моря --- единственный предиктор в модели, то его влияние статистически значимо ($F = 9.45$, $p < 0.05$)

$F_{(\text{ALT})}$

```{r}
mod_ALT1 <- lm(ABUND ~ ALT, data = bird)
mod_null <- lm(ABUND ~ 1, data = bird)
anova(mod_null, mod_ALT1)
```

# I и II типы сумм квадратов

## Порядок проведения сравнений при F-тестах (типы сумм квадратов)

`Y ~ A + B + C`

<div class="columns-2">

### I тип сумм квадратов (SS type I)

Последовательно вычисляем вклады предикторов при условии, что все предыдущие включены в модель

- $SS_{A}$
- $SS_{B|A}$
- $SS_{C|A, B}$

### II тип сумм квадратов (SS type II)

Поочередно вычисляем вклад каждого предиктора при условии, что все остальные включены в модель

- $SS_{A|B, C}$
- $SS_{B|A, C}$
- $SS_{C|A, B}$

</div>

## Последовательное тестирование `anova(модель)`

```{r}
anova(mod2)
```

## Осторожно, при последовательном тестировании результат зависит от порядка предикторов

Если мы поставим `ALT` первым, то изменится SS для других предикторов, а влияние самого `ALT` станет значимым (т.к. оно оценено без учета других предикторов).

```{r}
mod2_reordered <- lm(ABUND ~ ALT + logAREA + YRISOL + logDIST + logLDIST, 
                     data = bird)
anova(mod2_reordered)
```

## Поочередное тестирование `Anova(модель)` или `drop1()`

```{r}
library(car)
Anova(mod2)
# drop1(mod2, test = 'F')
```

## При поочередном тестировании результат НЕ зависит от порядка предикторов

```{r}
Anova(mod2_reordered)
```

## Есть и другое применение F-теста

F-тест, который мы только что рассмотрели, можно использовать не только для сравнения моделей и тестирования значимости отдельных предикторов. 

```{r}
Anova(mod2)
```

Не все предикторы влияют. Может, попытаться упростить модель?


# Принципы выбора лучшей линейной модели

"Essentially, all models are wrong,  
but some are useful"  
Georg E. P. Box


## Важно не только тестирование гипотез, но и построение моделей

- Проверка соответствия наблюдаемых данных предполагаемой связи между зависимой перменной и предикторами:
    - оценки параметров,
    - __тестирование гипотез__,
    - оценка объясненной изменчивости ($R^2$),
    - анализ остатков 

- __Построение моделей__ для предсказания значений в новых условиях:
    - Выбор оптимальной модели
    - Оценка предсказательной способности модели **на новых данных**

```{r echo=FALSE, purl=FALSE}
library(tidyr)
library(dplyr)

n <- 40
max_span <- 0.8
my_spans <- c(0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2)
sd_e <- 1.8

# Training set -----------------------------------
set.seed(199)
data_training <- data.frame(x = runif(n, 1, 10)) %>%
  mutate(y = 2*sin(x) + 1 * x  + rnorm(n, 0, 0.9)) %>%
  crossing(span = my_spans) %>%
  group_by(span) %>%
  nest(x, y, .key = "data")

# Trained models
mod_training <- data_training %>%
  mutate(model = purrr::map2(data, span, ~ loess(y ~ x, data = .x, span = .y)))

# Predictions on the training set
pred_training <- mod_training %>%
  mutate(pred = purrr::map2(model, data, ~ predict(.x, newdata = .y))) %>%
  unnest(data, pred, .id = "span") %>%
  mutate(span = factor(span, labels = sort(my_spans, decreasing = TRUE), levels = sort(my_spans, decreasing = TRUE)))
# MSE training
MSe_training <- pred_training %>%
  group_by(span) %>%
  summarise(training = mean(y - pred)^2)

# Testing set ------------------------------------
set.seed(12312)
data_testing <- data.frame(x = runif(n, 1, 10)) %>%
  mutate(y = 2 * sin(x) + 1 * x  + rnorm(n, 0, sd_e)) %>%
  crossing(span = my_spans) %>%
  group_by(span) %>%
  nest(x, y, .key = "data")
# The same model
data_testing$model <- mod_training$model
# Predictions on the testing set
pred_testing <- data_testing %>%
  mutate(pred = purrr::map2(model, data, ~ predict(.x, newdata = .y))) %>%
  unnest(data, pred, .id = "span") %>%
  mutate(span = factor(span, labels = sort(my_spans, decreasing = TRUE), levels = sort(my_spans, decreasing = TRUE)))
  # MSE testing
MSe_testing <- pred_testing %>% group_by(span) %>%
  summarise(testing = mean(y - pred, na.rm = TRUE)^2)

# All predictions of the smoothers ---------------
data_all <- data.frame(x = seq(1, 10, length.out = 400)) %>%
  crossing(span = my_spans) %>%
  group_by(span) %>%
  nest(x, .key = "data")
# The same model
data_all$model <- mod_training$model
# Predictions on an artificial grid for plotting
pred_all <- data_all %>%
  mutate(pred = purrr::map2(model, data, ~ predict(.x, newdata = .y))) %>%
  unnest(data, pred, .id = "span") %>%
  mutate(span = factor(span, labels = sort(my_spans, decreasing = TRUE), levels = sort(my_spans, decreasing = TRUE)))

# Plot of predictions -----------------------
gg_dat <- ggplot(pred_all, aes(x = x, y = pred, colour = span, group = span)) +
  geom_point(data = pred_training, aes(x = x, y = y), colour = "black", shape = 19) +
  # geom_point(data = pred_testing, aes(x = x, y = y), colour = "black", shape = 21) +
  # geom_line(size = 1) +
  # facet_wrap(~as.factor(span), nrow = 2) +
  labs(colour = "Сложность\nмодели", y = "y") +
  theme(legend.position = "bottom")

# Plot of predictions with training set -------
gg_train <- ggplot(pred_all, aes(x = x, y = pred, colour = span, group = span)) +
  geom_point(data = pred_training, aes(x = x, y = y), colour = "black", shape = 19) +
  geom_line(size = 1) +
  facet_wrap(~as.factor(span), nrow = 2) +
  labs(colour = "Сложность\nмодели", y = "y") +
  theme(legend.position = "bottom")


# Plot of predictions with training and testing sets -------
gg_pred <- ggplot(pred_all, aes(x = x, y = pred, colour = span, group = span)) +
  geom_point(data = pred_training, aes(x = x, y = y, shape = "использованные в модели"), colour = "black") +
  geom_point(data = pred_testing, aes(x = x, y = y, shape = "новые"), colour = "black") +
  geom_line(size = 1) +
  facet_wrap(~as.factor(span), nrow = 2) +
  scale_shape_manual(values = c(19, 21), guide = FALSE) +
  labs(colour = "Сложность\nмодели", y = "y", shape = "Данные") +
  theme(legend.position = "bottom")

# Plot of training and testing MSe -----
dat_mse <- merge(MSe_training, MSe_testing) %>% gather(Data, MSe, -span) %>%
  mutate(Complexity = factor(span,
                             levels = sort(my_spans, decreasing = TRUE),
                             labels = sort(my_spans, decreasing = TRUE)),
         Data = factor(Data,
                levels = c("training", "testing"), 
                labels = c("испольованные в модели",
                           "новые")))
gg_mse <- ggplot(dat_mse, aes(x = Complexity, y = MSe, group = Data)) +
  geom_line() +
  geom_point(aes(shape = Data), size = 3) +
  scale_shape_manual(values = c(19, 21), guide = guide_legend(nrow = 2)) +
  labs(x = "Сложность модели", y = "Ошибка предсказаний", shape = "Данные") +
  theme(legend.position = "bottom")

grid.arrange(
  gg_pred, 
  gg_mse, 
  nrow = 1, widths = c(0.6, 0.4))
```

## Зачем может понадобится упрощать модель?

### Какую модель можно подобрать для описания этой закономерности?


```{r, echo=FALSE, fig.height=3, fig.width=5, purl=FALSE}
gg_dat
```

>- Эти данные можно смоделировать очень разными способами. Мы попробуем посмотреть, как это будет выглядеть на примере loess--- локальной полиномиальной регрессии. (Если интересно, [подробнее о loess-регрессии](https://www.mathworks.com/help/curvefit/smoothing-data.html#bq_6ys3-4))

## Какая из этих моделей лучше описывает данные? {.smaller}

На этих графиках показаны предсказания loess-регрессии для одних и тех же исходных данных.

Cложность модели --- в общем случае, это число параметров. Для loess-регрессии сложность модели отражает степень сглаживания: у более сложных моделей маленькая степень сглаживания. 

```{r models-no-labs, echo=FALSE, fig.height=4, fig.width=10, purl=FALSE}
gg_train
```

- Простые модели недообучены (underfitted) --- слишком мало параметров, предсказания неточны.   
- Сложные модели переобучены (overfitted) --- слишком много параметров, предсказывают еще и случайный шум.

## Что будет, если получить предсказания моделей на новых данных? {.smaller}

```{r echo=FALSE, purl=FALSE, message=FALSE, warining=FALSE, fig.width=10, fig.height=4}
gg_pred + scale_shape_manual(values = c(19, 21), guide = guide_legend(nrow = 2))
```

На новых данных предсказания моделей не будут идеальными.


## Как при усложнении модели меняется качество предсказаний? {.smaller}

```{r echo=FALSE, purl=FALSE, fig.width=10, fig.height=3.5}
grid.arrange(
  gg_pred, 
  gg_mse, 
  nrow = 1, widths = c(0.6, 0.4))
```

Ошибка предсказаний на новых данных практически всегда больше, чем на исходных данных. Более сложные модели лучше описывают существующие данные, но на новых данных их предсказания хуже.

Обычно  при усложнении модели:

- ошибки предсказаний на исходных данных убывают (иногда, до какого-то уровня) (L-образная кривая)
- ошибки предсказаний на новых данных убывают, затем возрастают из-за переобучения (U-образная кривая) 

## Погрешность и точность

```{r echo=FALSE, purl=FALSE, fig.height=3.5}
library(ggforce)

n_reps <- 6
set.seed(9328)
dfr <- data.frame(
  x0 = rep(0, 6),
  y0 =  rep(0, 6),
  r = seq(1, 0.1, length.out = 6),
  fl = rep(1:2, 3)
)
dart <- ggplot() + geom_circle(data = dfr, aes(x0 = x0, y0 = y0, r = r, fill = fl)) +
  scale_fill_gradient(low = "#9ecae1", high = "#deebf7", guide = "none") +
  coord_equal() + theme_void() + theme(plot.title = element_text(hjust = 0.5))

HvLb <- dart +
  annotate(geom = "point", size = 3, shape = 21, colour = "black", fill = "orange",
                x = rnorm(n_reps, 0, 0.25), y = rnorm(n_reps, 0, 0.25)) +
  labs(title = "Большая дисперсия, \nмаленькая погрешность")

LvHb <- dart +
  annotate(geom = "point", size = 3, shape = 21, colour = "black", fill = "orange",
                x = rnorm(n_reps, 0, 0.1), y = rnorm(n_reps, 0, 0.1)) +
labs(title = "Маленькая дисперсия, \nмаленькая погрешность")

HvHb <- dart +
  annotate(geom = "point", size = 3, shape = 21, colour = "black", fill = "orange",
                x = rnorm(n_reps, 0.4, 0.25), y = rnorm(n_reps, 0.3, 0.25)) +
labs(title = "Большая дисперсия, \nбольшая погрешность")

LvLb <- dart +
  annotate(geom = "point", size = 3, shape = 21, colour = "black", fill = "orange",
                x = rnorm(n_reps, 0.4, 0.1), y = rnorm(n_reps, 0.3, 0.1)) +
  labs(title = "Маленькая дисперсия, \nбольшая погрешность")

grid.arrange(HvLb, HvHb, LvHb, LvLb, nrow = 2)
```

- Погрешность (accuracy, точность)--- отсутствие погрешности (bias).
- Точность (precision, тоже точность --- другой аспект) --- разброс значений

Предсказания, сделанные на новых данных, будут отличаться от истинных значений не только из-за погрешности или неточности. Еще один источник отличий --- это так называемая неснижаемая ошибка.

## Компромисс между погрешностью и разбросом значений предсказаний (Bias-Variance Tradeoff)

```{r echo=FALSE, purl=FALSE}
ggplot(data = data.frame(x = seq(-2, 2, by = 0.1)), aes(x = x)) +
  stat_function(fun = function(x) (0.5)^x, 
                size = 2, aes(colour = "Погрешность^2")) +
  stat_function(fun = function(x) 2^x, 
                size = 2, aes(colour = "Дисперсия")) +
  stat_function(fun = function(x) 1.5, 
                size = 2, aes(colour = "Неснижаемая ошибка")) +
  stat_function(fun = function(x) (0.5)^x + 2^x + 1.5, 
                size = 2, aes(colour = "Полная ошибка")) +
  scale_colour_manual(values = c("Погрешность^2" = "darkcyan",
                                 "Дисперсия" = "dodgerblue",
                                 "Неснижаемая ошибка" = "pink3",
                                 "Полная ошибка" = "orangered3"),
                      breaks = c("Полная ошибка", "Дисперсия",
                                 "Погрешность^2", "Неснижаемая ошибка")) +
  theme_classic() + theme(axis.text = element_blank())  +
  labs(x = "Сложность модели", y = "Ошибка", colour = "Источник ошибок")
```

$$Полная~ошибка = Дисперсия + (Погрешность)^2 + Неснижаемая~ошибка$$
При увеличении сложности модели снижается погрешность предсказаний, но возрастает их разброс. Поэтому общая ошибка предсказаний велика у недообученных или переобученных моделей, а у моделей средней сложности она будет минимальной.

## Критерии и методы выбора моделей зависят от задачи

__Объяснение закономерностей, описание функциональной зависимости__

- Нужна точность оценки параметров
- Нужны точные тесты влияния предикторов: F-тесты или тесты отношения правдоподобий (likelihood-ratio tests)

__Предсказание значений зависимой переменной__

- Нужна простая модель: "информационные" критерии (АIC, BIC, и т.д.)
- Нужна оценка качества модели на данных, которые не использовались для ее первоначальной подгонки: методы ресамплинга (кросс-валидация, бутстреп)

### Не позволяйте компьютеру думать за вас!

- Хорошая модель должна соответствовать условиям применимости, иначе вы не сможете доверять результатам тестов.

- Другие соображения: разумность, целесообразность модели, простота, ценность выводов, важность предикторов.







# Отбор моделей

## Упрощение линейных моделей при помощи частного F-критерия

Постепенно удаляем предикторы. Модели обязательно должны быть вложенными! *

### Обратный пошаговый алгоритм (backward selection)

>- 1.Подбираем полную модель

>- Повторяем 2-3 для каждого из предикторов:  
- 2.Удаляем один предиктор (строим уменьшенную модель)  
- 3.Тестируем отличие уменьшенной модели от полной

>- 4.Выбираем предиктор для окончательного удаления: это предиктор, удаление которого минимально ухудшает модель. Модель без него будет "полной" для следующего раунда выбора оптимальной модели.  

>- Повторяем 1-4 до тех пор, пока что-то можно удалить.

<hr/>
* --- __Важно!__ Начинать упрощать модель нужно со взаимодействий между предикторами.  Если взаимодействие из модели удалить нельзя, то нельзя удалять и отдельно стоящие предикторы, из которых оно состоит. Но мы поговорим о взаимодействиях позже.

## Влияют ли предикторы? {.smaller}

>- Можем попробовать оптимизировать модель

```{r}
summary(mod2)
```

## Что происходит на каждом шаге обратного пошагового алгоритма?

`anova(модель_1, модель_2)`

Подбираем полную модель, удаляем предикторы по-одному, тестируем ухудшилась ли модель. Для окончательного удаления на этом шаге выбираем предиктор, удаление которого меньше всего ее ухудшает.

```{r eval=FALSE}
mod3 <- update(mod2, . ~ . - logAREA)
anova(mod2, mod3)
mod4 <- update(mod2, . ~ . - YRISOL)
anova(mod2, mod4)
mod5 <- update(mod2, . ~ . - logDIST)
anova(mod2, mod5)
mod6 <- update(mod2, . ~ . - logLDIST)
anova(mod2, mod6)
mod7 <- update(mod2, . ~ . - ALT)
anova(mod2, mod7)
```

>- Но мы пойдем другим путем. Все эти действия может выполнить одна функция `drop1()`

##  Частный F-критерий при помощи `drop1()` (шаг 1)

Тестируем значимость всех предикторов за один раз. Затем выбираем предиктор, удаление которого меньше всего ухудшает модель.

```{r}
drop1(mod2, test = "F")
# Нужно убрать logDIST
```

## Тестируем предикторы (шаг 2)

Удаляем выбранный предиктор и повторяем тесты снова. И т.д.

```{r}
# Убрали logDIST
mod3 <- update(mod2, . ~ . - logDIST)
drop1(mod3, test = "F")
# Нужно убрать logLDIST 
```

## Тестируем предикторы (шаг 3)

```{r purl=FALSE}
# Убрали logLDIST 
mod4 <- update(mod3, . ~ . - logLDIST )
drop1(mod4, test = "F")
# Нужно убрать ALT
```

## Тестируем предикторы (шаг 4)

```{r purl=FALSE}
# Убрали ALT
mod5 <- update(mod4, . ~ . - ALT)
drop1(mod5, test = "F")
# Больше ничего не убрать
```

## Итоговая модель

```{r}
summary(mod5)
```

## Задание

Проверьте финальную модель на выполнение условий применимости. Дополните код

```{r eval=FALSE, purl=TRUE}
library()
mod_diag <- data.frame(fortify(), bird[, c()])
# 1) График расстояния Кука
ggplot(data = , aes(x = 1:, y = .cooksd)) + geom_bar(stat = "")
# 2) График остатков от предсказанных значений
gg_resid <- ggplot(data = , aes(x = , y = )) + geom_point() + geom_hline()
gg_resid
# 3) Графики остатков от предикторов в модели и нет
res_1 <- gg_resid + aes(x = logAREA)
res_1
res_2 <- gg_resid
res_3 <- gg_resid
res_4 <- gg_resid
res_5 <- gg_resid
res_6 <- gg_resid
# все графики вместе
library()
grid.arrange(res_1, res_2, nrow = 2)
# 4) Квантильный график остатков
library()
qq
```

## Решение

### 1) График расстояния Кука 

- Выбросов нет

```{r solution-0a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
mod5_diag <- data.frame(
  fortify(mod5), 
  bird[, c("logDIST", "logLDIST", "GRAZE", "ALT")]
  )

ggplot(mod5_diag, aes(x = 1:nrow(mod5_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

## Решение

### 2) График остатков от предсказанных значений

- Выбросов нет
- Гетерогенность дисперсии?
- Два наблюдения с очень большими предсказанными значениями и большими остатками. Хорошо бы проверить их.

```{r solution-1a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
gg_resid <- ggplot(data = mod5_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid
```


## Решение

### 3) Графики остатков от предикторов в модели и нет

- Величина остатков зависит от уровня выпаса скота. Возможно, не стоило удалять эту переменную
- Есть наблюдения с экстремальными значениями предикторов (два больших леса, один далекий, один высокогорный).  Хорошо бы проверить их.

```{r solution-2a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=5, echo=FALSE}
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid + aes(x = YRISOL)
res_3 <- gg_resid + aes(x = logDIST)
res_4 <- gg_resid + aes(x = logLDIST)
res_5 <- gg_resid + aes(x = ALT)
res_6 <- gg_resid + aes(x = GRAZE)

library(gridExtra)
grid.arrange(res_1, res_2, res_3, res_4,
             res_5, res_6, nrow = 2)
```

## Решение

### 3) Код для графиков остатков от предикторов в модели и нет

```{r solution-2a, fig.show='hide', purl=FALSE, echo=TRUE}
```

## Решение

### 4) Квантильный график остатков

- Отклонения от нормального распределения остатков незначительны

```{r solution-3a, purl=FALSE, fig.width=4, fig.height=4, message=FALSE}
library(car)
qqPlot(mod5)
```


## Описываем финальную модель

```{r}
summary(mod5)
```

## График предсказаний модели: один предиктор

$$\widehat{ABUND}_i = -252.20 + 3.73 \cdot logAREA_i + 0.14 \cdot YRISOL_i$$

```{r gg-predict-one, echo=FALSE, purl=FALSE}
# Искуственный датафрейм для предсказаний
MyData1 <- data.frame(
  logAREA = seq(min(bird$logAREA), max(bird$logAREA), length.out = 100),
  YRISOL = mean(bird$YRISOL))
# Предсказанные значения
Predictions1 <- predict(mod5, newdata = MyData1,  interval = 'confidence')
MyData1 <- data.frame(MyData1, Predictions1)
# Обратная трансформация предиктора, который будем изображать
MyData1$AREA <- exp(MyData1$logAREA)
# График предсказаний модели
Pl_predict1 <- ggplot(MyData1, aes(x = AREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line()
Pl_predict1
```

## Задание:

Постройте график предсказаний модели. Отобразите, как меняются значения зависимой переменной в зависимости от значений одного из предикторов, при условии, что другие предикторы принимают свои средние значения. Дополните этот код:

```{r eval=FALSE}
# Искуственный датафрейм для предсказаний
MyData1 <- data.(
   = seq(min(   ), max(   ),    ),
  YRISOL = )
# Предсказанные значения
Predictions1 <- predict(   , newdata = ,  interval =    )
MyData1 <- data.frame(MyData1,    )
# Обратная трансформация предиктора, который будем изображать
MyData1$AREA <- 
# График предсказаний модели
Pl_predict1 <- ggplot(   , aes(x = AREA, y = )) +
  geom_   (alpha = 0.2, aes(ymin = , ymax = )) +
  geom_   ()
Pl_predict1
```


## Код для графика предсказаний модели: один предиктор

$$\widehat{ABUND}_i = -252.20 + 3.73 \cdot logAREA_i + 0.14 \cdot YRISOL_i$$

```{r gg-predict-one, eval=FALSE, echo=TRUE, purl=FALSE}
```


## График предсказаний модели: два предиктора

$$\widehat{ABUND}_i = -252.20 + 3.73 \cdot logAREA_i + 0.14 \cdot YRISOL_i$$

```{r gg-predict-two, echo=FALSE, purl=FALSE}
# Искуственный датафрейм для предсказаний
MyData2 <- expand.grid(
  logAREA = seq(min(bird$logAREA), max(bird$logAREA), length.out = 100),
  YRISOL = round(quantile(bird$YRISOL)))
# Предсказанные значения
Predictions2 <- predict(mod5, newdata = MyData2,  interval = 'confidence')
MyData2 <- data.frame(MyData2, Predictions2)
# Обратная трансформация предиктора, который будем изображать
MyData2$AREA <- exp(MyData2$logAREA)
# Делаем год фактором
MyData2$YRISOL <- factor(MyData2$YRISOL)
# График предсказаний модели
Pl_predict2 <- ggplot(MyData2, aes(x = AREA, y = fit, group = YRISOL)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line(aes(colour = YRISOL)) +
  scale_colour_brewer(palette = 'Spectral')
Pl_predict2
```

## Код для графика предсказаний модели: два предиктора

$$\widehat{ABUND}_i = -252.20 + 3.73 \cdot logAREA_i + 0.14 \cdot YRISOL_i$$

```{r gg-predict-two, eval=FALSE, echo=TRUE, purl=TRUE}
```


## Недостатки этой модели

$$\widehat{ABUND}_i = -252.20 + 3.73 \cdot logAREA_i + 0.14 \cdot YRISOL_i$$

```{r gg-predict-two, echo=FALSE, purl=FALSE}
```

- отрицательные предсказания для очень давно изолированных маленьких лесов (обилие птиц не может быть отрицательным).
- не учтен уровень выпаса скота из-за колинеарности с другими предикторами (но он особенно интересен исследователям и остатки от него зависят).
- в выборке очень мало лесов большой площади --- место, где кривая выходит на плато, плохо поддержано данными.


## Недостатки и ограничения методологии отбора моделей

- Разные способы отбора оптимальной модели могут приводить к разным результатам. Не важно, какой из способов выбрать, но важно сделать это заранее, __до анализа__, чтобы не поддаваться соблазну подгонять результаты.

- При отборе моделей приходится делать множество тестов, поэтому увеличивается риск ошибок I рода (подробнее на занятии про дисперсионный анализ). Чтобы хоть как-то себя обезопасить, лучше не включать в модель все подряд --- только самое необходимое.

- Оптимальную модель лучше применять для тестирования гипотез на независимых данных, иначе получаются заниженные стандартные ошибки и завышенные эффекты. Обычно эту проблему игнорируют, но если у вас есть возможность, лучше сделать хотябы [кросс-валидацию](https://en.wikipedia.org/wiki/Cross-validation_(statistics)).

- Какой-то одной "лучшей" модели, как правило, не существует.



## Take-home messages

- Модели, которые качественно описывают существующие данные включают много параметров, но предсказания с их помощью менее точны из-за переобучения
- Для выбора оптимальной модели используются разные критерии в зависимости от задачи
- Сравнивая модели можно отбраковать переменные, включение которых в модель не улучшает ее
- __Метод сравнения моделей нужно выбрать заранее, еще до анализа__


## Что почитать

+ <span style="color:red">Must read paper!</span> Zuur, A.F. and Ieno, E.N., 2016. A protocol for conducting and presenting results of regression‐type analyses. Methods in Ecology and Evolution, 7(6), pp.636-645.

+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide
