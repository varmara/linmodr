---
title: "Множественная регрессия"
author: Марина Варфоломеева, Вадим Хайтов
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
  beamer_presentation:
    colortheme: beaver
    highlight: tango
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - --latex-engine=xelatex
    - -V fontsize=10pt
    - -V lang=russian
    slide_level: 2
    theme: default
    toc: no
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

## Множественная регрессия



### Вы сможете

+ Подобрать модель множественной линейной регрессии
+ Протестировать ее статистическую значимость и валидность

## Пример: птицы в лесах Австралии

Фрагментация лесных местообитаний - одна из важнейших проблем Австралии.
От каких характеристик лесного участка зависит обилие птиц во фрагментированных лесных массивах? (Loyn, 1987)

<div class="columns-2">

![forest in Victoria, Australia](images/vict_m.jpg)
<small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small>

56 лесных участков:

- ABUND - обилие птиц
- AREA - площадь участка
- YRISOL - год изоляции участка
- DIST - расстояние до ближайшего леса
- LDIST - расстояние до ближайшего большого леса
- GRAZE - пастбищная нагрузка (1-5)
- ALT - высота над уровнем моря

</div>

<small>Пример из кн. Quinn, Keugh, 2002, данные из Loyn, 1987)</small>

## Читаем данные

```{r}
bird <- read.csv("data/loyn.csv")
```
Все ли правильно открылось?

```{r}
str(bird)
```

Есть ли пропущенные значения?

```{r}
colSums(is.na(bird))
```

## Можно ли ответить на вопрос таким методом?

```{r}
cor(bird)
```

Нет

- Обычная корреляция не учитывает, что взаимосвязь между переменными может находиться под контролем других переменных и их взаимодействий.
- Множественные тесты. При тестировании значимости множества коэффициентов корреляции нужно вводить поправку для уровня значимости. Лучше было бы учесть все в одном анализе.

## Нам предстоит построить модель множественной линейной регрессии

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + e_i$$

- $y_i$ --- значение зависимой переменной для $i$-того наблюдения
- $b_0$ --- свободный член (intercept). Значение $y$ при $x_1 = x_2 = x_3= \ldots = x_{p - 1} = 0$
- $b_1$ --- частный угловой коэффициент для зависимости $y$ от $x_1$. Показывает, на сколько единиц изменяется $y$ при изменении $x_1$ на одну единицу и при условии, что все остальные предикторы не изменяются
$b_2$, $b_3$, ...., $b_{p - 1}$ --- аналогично
- $e_i$ --- варьирование $y$, не объясненное данной моделью
- $p$ --- число параметров модели


## Геометрическая интерпретация множественной линейной модели 

### Для случая с одним предиктором $y_i = b_0 + b_1x_{1i} + e_i$ --- линия регрессии

```{r, echo=FALSE, purl=FALSE}
library(ggplot2)
dfr <- data.frame(x1 = runif(25, 0, 10))
dfr$y1 <- 5 + 5 * dfr$x1 + rnorm(25, 0, 5)
ggplot(data = dfr, aes(x = x1, y = y1)) + geom_point() + geom_smooth(method = "lm") + ylab("y")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с двумя предикторами $y_i = b_0 + b_1x_{1i} + b_2x_{2i} + e_i$ --- плоскость в трехмерном пространстве

```{r, echo=FALSE, fig.height=5, fig.width=5, purl=FALSE}
library(plot3D)

dfr$x2 <- runif(25, 10, 20)
dfr$y2 <- 5 + 5 * dfr$x1 + 3 * dfr$x2 + rnorm(25, 0, 15)
fit <- lm(y2 ~ x1 + x2, data = dfr)

# predict values on regular xy grid
x1.pred <- seq(0, 10, length.out = 20)
x2.pred <- seq(10, 20, length.out = 20)
xy <- expand.grid(x1 = x1.pred, 
                  x2 = x2.pred)

y2.pred <- matrix(nrow = 20, ncol = 20, 
                  data = predict(fit, newdata = xy, 
                                 interval = "prediction"))

# fitted points for droplines to surface
fitpoints <- predict(fit) 

scatter3D(x = dfr$x1, y = dfr$x2, z = dfr$y2, 
          pch = 18, cex = 1.5,
          theta = 20, phi = 16,
          ticktype = "detailed",
          surf = list(x = x1.pred, y = x2.pred, z = y2.pred,
                      facets = NA, fit = fitpoints),
          xlab = "First predictor X1", ylab = "Second predictor X2",
          zlab = "Response variable",
          main = "")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с большим количеством предикторов 

$$y_i = b_0 + b_1x_{1i} + b_2x_{2i} + b_3x_{3i} + ... + b_{p - 1}x_{p - 1\;i} + e_i$$

Плоскость в n-мерном пространстве, оси которого образованы значениями предикторов


## Знакомство с данными {.smaller}

```{r fig.height=5, fig.width=10}
library(car)
pairs(bird)
```

## Итог предварительного знакомства с данными

- Большая часть значений  AREA, DIST, LDISТ сгруппирована в начале области определения. Связь между AREA и откликом выглядит нелинейной. Нужно логарифмировать эти переменные.

- Переменная GRAZE --- это уровень выпаса скота __в баллах__, ее лучше было бы анализировать как дискретную переменную. Технически, ее можно анализировать и как непрерывную, но нужно помнить, это предполагает одинаковые различия между разными соседними уровнями выпаса скота. Это нереалистично.


Трансформируем переменные

```{r}
bird$logAREA <- log(bird$AREA)
bird$logDIST <- log(bird$DIST)
bird$logLDIST <- log(bird$LDIST)
```


## Проблемы: сильные корреляции между некоторыми предикторами

```{r fig.height=6, fig.width=10, echo=FALSE}
pairs(bird[, c("ABUND", "logAREA", "YRISOL", "logDIST", "logLDIST", "GRAZE", "ALT")])
```

## Модель, которую мы хотим подобрать

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + e_i\\
\end{aligned}$$

Возможно, что эту модель придется изменить.

В начале нам нужно убедиться, что условия применимости линейной регрессии выполняются.

## Вспомним условия применимости линейной регрессии

- Линейная связь между зависимой переменной ($Y$) и предикторами ($X$)
- Независимость значений $Y$ друг от друга
- Нормальное распределение $Y$ для каждого уровня значений $X$
- Гомогенность дисперсий $Y$ для каждого уровня значений $X$
- __Отсутствие коллинеарности предикторов (для можественной регрессии)__

# Мультиколлинеарность

## Мультиколлинеарность

Мультиколлинеарность ---  наличие линейной зависимости между независимыми переменными (предикторами) в регрессионной модели.

При наличии мультиколлинеарности оценки параметров неточны, а значит сложно интерпретировать влияние предикторов на отклик.

### Косвенные признаки мультиколлинеарности:

- Большие ошибки оценок параметров     
- Большинство значений параметров модели незначимо отличается от нуля, но F критерий говорит, что модель в целом значима.

### Проверка на мультиколлинеарность

- Коэффициент раздутия дисперсии (Variance inflation factor, VIF).

## Как рассчитывается VIF

Пусть наша модель $y_i = b_0 + b_1 x_{1i} + b_2 x_{2i} + \ldots + b_{p - 1} x_{p - 1\;i} + e_i$.

Нужно оценить какую долю изменчивости конкретного предиктора могут объяснить другие предикторы (т.е. насколько предикторы независимы).

Для каждого предиктора:

1. Строим регрессионную модель данного предиктора от всех остальных:
$$x_1 = c_0 + c_1x_2 +c_2x_3 + .... + c_{p - 2}x_{p - 1}$$
2. Находим $R^2$ этой модели.
3. Вычисляем коэффициент раздутия дисперсии:
$$VIF = \frac{1}{1-R^2}$$

## Мультиколлинеарность опасна

В случае наличия мультиколлинеарности:

- Оценки коэффициентов модели нестабильны (даже могут менять знак при небольших
изменениях модели или исходных данных).
- Стандартные ошибки оценок параметров увеличатся в $\sqrt{VIF}$ раз.
- В результате меньше шансов заметить влияние предиктора, т.к. уровень значимости (p-value) в тестах будет выше.


## Как бороться с мультиколлинеарностью?

- Можно последовательно удалить из модели избыточные предикторы с VIF > 2  
    1. подбираем модель
    2. считаем VIF
    3. удаляем предиктор с самым большим VIF
    4. повторяем 1-3

- Можно заменить исходные предикторы новыми независимыми друг от друга переменными, сконструированными методом главных компонент (Principal component analysis, PCA).

## Задание

- Постройте множественную линейную регрессию для зависимости обилия птиц (`ABUND`) от других переменных (`logAREA`, `YRISOL`, `logDIST`, `logLDIST`, `GRAZE`, `ALT`)

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot GRAZE_i + b_6 \cdot ALT_i + e_i\\
\end{aligned}$$

- Используйте функцию `vif()`, чтобы проверить, коллинеарны ли предикторы.

Дополните код:

```{r eval=FALSE, purl=TRUE}
mod1 <- lm(formula = , data = )
vif()
```

## Решение

```{r}
# Строим модель
mod1 <- lm(formula = ABUND ~  logAREA + YRISOL + logDIST + logLDIST + GRAZE + ALT, 
           data = bird)
# Проверяем, есть ли коллинеарность?
vif(mod1)
```

В нашей модели сильной мультиколлинеарности нет.

Однако, возможно `GRAZE` --- избыточный предиктор.

## Удалим из модели избыточный предиктор

```{r}
mod2 <- update(mod1, ~ . -GRAZE)
vif(mod2)
```

Теперь мультиколлинеарности нет. В модели осталось пять предикторов (и шесть параметров).


$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

## Уравнение модели

$$\begin{aligned}{ABUND}_i &= b_0 + b_1 \cdot logAREA_i + b_2 \cdot YRISOL_i + \\
&+ b_3 \cdot logDIST_i + b_4 \cdot logLDIST_i + b_5 \cdot ALT_i + e_i\\
\end{aligned}$$

Мы подобрали коэффициенты и можем записать уравнение модели.

```{r}
coef(mod2)
```

$$\begin{aligned}{ABUND}_i &= -226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i - \\
&-0.10 \cdot logDIST_i -0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i + e_i\\
\end{aligned}$$

## В этой модели многие предикторы незначимы {.smaller}

```{r}
summary(mod2)
```

## Дальше может быть два варианта действий:

- Оставить все как есть. Если значение коэффициента при предикторе не значимо отличается от нуля, значит, этот предиктор не влияет на обилие птиц.
- Провести пошаговый подбор оптимальной модели (Об этом на следующей лекции).

Сейчас оставим все как есть.

Теперь давайте проверим, выполняются ли оставшиеся условия применимости, а после этого попытаемся выяснить, какие предикторы влияют сильнее всего.

## Задание

Проверьте, выполняются ли условия применимости для модели `mod2`. Дополните код:

```{r eval=FALSE, purl=TRUE}
library()
mod2_diag <- data.frame(fortify(), $GRAZE)
# 1) График расстояния Кука
ggplot(data = , aes(x = 1:, y = .cooksd)) + geom_bar(stat = "")
# 2) График остатков от предсказанных значений
gg_resid <- ggplot(data = , aes(x = , y = )) + geom_point() + geom_hline()
gg_resid
# 3) Графики остатков от предикторов в модели и нет
res_1 <- gg_resid + aes(x = logAREA)
res_1
res_2 <- gg_resid
res_3 <- gg_resid
res_4 <- gg_resid
res_5 <- gg_resid
res_6 <- gg_resid
# все графики вместе
library(gridExtra)
grid.arrange(res_1, res_2, nrow = 2)
# 4) Квантильный график остатков
library(car)
qq
```

## Решение

### 1) График расстояния Кука 

- Выбросов нет

```{r solution-0a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
library(ggplot2)
mod2_diag <- data.frame(fortify(mod2), GRAZE = bird$GRAZE)

ggplot(data = mod2_diag, aes(x = 1:nrow(mod2_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

## Решение

### 2) График остатков от предсказанных значений

- Выбросов нет
- Гетерогенность дисперсии?
- Два наблюдения с очень большими предсказанными значениями и большими остатками. Хорошо бы проверить их.

```{r solution-1a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
gg_resid <- ggplot(data = mod2_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid
```


## Решение

### 3) Графики остатков от предикторов в модели и нет

- Величина остатков зависит от уровня выпаса скота. Возможно, не стоило удалять эту переменную
- Есть наблюдения с экстремальными значениями предикторов (два больших леса, один далекий, один высокогорный).  Хорошо бы проверить их.
```{r solution-2a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=5, echo=FALSE}
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid + aes(x = YRISOL)
res_3 <- gg_resid + aes(x = logDIST)
res_4 <- gg_resid + aes(x = logLDIST)
res_5 <- gg_resid + aes(x = GRAZE)
res_6 <- gg_resid + aes(x = ALT)

library(gridExtra)
grid.arrange(res_1, res_2, res_3, res_4,
             res_5, res_6, nrow = 2)
```

## Решение

### 3) Код для графиков остатков от предикторов в модели и нет

```{r solution-2a, fig.show='hide', purl=FALSE, echo=TRUE}
```

## Решение

### 4) Квантильный график остатков

- Отклонения от нормального распределения остатков незначительны

```{r solution-3a, purl=FALSE, fig.width=4, fig.height=4, message=FALSE}
library(car)
qqPlot(mod2)
```

# Сравнение силы влияния разных предикторов --- стандартизованные коэффициенты

## Какой из предикторов оказывает наиболее сильное влияние? {.smaller}

```{r}
coef(summary(mod2))
```

## Какой из предикторов оказывает наиболее сильное влияние?

Для ответа на этот вопрос надо "уравнять" шкалы, всех предикторов, то есть стандартизовать их. 

Коэффициенты при стандартизованных предикторах покажут, насколько сильно меняется отклик __при изменении предиктора на одно стандартное отклонение__.

Для стандартизации используем функцию `scale()`

```{r, tidy=TRUE}
mod2_scaled <- lm(ABUND ~ scale(logAREA) + scale(YRISOL) + scale(logDIST) + 
                          scale(logLDIST) + scale(ALT), data = bird)
```

## Какой из предиктов оказывает наиболее сильное влияние на обилие птиц?

```{r}
coef(summary(mod2_scaled))
```

>- Сильнее всего на обилие птиц влияют логарифм площади леса и продолжительность изоляции
>- При изменении логарифма площади на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[2], 2)`
>- При изменении продолжительности изоляции на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[3], 2)`

# График предсказаний модели множественной линейной регрессии

## График предсказаний модели множественной линейной регрессии

Для простой линейной регрессии легко нарисовать график на плоскости, поскольку есть только две переменные: отклик и предиктор.

Во множественной линейной регрессии один отклик, но предикторов много, поэтому чтобы изобразить на плоскости нужны ухищрения.

Самое частое решение --- построить график $y$ от наиболее важного предиктора при средних значениях всех остальных предикторов. Но можно рассмотреть и любые другие интересные вам сценарии.

## Выбираем предикторы для графика модели

$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

<br/>

```{r}
coef(mod2_scaled)
```

Судя по стандартизованным коэффициентам, самая важная здесь переменная --- это логарифм площади леса.

Построим график предсказанных значений обилия птиц для лесов разной площади при средних значениях всех остальных предикторов.


## График предсказаний модели "как есть"


$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

В нашей модели предикторы трансформированы и ABUND от них зависит линейно.

```{r gg-predict-data, echo=FALSE}
# Искуственный датафрейм для предсказаний
MyData <- data.frame(
  logAREA = seq(min(bird$logAREA), max(bird$logAREA), length.out = 100),
  YRISOL = mean(bird$YRISOL),
  logDIST = mean(bird$logDIST),
  logLDIST = mean(bird$logLDIST),
  ALT = mean(bird$ALT))
# Предсказанные значения
Predictions <- predict(mod2, newdata = MyData,  interval = 'confidence')
MyData <- data.frame(MyData, Predictions)
# График предсказаний модели
Pl_predict <- ggplot(MyData, aes(x = logAREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line()
Pl_predict
```

## График предсказаний модели "как есть"

```{r gg-predict-data, echo=TRUE, purl=FALSE, eval=FALSE}
```

## График предсказаний модели после обратной трансформации предикторов

$$\begin{aligned}\widehat{ABUND}_i = &-226.00 + 3.69 \cdot logAREA_i + 0.12 \cdot YRISOL_i \\
&- 0.10 \cdot logDIST_i - 0.33 \cdot logLDIST_i + 0.03 \cdot ALT_i\\
\end{aligned}$$

Для удобства восприятия лучше сделать обратную трансформацию предикторов.

```{r gg-predict, echo=FALSE}
# Обратная трансформация предиктора, который будем изображать
MyData$AREA <- exp(MyData$logAREA)
# График предсказаний модели
Pl_predict <- ggplot(MyData, aes(x = AREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() + xlab("Площадь леса") + ylab("Обилие птиц")
Pl_predict
```

## График предсказаний модели после обратной трансформации предикторов

```{r gg-predict, echo=TRUE, purl=FALSE, eval=FALSE}
```

## Вопрос:

Имеет ли смысл на таком графике изображать исходные наблюдения?

>- Обычно это делают, чтобы (1) посмотреть на величину остатков, (2) посмотреть на диапазон исходных наблюдений.

```{r purl=FALSE, echo=FALSE, fig.height=3}
Pl_predict +
  geom_point(data = bird, aes(x = AREA, y = ABUND))
```

>- Нет, нет смысла. Наш график показывает предсказания только для определенных наблюдений --- со средними значениями нескольких предикторов. Если мы нарисуем значения наблюдений, то их остатки не будут иметь смысл, т.к. у этих наблюдений в реальности совсем не обязательно средние значения этих предикторов.

## Описание множественной линейной регрессии

- Записываем уравнение модели. 
- Общую значимость модели оцениваем при помощи _F_-критерия. 
- Качество подгонки модели описываем при помощи коэффициента детерминации с поправкой ($R^2_{adj.}$).
- При обсуждении значимости отдельных предикторов можно привести таблицу с оценками коэффициентов и тестами их значимости. 
- При сравнении влияния отдельных предикторов приводим стандартизованные коэффициенты
- Приводим график предсказаний модели


<!-- # Задание -->

<!-- ## Задание -->

<!-- - Постройте модель описывающую связь между усилием мышц, осуществляющих выдох (`pemax`) и следующими переменными: -->

<!-- - `age` --- Возраст -->
<!-- - `height` --- Рост (см) -->
<!-- - `weight` --- Вес (кг) -->
<!-- - `bmp` --- Отклонения в весе от нормы (% от нормы) -->
<!-- - `fev1` --- Объем наполненных легких -->
<!-- - `rv` --- Остаточный объем легких -->
<!-- - `frc` --- Функциональная остаточная емкость легких -->
<!-- - `tlc` --- Общая емкость легких -->

<!-- - Не учитывайте влияние пола `sex` (мы пока не умеем работать с дискретными переменными, о них позже) -->
<!-- - Исключите из модели коллинеарные предикторы. -->

<!-- Для получения данных выполните следующий код: -->

<!-- ```{r} -->
<!-- library(ISwR) -->
<!-- data(cystfibr) -->
<!-- ``` -->

<!-- ## Решение -->

<!-- ```{r purl=FALSE} -->
<!-- M1 <- lm(pemax ~ . - sex, data = cystfibr) -->
<!-- summary(M1) -->
<!-- ``` -->

<!-- ## Проверяем на коллинеарность -->

<!-- ```{r purl=FALSE} -->
<!-- vif(M1) -->
<!-- ``` -->

<!-- ### Удаляем избыточные предикторы -->

<!-- ```{r purl=FALSE} -->
<!-- M2 <- update(M1, . ~ . - weight) -->
<!-- vif(M2) -->
<!-- ``` -->


<!-- ## Продолжаем удалять избыточные предикторы -->

<!-- ```{r purl=FALSE} -->
<!-- M3 <- update(M2, . ~. - frc) -->
<!-- vif(M3) -->
<!-- ``` -->

<!-- ### Продолжаем удалять избыточные предикторы -->

<!-- ```{r purl=FALSE} -->
<!-- M4 <- update(M3, . ~. - height) -->
<!-- vif(M4) -->
<!-- ``` -->

<!-- ### Продолжаем удалять избыточные предикторы -->

<!-- ```{r purl=FALSE} -->
<!-- M5 <- update(M4, . ~. - rv) -->
<!-- vif(M5) -->
<!-- ``` -->

<!-- ### Наконец-то коллинеарности нет -->

<!-- ## Смотрим на полученную модель -->

<!-- ```{r purl=FALSE} -->
<!-- summary(M5) -->
<!-- ``` -->


## Take-home messages

- При построении множественной регрессии важно, помимо других условий, проверить модель на наличие мультиколлинеарности
- Если модель построена на основе стандартизированных значений предикторов, то можно сравнивать влияние этих предикторов

## Что почитать

+ Гланц, С., 1998. Медико-биологическая статистика. М., Практика
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide
