---
title: "Диагностика линейных моделей"
subtitle: "Линейные модели..."
author: "Марина Варфоломеева, Вадим Хайтов"
output:
  beamer_presentation:
    colortheme: beaver
    highlight: tango
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - --latex-engine=xelatex
    - -V fontsize=10pt
    - -V lang=russian
    slide_level: 2
    theme: default
    toc: no
institute: "СПбГУ"
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
# opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
opts_chunk$set(fig.show='hold', size='footnotesize', comment="#", warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=3, fig.width=7.5)
library("extrafont")
```

## Мы рассмотрим 

+ Диагностика линейных моделей
- 

### Вы сможете

- 
- 
-

## Пример: IQ и размеры мозга

Зависит ли уровень интеллекта от размера головного мозга? (Willerman et al. 1991)

С этим примером мы познакомились в прошлый раз

\begin{columns}
\begin{column}{0.48\textwidth}
\begin{figure}
\centering
\includegraphics{./images/MRI-Scan_03_11-by_bucaorg(Paul_Burnett)_no_Flickr.jpg}
\caption{\footnotesize{}}
\end{figure}
\end{column}

\begin{column}{0.48\textwidth}
Было исследовано 20 девушек и 20 молодых людей.

У каждого индивида измеряли:
\begin{itemize}
\item вес
\item рост
\item размер головного мозга (количество пикселей на изображении ЯМР сканера)
\item уровень интеллекта (различные IQ тесты)
\end{itemize}

\end{column}
\end{columns}

\tiny{Пример: Willerman, L., Schultz, R., Rutledge, J. N., and Bigler, E. (1991), "In Vivo Brain Size and Intelligence", Intelligence, 15, p.223--228. 
Данные: \href{http://lib.stat.cmu.edu/DASL}{"The Data and Story Library"} 
Фото: \href{https://flic.kr/p/c45eZ3}{Scan\_03\_11} by bucaorg(Paul\_Burnett) on Flickr}

## Данные можно загрузить с сайта

Не забудьте войти в вашу директорию для матметодов при помощи `setwd()`

```{r eval=FALSE}
library(downloader)

# в рабочем каталоге создаем суб-директорию для данных
if(!dir.exists("data")) dir.create("data")

# скачиваем файл
download(
  url = "https://varmara.github.io/linmodr-course/data/IQ_brain.csv", 
  destfile = "data/IQ_brain.csv")
```

## Подберем модель, описывающую зависимость результатов IQ-теста от размера головного мозга

```{r}
brain <- read.csv("data/IQ_brain.csv", header = TRUE)
brain_model <- lm(PIQ ~ MRINACount, data = brain)
brain_model
```
Пишем статью?

\pause

Нет, еще рано. Нужно кое-что проверить.

## Анализ остатков линейных моделей

### Проверка на наличие влиятельных наблюдений

### Проверка условий применимости линейных моделей

- Линейная связь между зависимой перменной ($Y$) и предикторами ($X$)
- Независимость значений $Y$ друг от друга
- Нормальное распределение $Y$ для каждого уровня значений $X$
- Гомогенность дисерсий $Y$ для каждого уровня значений $X$
- Отсутствие коллинеарности предикторов (для можественной регрессии)

# Проверка на наличие влиятельных наблюдений

## Влиятельные наблюдения --- это...

наблюдения, которые вносят слишком большой вклад в оценку парметров (коэффициентов) модели.

\begin{columns}
\begin{column}{0.48\textwidth}
\begin{figure}
\centering
\includegraphics{./images/leverage.png}
\end{figure}
\end{column}

\begin{column}{0.48\textwidth}
Учет каких из этих точек повлияет на ход регрессии и почему?
\begin{itemize}
\item<2-> Точка 1 почти не повлияет, т.к. у нее маленький остаток, хоть и большой $X$
\item<3-> Точка 2 почти не повлияет, т.к. ее $X$ близок к среднему, хоть и большой остаток
\item<4-> Точка 3 повлияет сильно, т.к. у нее не только большой остаток, но и большой $X$
\end{itemize}
\end{column}
\end{columns}

\footnotesize{Из кн. Quinn, Keugh, 2002}


## Типы остатков

### "Сырые" остатки

$\varepsilon_i = y_i - \hat{y_i}$

\pause

### Пирсоновские остатки

$p_i = \frac{\varepsilon_i}{\sqrt{Var(\hat{y_i})}}$,
где $\sqrt{Var(\hat{y_i})}$ --- это cтандартное отклонение предсказанных значений

легко сравнивать, т.к. стандартизованы

\pause

### Стьюдентовские остатки

$s_i = \frac{p_i}{\sqrt{1 - h_{ii}}} = \frac{\varepsilon_i}{\sqrt{Var(\hat{y_i})(1-h_{ii})}}$,  
где $h_{ii}$ --- "сила воздействия" отдельных наблюдений (leverage)

легко сравнивать, т.к. стандартизованы и учитывают влияние наблюдений


## Воздействие точек $h_{ii}$ (leverage)

### показывает, насколько каждое значение $x_i$ влияет на ход линии регрессии, то есть на $\hat{y_i}$

\begin{columns}

\begin{column}[b]{0.55\textwidth}
\centering
\includegraphics[height=4cm]{images/leverage.png}

\tiny{Из кн. Quinn, Keough, 2002}

\includegraphics[height=2.5cm]{images/seasaw-Weighing-Machine-by-neys-fadzil-on-Flickr.jpg}

\tiny{Weighing Machine by neys fadzil on Flickr}

\end{column}

\begin{column}[b]{0.45\textwidth}
\begin{itemize}
\item Точки, располагающиеся дальше от $\bar{x}$, оказывают более сильное влияние на $\hat{y_i}$  
\item Эта величина, в норме, варьирует в промежутке от $1/n$ до 1  
\item Если  $h_{ii} > 2(p/n)$, то надо внимательно посмотреть на данное значение (p --- число параметров, n --- объем выборки)
\end{itemize}
\end{column}

\end{columns}

## Расстояние Кука (Cook's distance)

### описывает, как повлияет на модель удаление данного наблюдения

$$D_i = \frac{\sum{(\hat{y_j}-\hat{y}_{j(i)})^2}}{p \cdot MSE} \large( \frac {h_{ii}} {1 - h_{ii}} \large)$$ 

- $\hat{y_j}$ - значение предсказанное полной моделью
- $\hat{y}_{j(i)}$ - значение, предказанное моделью, построенной без учета $i$-го значения предиктора
- $p$ - количество параметров в модели
- $MSE$ - среднеквадратичная ошибка модели ($\hat\sigma^2$)
- $h_{ii}$ --- "сила воздействия" отдельных наблюдений (leverage)

Расстояние Кука зависит одновременно от величины остатков и "силы воздействия" наблюдений.

Статистических тестов для $D_i$ нет, но можно использовать один из двух условных порогов. Наблюдение является выбросом (outlier), если:

- $D_i > 1$ 
- $D_i > 4/(N − k − 1)$ (N - объем выборки, k - число предикторов)

## Расстояние Кука

```{r}
plot(brain_model, which = 4) # базовый график
```


## Извлечем из результатов сведения для анализа остатков

Функция `fortify()` из пакета `{ggplot2}`

```{r}
library(ggplot2)
brain_diag <- fortify(brain_model)
head(brain_diag, 2)
```

- `.hat` --- "сила воздействия" данного наблюдения (_leverage_)  
- `.cooksd` --- расстояние Кука   
- `.fitted` --- предсказанные значения   
- `.resid` --- остатки
- `.stdresid` --- стандартизованные остатки  

## Задание

Для модели `brain_model` постройте график рaссеяния стандартизированных остатков в зависимости от предсказанных значений, используя данные из датафрейма `brain_diag`

## Решение

```{r purl=FALSE}
theme_set(theme_bw()) # устанавливаем тему (не обязательно)
ggplot(data = brain_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(aes(yintercept = 0))
```

Что мы видим?

\begin{itemize}[<+(1)->]
\item Большая часть стандартизованных остатков в пределах двух стандартных отклонений
\item Есть одно влиятельное наблюдение, которое нужно проверить, но сила его влияния невелика
\item Среди остатков нет тренда, но, возможно, есть иной паттерн...
\end{itemize}

## Добавим линию loess-сглаживания на график

```{r}
ggplot(data = brain_diag, aes(x = .fitted, y = .stdresid)) +
  geom_point(aes(size = .cooksd)) + 
  geom_hline(yintercept = 0) + 
  geom_smooth(method="loess", se=FALSE) 
```

Чем мог быть вызван такой странный паттерн?

\begin{itemize}[<+(1)->]
\item Неучтенная переменная --- добавляем в модель
\item Нелинейная зависимость --- используем GAM, нелинейную регрессию и т.д.
\end{itemize}

## Что делать с наблюдениями-выбросами?

### Удалить?

__Осторожно!__ Нельзя удалять выбросы только на основе такого диагноза. Задача диагностики --- заставить вас искать причины такого поведения данных. 
Удалять следует только очевидные ошибки в наблюдениях.

### Трансформировать?

Некоторые виды трансформаций

Трансформация  |  Формула  
------------- | -------------   
степень -2 | $1/x^2$
степень -1 | $1/x$
степень -0.5  | $1/\sqrt{x}$
степень 0.5 | $\sqrt{x}$
логарифмирование | $log(x)$  

# Условия применимости линейных моделей (Assumptions)

## 1. Линейность связи

Нелинейные зависимости не всегда видны на исходных графиках в осях Y vs X

Они становятся лучше заметны на графиках рассеяния остатков (Residual plots)

```{r echo=FALSE, purl=FALSE}
library(gridExtra)

set.seed(92387)
x <- rnorm(100, 10, 3)
y <- (x^2.4) + rnorm(100, 0, 100)
pl_1 <- ggplot(data.frame(x=x, y=y), aes(x=x, y=y)) + geom_point() 

lm1 <- lm(y ~ x)

pl_1res <- ggplot(data.frame(fit=fitted(lm1), res=residuals(lm1)), aes(x=fit, y=res)) + geom_point() + geom_hline(yintercept=0) + xlab("Fitted") + ylab("Residuals")


x2 <- runif(100, 1, 10)
y2 <- sin(x2) + 1.8*x2 + rnorm(100)
pl_2 <- ggplot(data.frame(x=x2, y=y2), aes(x=x, y=y)) + geom_point() 

lm2 <- lm(y2 ~ x2)
pl_2res <- ggplot(data.frame(fit=fitted(lm2), res=residuals(lm2)), aes(x=fit, y=res)) + geom_point() + geom_hline(yintercept=0) + xlab("Fitted") + ylab("Residuals") 

grid.arrange(pl_1, pl_2, pl_1res, pl_2res)
```

## Что делать, если связь нелинейна?  

- Построить аддитивную модель (если достаточно наблюдений по $x$)
- Построить нелинейную модель (если известна форма зависимости)
- Применить линеаризующее преобразование (Осторожно!)
- Применить обобщенную линейную модель с другой функцией связи (об этом позже)


## Пример линеаризующего преобразования   

```{r echo=FALSE, purl=FALSE}
set.seed(29834)
x <- runif(100, 2, 5)
y <- (2^(2*x)) + rnorm(100, 0, 70)

pl_raw <- ggplot(data.frame(x=(x), y=(y)), aes(x=x, y=y)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7) 

pl_log <- ggplot(data.frame(x= (x), y=log(y)), aes(x=x, y=y)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7) + ylab("Log (y)")

grid.arrange(pl_raw, pl_log, ncol=2)

```

\pause

__Осторожно!__ При таком преобразовании вы рискуете изучить не то, что хотели. Матожидание логарифма величины (как при трансформации) не то же самое, что логарифм матожидания величины (как при использовании обобщенной линейной модели с логарифмической функцией связи). Но об этом --- позже.

## 2. Независимость $Y$ друг от друга

Каждое значение $Y_i$ должно быть независимо от любого другого $Y_j$ 

Это нужно контролировать на этапе планирования сбора матриала 

* Наиболее частые источники зависимостей: 
    + псевдоповторности (повторно измеренные объекты --- чтобы исправить, используем случайные факторы в модели)
    + неучтенные переменные (чтобы исправить, включаем переменные)
    + временные автокорреляции (если данные - временной ряд)
    + пространственные автокорреляции (если пробы взяты в разных местах)

\pause

Взаимозависимости можно заметить на графиках остатков:

- остатки vs. предсказанные значения
- остатки vs. переменные в модели
- остатки vs. переменные не в модели

## Нарушение условия независимости: Неучтенная переменная

```{r echo=FALSE, purl=FALSE, fig.height=4}
set.seed(239874)
x1 <- runif(100, 20, 50)
x2 <- runif(100, 8, 22)
y <- 21 + 2*x1 + 0.5*x2 + rnorm(100, 0, 10)
NewData1 <- data.frame(y = y, x1 = x1, x2 = x2)

mod1 <- lm(y~x1)
gg_lm1 <- ggplot(NewData1, aes(x=x1, y=y)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7) + xlab("X1") + ggtitle("Y ~ X1")
gg_res1 <- ggplot(data.frame(fit = fitted(mod1), res = residuals(mod1, type = "pearson")), aes(x = fit, y = res)) + geom_point() + geom_smooth(se = FALSE) + geom_hline(yintercept = 0) + xlab("Fitted") + ylab("Residuals")
gg_res2 <- ggplot(data.frame(fit = fitted(mod1), res = residuals(mod1, type = "pearson")), aes(x = x2, y = res)) + geom_point() + geom_smooth(se = FALSE) + geom_hline(yintercept = 0) + xlab("X2") + ylab("Residuals")


mod2 <- lm(y~x1+x2)
NewData2 <- data.frame(x1 = seq(min(x1), max(x1), length.out = 10),
                      x2 = mean(x2))
NewData2$y <- predict(mod2, newdata = NewData2)
gg_lm2 <- ggplot(NewData2, aes(x= x1, y = y)) + geom_point(data = NewData1, aes(x = x1, y = y)) + geom_line(colour = "blue", size = 1) + xlab("X1") + ggtitle("Y ~ X1 + X2")
gg_res3 <- ggplot(data.frame(fit = fitted(mod2), res = residuals(mod2, type = "pearson")), aes(x = fit, y = res)) + geom_point() + geom_smooth(se = FALSE) + geom_hline(yintercept = 0) + xlab("Fitted") + ylab("Residuals")
gg_res4 <- ggplot(data.frame(fit = fitted(mod2), res = residuals(mod2, type = "pearson")), aes(x = x2, y = res)) + geom_point() + geom_smooth(se = FALSE) + geom_hline(yintercept = 0) + xlab("X2") + ylab("Residuals")

grid.arrange(gg_lm1, gg_lm2, gg_res1, gg_res3, gg_res2, gg_res4, ncol=2)
```

Если в модели не учтена переменная $X2$ (слева), внешне все нормально (только остатки большие), но если построить график зависимости остатков от $X2$.

Если $X2$ учесть (справа) --- остатки становятся меньше, зависимость остатков от $X2$ исчезает.

## Нарушение условия независимости: Автокоррелированные данные

В данном случае, наблюдения --- это временной ряд. 

```{r echo=FALSE, purl=FALSE}
x3 <- seq(1, 100, 1)
  
y3 <-  diffinv(rnorm(99)) + rnorm(100, 0, 2)

y3 <- y3[1:100]
pl_3 <- ggplot(data.frame(x=x3, y=y3), aes(x=x, y=y)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7)

lm3 <- lm(y3 ~ x3)

pl_3res <- ggplot(data.frame(fit=fitted(lm3), res=residuals(lm3)), aes(x=fit, y=res)) + geom_point() + geom_smooth(se = FALSE) + geom_hline(yintercept=0) + xlab("Fitted") + ylab("Residuals")

grid.arrange(pl_3, pl_3res, nrow=2)
```

На графиках остатков четко видно, что остатки не являются независимыми.

## Проверка на автокорреляцию

Проверка на автокорреляцию нужна если данные это временной ряд, или если известны координаты проб.

Способы проверки временной автокорреляции (годятся, если наблюдения в ряду расположены через равные интервалы):

- График автокорреляционной функции остатков (ACF-plot) покажет корреляции с разными лагами.
- Критерий Дарбина-Уотсона (значимость автокорреляции 1-го порядка).

Для проверки пространственных автокорреляций

- вариограмма
- I Морана (Moran's I)

## 3. Нормальное распределение $Y$ (для каждого уровня значений $X$) 

<img src="figure/Zuur.png" width="400" height="300" >   

<img src="figure/Normality.png" width="400" height="200" > 

Это условие невозможно проверить "влоб", т.к. обычно каждому $X$ сообветствует лишь небольшое число $Y$ 

Если $Y$ это нормально распределенная случайная величина

$$Y_i \in N(\mu_{y_i}, \sigma^2)$$

и мы моделируем ее как 

$$Y_i \sim b_0 + b_1x_{1i} + \cdots + \varepsilon_i$$  

то остатки от этой модели --- тоже нормально распределенная случайная величина 

$$\varepsilon_i \in N(\mu_{y_i}, \sigma^2)$$

Т.е. выполнение этого условия можно оценить по поведению случайной части модели.

## Проверка нормальности распределения остатков

Есть формальные тесты, но:

- у формальных тестов тоже есть свои условия применимости
- при больших выборках формальные тесты покажут, что значимы даже небольшие отклонения от нормального распределения
- тесты, которые используются в линейной регрессии, устойчивы к небольшим отклонениям от нормального распределения

Лучший способ проверки --- квантильный график остатков.

## Квантильный график остатков

_Квантиль_ - значение, которое заданная случайная величина не превышает с фиксированной вероятностью.       

Если точки - это реализации случайной величины из $N(0, \sigma^2)$, то они должны лечь вдоль прямой $Y=X$. Если это стьюдентизированные остатки --- то используются квантили t-распределения

```{r}
library(car)
qqPlot(brain_model)
```

## Аналогичный график при помощи `ggplot2`

```{r, fig.height=3, fig.align='center', tidy=TRUE}
mean_val <- mean(brain_diag$.stdresid)
sd_val <- sd(brain_diag$.stdresid)
ggplot(brain_diag, aes(sample = .stdresid)) + geom_point(stat = "qq") + geom_abline(intercept = mean_val, slope = sd_val)
```


## 4. Постоянство дисперсии (гомоскедастичность)

Это самое важное условие, поскольку многие тесты чувствительны к гетероскедастичности.     

```{r echo=FALSE, purl=FALSE}
N <- 300
b_0 <- 0.2 
b_1 <- 5

set.seed(123456)
x <- rnorm(N, 10, 3)
eps_1 <- rnorm(N, 0, 10)
y_1 <- b_0 + b_1*x + eps_1

# |v|^(2*t), t = 0.7
h <- function(x) x^(2*0.7) 
eps_2 <- rnorm(N, 0, h(x))
y_2 <- b_0 + b_1*x + eps_2
dat <- data.frame(x, y_1, y_2)
dat$log_y <- log(y_2)

pl_hom <- ggplot(dat, aes(x = x, y = y_1)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7) + ggtitle("Гомоскедастичность") + ylab("Y")
pl_heter <- pl_hom + aes(y = y_2) + ggtitle("Гетероскедастичность") + ylab("Y")

dat_diag_1 <- fortify(lm(y_1 ~ x, data = dat))
dat_diag_2 <- fortify(lm(y_2 ~ x, data = dat))

pl_hom_resid <- ggplot(dat_diag_1, aes(x = .fitted, y = .stdresid)) + geom_point() + geom_smooth(se=FALSE)
pl_heter_resid <- pl_hom_resid %+% dat_diag_2

grid.arrange (pl_hom, pl_heter, 
              pl_hom_resid, pl_heter_resid, 
              ncol=2)

```

## Проверка постоянства дисперсий

Есть формальные тесты (тест Бройша-Пагана, тест Кокрана), но:

- у формальных тестов тоже есть свои условия применимости, и многие сами неустойчивы к гетероскедастичности
- при больших выборках формальные тесты покажут, что значима даже небольшая гетероскедастичность

Лучший способ проверки --- график остатков.

## Проверка на гетероскедастичность

Мы уже строили график остатков в `ggplot2`

```{r}
ggplot(data = brain_diag,
       aes(x = .fitted, y = .stdresid)) +
  geom_point() + geom_hline(yintercept = 0) 
```

## Проверка на гетероскедастичность

Можем построить аналогичный график остатков средствами пакета `car`

```{r}
residualPlot(brain_model)
```


## Что делать если вы столкнулись с гетероскедастичностью?

### Решение 1. Трансформировать зависимую переменную (или в некоторых случаях предиктор).  

```{r echo=FALSE,purl=FALSE}

dat_diag2 <- fortify(lm(log_y~x, data=dat))


pl_heter2 <- ggplot(dat, aes(x=x, y=log_y)) + geom_point() + geom_smooth(method = "lm", alpha = 0.7)

pl_heter_resid2 <- ggplot(dat_diag2, aes(x = .fitted, y = .stdresid)) + geom_point() + geom_smooth(se=FALSE)

pl_heter <- pl_heter + ggtitle("No transformation")
pl_heter2 <- pl_heter2 + ggtitle("Log transformed Y")


grid.arrange (pl_heter, pl_heter2,  pl_heter_resid, pl_heter_resid2,  nrow=2)

```

Недостатки:

- Не всегда спасает. Может стать хуже.
- Модель описывает поведение не исходной, а преобразованной величины.


## Что делать если вы столкнулись с гетероскедастичностью?

### Решение 2. Построить более сложную модель, которая учитывала бы гетерогенность дисперсии зависимой перменной.  

"Welcome to our world, the world of _mixed effects modelling_."(Zuur et al., 2009)  

Об этом речь впереди!


## Некоторые распространенные паттерны на графиках остатков


\begin{columns}

\begin{column}{0.5\textwidth}
\includegraphics[height=8cm]{images/Residuals.png}

\tiny{Bз кн. Logan, 2010, стр. 174}

\end{column}

\begin{column}{0.48\textwidth}
\begin{itemize}
\item a) Условия применимости соблюдаются. Модель хорошая
\item b) Клиновидный паттерн. Есть гетероскедастичность. Модель плохая
\item c) Остатки рассеяны равномерно, но модель неполна. Нужны дополнительные предикторы. Модель можно улучшить
\item d) Нелинейный паттерн сохранился. Линейная модель использована некорректно. Модель плохая
\end{itemize}
\end{column}

\end{columns}

## Задание

Выполните три блока кода (см. код лекции). 

Какие нарушения условий применимости линейных моделей здесь наблюдаются?

## Задание, блок 1

```{r}
set.seed(12345)
x1 <- seq(1, 100, 1)
y1 <-  diffinv(rnorm(99)) + rnorm(100, 0.2, 2)
dat1 = data.frame(x1, y1)
ggplot(dat1, aes(x = x1, y = y1)) + geom_point()+ geom_smooth(method="lm", alpha = 0.7)
```

## Решение, блок 1

```{r fig.show='hold'}
mod1 <- lm(y1 ~ x1, data = dat1)
op <- par(mfrow = c(1, 3)) # располагаем картинки в 3 колонки
plot(mod1, which = 4) # Расстояние Кука
residualPlot(mod1)    # График остатков
qqPlot(mod1)          # Квантильный график остатков
par(op) # возвращаем старые графические параметры
```



## Что нужно писать в тексте статьи по поводу проверки валидности моделей?

### Вариант 1

Привести необходимые графики в электронных приложениях.

\pause

### Вариант 2

Привести в тексте работы результаты тестов на гомогеность дисперсии, автокорреляцию (если используются пространственые или временные предикторы) и нормальность распределиня остатков.

\pause

### Вариант3

Написать в главе _"Материал и методика"_ фразу вроде такой:   "Визуальная проверка графиков рассяния остатков не выявила заметных отклонений от условий гомогенности дисперсий и нормальности".

## Summary

- Не любая модель с достверными результатами проверки $H_0$ валидна.  
- Обязательный этап работы с моделями - проверка условий применимости.
- Наиболее важную информацию о валидности модели дает анализ остатков.

## Что почитать

+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014.
+ Quinn G.P., Keough M.J. (2002) Experimental design and data analysis for biologists, pp. 92-98, 111-130
+ Diez D. M., Barr C. D., Cetinkaya-Rundel M. (2014) Open Intro to Statistics., pp. 354-367.
+ Logan M. (2010) Biostatistical Design and Analysis Using R. A Practical Guide, pp. 170-173, 208-211
+ Legendre P., Legendre L. (2012) Numerical ecology. Second english edition. Elsevier, Amsterdam. 

