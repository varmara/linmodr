---
title: "Множественная регрессия"
author: Марина Варфоломеева, Вадим Хайтов
output:
  ioslides_presentation:
    widescreen: true
    css: assets/my_styles.css
    logo: assets/Linmod_logo.png
  beamer_presentation:
    colortheme: beaver
    highlight: tango
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - --latex-engine=xelatex
    - -V fontsize=10pt
    - -V lang=russian
    slide_level: 2
    theme: default
    toc: no
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, fig.width = 7, fig.height = 3, warning = FALSE)
```

## Множественная регрессия



### Вы сможете

+ Подобрать модель множественной линейной регрессии
+ Протестировать ее статистическую значимость и валидность

## Пример: птицы в лесах Австралии

Фрагментация лесных местообитаний - одна из важнейших проблем Австралии.
От каких характеристик лесного участка зависит обилие птиц во фрагментированных лесных массивах? (Loyn, 1987)

<div class="columns-2">

![forest in Victoria, Australia](images/vict_m.jpg)
<small>Mystic Forest - Warburton, Victoria by ¡kuba! on flickr</small>

56 лесных участков:

- ABUND - обилие птиц
- AREA - площадь участка
- YRISOL - год изоляции участка
- DIST - расстояние до ближайшего леса
- LDIST - расстояние до ближайшего большого леса
- GRAZE - пастбищная нагрузка (1-5)
- ALT - высота над уровнем моря

</div>

<small>Пример из кн. Quinn, Keugh, 2002, данные из Loyn, 1987)</small>

## Читаем данные

```{r}
bird <- read.csv("data/loyn.csv")
```
Все ли правильно открылось?

```{r}
str(bird)
```

Есть ли пропущенные значения?

```{r}
colSums(is.na(bird))
```

## Можно ли ответить на вопрос таким методом?

```{r}
cor(bird)
```

Нет

- Обычная корреляция не учитывает, что взаимосвязь между переменными может находиться под контролем других переменных и их взаимодействий.
- Множественные тесты. При тестировании значимости множества коэффициентов корреляции нужно вводить поправку для уровня значимости. Лучше было бы учесть все в одном анализе.

## Нам предстоит построить модель множественной линейной регрессии

$$y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \beta_3x_{i3} + ... + \beta_px_{ip} + \varepsilon_i$$

- $y_i$ --- значение зависимой переменной для $i$-того наблюдения
- $\beta_0$ --- свободный член (intercept). Значение $y$ при $x_1 = x_2 = x_3= \ldots = x_p = 0$
- $\beta_1$ --- частный угловой коэффициент для зависимости $y$ от $x_1$. Показывает насколько единиц изменяется $y$ при изменении $x_1$ на одну единицу и при условии, что все остальные предикторы не изменяются
$\beta_2$, $\beta_3$, ...., $\beta_p$ --- аналогично
- $\varepsilon_i$ --- варьирование $y$, не объясненное данной моделью


## Геометрическая интерпретация множественной линейной модели 

### Для случая с одним предиктором $y_i = \beta_0 + \beta_1x_i + \varepsilon_i$ --- линия регрессии

```{r, echo=FALSE, purl=FALSE}
library(ggplot2)
dfr <- data.frame(x1 = runif(25, 0, 10))
dfr$y1 <- 5 + 5 * dfr$x1 + rnorm(25, 0, 5)
ggplot(data = dfr, aes(x = x1, y = y1)) + geom_point() + geom_smooth(method = "lm") + ylab("y")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с двумя предикторами $y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \varepsilon_i$ --- плоскость в трехмерном пространстве

```{r, echo=FALSE, fig.height=5, fig.width=5, purl=FALSE}
library(plot3D)

dfr$x2 <- runif(25, 10, 20)
dfr$y2 <- 5 + 5 * dfr$x1 + 3 * dfr$x2 + rnorm(25, 0, 15)
fit <- lm(y2 ~ x1 + x2, data = dfr)

# predict values on regular xy grid
x1.pred <- seq(0, 10, length.out = 20)
x2.pred <- seq(10, 20, length.out = 20)
xy <- expand.grid(x1 = x1.pred, 
                  x2 = x2.pred)

y2.pred <- matrix(nrow = 20, ncol = 20, 
                  data = predict(fit, newdata = xy, 
                                 interval = "prediction"))

# fitted points for droplines to surface
fitpoints <- predict(fit) 

scatter3D(x = dfr$x1, y = dfr$x2, z = dfr$y2, 
          pch = 18, cex = 1.5,
          theta = 20, phi = 16,
          ticktype = "detailed",
          surf = list(x = x1.pred, y = x2.pred, z = y2.pred,
                      facets = NA, fit = fitpoints),
          xlab = "First predictor X1", ylab = "Second predictor X2",
          zlab = "Response variable",
          main = "")
```

## Геометрическая интерпретация множественной линейной модели

### Для случая с большим количеством предикторов 

$$y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \beta_3x_{i3} + ... + \beta_px_{ip} + \varepsilon_i$$

Плоскость в n-мерном пространстве, оси которого образованы значениями предикторов


## Знакомство с данными {.smaller}

```{r fig.height=5, fig.width=10}
library(car)
scatterplotMatrix(bird)
```

## Итог предварительного знакомства с данными

- Большая часть значений  AREA, DIST, LDISТ сгруппирована в начале области определения. Связь между AREA и откликом выглядит нелинейной. Нужно логарифмировать эти переменные.

- Переменная GRAZE --- это уровень выпаса скота __в баллах__, ее лучше было бы анализировать как дискретную переменную. Технически, ее можно анализировать и как непрерывную, но нужно помнить, это предполагает одинаковые различия между разными соседними уровнями выпаса скота. Это нереалистично.


Трансформируем переменные

```{r}
bird$logAREA <- log(bird$AREA)
bird$logDIST <- log(bird$DIST)
bird$logLDIST <- log(bird$LDIST)
```


## Явные проблемы --- есть сильные корреляции между некоторым предикторами

```{r fig.height=6, fig.width=10, echo=FALSE}
scatterplotMatrix(bird[, c("ABUND", "logAREA", "YRISOL", "logDIST", "logLDIST", "GRAZE", "ALT")])
```

## Вспомним условия применимости линейной регрессии

- Линейная связь между зависимой переменной ($Y$) и предикторами ($X$)
- Независимость значений $Y$ друг от друга
- Нормальное распределение $Y$ для каждого уровня значений $X$
- Гомогенность дисперсий $Y$ для каждого уровня значений $X$
- __Отсутствие коллинеарности предикторов (для можественной регрессии)__

# Мультиколлинеарность

## Мультиколлинеарность

Мультиколлинеарность ---  наличие линейной зависимости между независимыми переменными (факторами) регрессионной модели.

При наличии мультиколлинеарности оценки параметров получаются неточными, а значит сложно будет дать интерпретацию влияния предикторов на отклик

Косвенные признаки мультиколлинеарности:

- Большие ошибки оценок параметров             
- Большинство параметров модели недостоверно отличаются от нуля, но F критерий говорит, что вся модель значима

### Проверка на мультиколлинеарность

- Коэффициент раздутия дисперсии (Variance inflation factor, VIF)

## Как рассчитывается VIF

Мы должны оценить какую долю изменчивости конкретного предиктора могут объяснить другие предикторы (т.е. насколько предикторы независимы)

Для каждого предиктора:

1. Строим регрессионную модель данного предиктора от всех остальных
$$x_1 = c_0 + c_2x_2 +c_2x_3 + .... + c_px_p$$
2. Находим $R^2$ модели
3. Вычисляем коэффициент раздутия дисперсии
$$VIF = \frac{1}{1-R^2}$$

## Что делать, если мультиколлинеарность выявлена?

- Можно последовательно удалить из модели избыточные предикторы с VIF > 3 (или даже VIF > 2)
    1. подбираем модель
    2. считаем VIF
    3. удаляем предиктор с самым большим VIF
    4. повторяем 1-3

- Можно заменить исходные предикторы новыми независимыми друг от друга переменными, полученными с помощью метода главных компонент


## Задание

- Постройте множественную линейную регрессию для зависимости обилия птиц (`ABUND`) от других переменных (`logAREA`, `YRISOL`, `logDIST`, `logLDIST`, `GRAZE`, `ALT`)
- Используйте функцию vif, чтобы проверить, коллинеарны ли предикторы.

Дополните этот код:

```{r eval=FALSE, purl=TRUE}
mod1 <- lm(data = bird)
vif()
```

## Решение

```{r}
# Строим модель
mod1 <- lm(ABUND ~  logAREA + YRISOL + logDIST + logLDIST + GRAZE + ALT, data = bird)
# Проверяем, есть ли коллинеарность?
vif(mod1)
```

В нашей модели сильной мультиколлинеарности нет

Однако, возможно, что  `GRAZE` - избыточный предиктор

## Удалим из модели избыточный предиктор

```{r}
mod2 <- update(mod1, ~ . -GRAZE)
vif(mod2)
```

Теперь мультиколлинеарности нет

## В этой модели осталось много незначимых предикторов

```{r}
coef(summary(mod2))
```

### Что дальше?

Два варианта действий:

- Оставить все как есть. Если значение коэффициента при предикторе не значимо отличается от нуля, значит, этот предиктор не влияет на обилие птиц
- Провести пошаговый подбор оптимальной модели (Об этом на следующей лекции)

Сейчас мы оставим все как есть.

Теперь давайте проверим, выполняются ли оставшиеся условия применимости, а после этого попытаемся выяснить, какие предикторы влияют сильнее всего.

## Задание

Проверьте, выполняются ли условия применимости для модели `mod2`

Дополните этот код

```{r eval=FALSE, purl=TRUE}
library()
mod2_diag <- data.frame(fortify(), $GRAZE)
# 1) График расстояния Кука
ggplot(data = , aes(x = 1:, y = .cooksd)) + geom_bar(stat = "")
# 2) График остатков от предсказанных значений
gg_resid <- ggplot(data = , aes(x = , y = )) + geom_point() + geom_hline()
gg_resid
# 3) Графики остатков от предикторов в модели и нет
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid
res_3 <- gg_resid
res_4 <- gg_resid
res_5 <- gg_resid
res_6 <- gg_resid
# все графики вместе
library(gridExtra)
grid.arrange(res_1, res_2, nrow = 2)
# 4) Квантильный график остатков
library(car)
qq
```

## Решение

### 1) График расстояния Кука 

- Выбросов нет

```{r solution-0a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
library(ggplot2)
mod2_diag <- data.frame(fortify(mod2), GRAZE = bird$GRAZE)

ggplot(data = mod2_diag, aes(x = 1:nrow(mod2_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

## Решение

### 2) График остатков от предсказанных значений

- Выбросов нет
- Гетерогенность дисперсии?
- Два наблюдения с очень большими предсказанными значениями и большими остатками. Хорошо бы проверить их.

```{r solution-1a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=2.2}
gg_resid <- ggplot(data = mod2_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + geom_hline(yintercept = 0)
gg_resid
```


## Решение

### 3) Графики остатков от предикторов в модели и нет

- Величина остатков зависит от уровня выпаса скота. Возможно, не стоило удалять эту переменную
- Есть наблюдения с экстремальными значениями предикторов (два больших леса, один далекий, один высокогорный).  Хорошо бы проверить их.
```{r solution-2a, fig.show='hold', purl=FALSE, fig.width=10, fig.height=5, echo=FALSE}
res_1 <- gg_resid + aes(x = logAREA)
res_2 <- gg_resid + aes(x = YRISOL)
res_3 <- gg_resid + aes(x = logDIST)
res_4 <- gg_resid + aes(x = logLDIST)
res_5 <- gg_resid + aes(x = GRAZE)
res_6 <- gg_resid + aes(x = ALT)

library(gridExtra)
grid.arrange(res_1, res_2, res_3, res_4,
             res_5, res_6, nrow = 2)
```

## Решение

### 3) Код для графиков остатков от предикторов в модели и нет

```{r solution-2a, fig.show='hide', purl=FALSE, echo=TRUE}
```

## Решение

### 4) Квантильный график остатков

- Отклонения от нормального распределения остатков незначительны

```{r solution-3a, purl=FALSE, fig.width=4, fig.height=4, message=FALSE}
library(car)
qqPlot(mod2)
```

## Описание множественной линейной регрессии {.smaller}

План:

- Записываем уравнение модели. 
- Общую значимость модели оцениваем при помощи _F_-критерия. 
- Качество подгонки модели описываем при помощи коэффициента детерминации с поправкой ($R^2_{adj.}$).
- При обсуждении значимости отдельных предикторов можно привести таблицу с оценками коэффициентов и тестами их значимости. 
- При сравнении влияния отдельных предикторов приводим стандартизованные коэффициенты (см. далее)
- Приводим график предсказаний модели (см. далее)

```{r eval=FALSE}
summary(mod2)
```

# Сравнение силы влияния разных предикторов --- стандартизованные коэффициенты

## Какой из предикторов оказывает наиболее сильное влияние?

Для ответа на этот вопрос надо "уравнять" шкалы, всех предикторов, то есть стандартизовать их. 

Коэффициенты при стандартизованных предикторах покажут, насколько сильно меняется отклик __при изменении предиктора на одно стандартное отклонение__.

Для стандартизации используем функцию `scale()`

```{r, tidy=TRUE}
mod2_scaled <- lm(ABUND ~ scale(logAREA) + scale(YRISOL) + scale(logDIST) + scale(logLDIST) + scale(ALT), data = bird)
```

## Какой из предиктов оказывает наиболее сильное влияние на обилие птиц?

```{r}
coef(summary(mod2_scaled))
```

>- Сильнее всего на обилие птиц влияют логарифм площади леса и продолжительность изоляции
>- При изменении логарифма площади на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[2], 2)`
>- При изменении продолжительности изоляции на 1 стандартное отклонение, обилие птиц изменяется на `r round(coef(mod2_scaled)[3], 2)`

# График предсказаний модели множественной линейной регрессии

## График предсказаний модели множественной линейной регрессии

Для простой линейной регрессии легко нарисовать график на плоскости, поскольку есть только две переменные: отклик и предиктор.

Во множественной линейной регрессии один отклик, но предикторов много, поэтому чтобы изобразить на плоскости нужны ухищрения.

Самое частое решение --- построить график $y$ от наиболее важного предиктора при средних значениях всех остальных предикторов. Но можно рассмотреть и любые другие интересные вам сценарии.

## График предсказаний модели

Судя по стандартизованным коэффициентам, самая важная здесь переменная --- это площадь леса.

Построим график предсказанных значений обилия птиц для лесов разной площади при средних значениях всех остальных предикторов.

```{r gg-predict, echo=FALSE, purl=TRUE, fig.width=10, fig.height=4}
# Искуственный датафрейм для предсказаний
MyData <- data.frame(
  logAREA = seq(min(bird$logAREA), max(bird$logAREA), length.out = 100),
  YRISOL = mean(bird$YRISOL),
  logDIST = mean(bird$logDIST),
  logLDIST = mean(bird$logLDIST),
  ALT = mean(bird$ALT))
# Предсказанные значения
Predictions <- predict(mod2, newdata = MyData, se.fit = TRUE)
MyData$fit <- Predictions$fit
# Стандартные ошибки
MyData$SE <- Predictions$se.fit
# Доверительный интервал
MyData$upr <- MyData$fit + 1.96 * MyData$SE
MyData$lwr <- MyData$fit - 1.96 * MyData$SE
# Обратная трансформация предикторов
MyData$AREA <- exp(MyData$logAREA)
MyData$DIST <- exp(MyData$logDIST)
MyData$LDIST <- exp(MyData$logLDIST)
# График предсказаний модели
Pl_predict <- ggplot(MyData, aes(x = AREA, y = fit)) +
  geom_ribbon(alpha = 0.2, aes(ymin = lwr, ymax = upr)) +
  geom_line() + xlab("Площадь леса") + ylab("Обилие птиц")
Pl_predict
```

## График предсказаний модели

```{r gg-predict, echo=TRUE, purl=FALSE, eval=FALSE}
```

## Вопрос:

Имеет ли смысл на таком графике изображать исходные наблюдения?

Обычно это делают, чтобы (1) посмотреть на величину остатков, (2) посмотреть на диапазон исходных наблюдений.

Будет ли это иметь смысл здесь?

```{r purl=FALSE, echo=FALSE, fig.width=10, fig.height=4}
Pl_predict +
  geom_point(data = bird, aes(x = AREA, y = ABUND))
```

>- Нет, не нужно. Наш график показывает предсказания только для определенных наблюдений --- со средними значениями нескольких предикторов. Если мы нарисуем значения наблюдений, то их остатки не будут иметь смысл, т.к. у этих наблюдений в реальности совсем не обязательно средние значения этих предикторов.

# Задание

## Задание

- Постройте модель описывающую связь между усилием мышц, осуществляющих выдох (`pemax`) и следующими переменными:

- `age` --- Возраст
- `height` --- Рост (см)
- `weight` --- Вес (кг)
- `bmp` --- Отклонения в весе от нормы (% от нормы)
- `fev1` --- Объем наполненных легких
- `rv` --- Остаточный объем легких
- `frc` --- Функциональная остаточная емкость легких
- `tlc` --- Общая емкость легких

- Не учитывайте влияние пола `sex` (мы пока не умеем работать с дискретными переменными, о них позже)
- Исключите из модели коллинеарные предикторы.

Для получения данных выполните следующий код:

```{r}
library(ISwR)
data(cystfibr)
```

## Решение

```{r purl=FALSE}
M1 <- lm(pemax ~ . - sex, data = cystfibr)
summary(M1)
```

## Проверяем на коллинеарность

```{r purl=FALSE}
vif(M1)
```

### Удаляем избыточные предикторы

```{r purl=FALSE}
M2 <- update(M1, . ~ . - weight)
vif(M2)
```


## Продолжаем удалять избыточные предикторы

```{r purl=FALSE}
M3 <- update(M2, . ~. - frc)
vif(M3)
```

### Продолжаем удалять избыточные предикторы

```{r purl=FALSE}
M4 <- update(M3, . ~. - height)
vif(M4)
```

### Продолжаем удалять избыточные предикторы

```{r purl=FALSE}
M5 <- update(M4, . ~. - rv)
vif(M5)
```

### Наконец-то коллинеарности нет

## Смотрим на полученную модель

```{r purl=FALSE}
summary(M5)
```


## Summary

- При построении множественной регрессии важно, помимо других условий, проверить модель на наличие мультиколлинеарности
- Если модель построена на основе стандартизированных значений предикторов, то можно сравнивать влияние этих предикторов

## Что почитать

+ Гланц, С., 1998. Медико-биологическая статистика. М., Практика
+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide
