---
title: "Линейные модели с дискретными предикторами"
subtitle: ""
author: "Марина Варфоломеева, Вадим Хайтов"
output:
  xaringan::moon_reader:
    self-contained: true
    lib_dir: libs
    css: [default, tamu-fonts, "assets/xaringan.css"]
    df_print: default
    nature:
      highlightStyle: vs
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: [top, center, inverse]
    includes:
      in_header: "assets/xaringan_in_header.html"
      after_body: "assets/xaringan_after_body.html"
---


```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 80, scipen = 6, digits = 3)
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', tidy = FALSE, 
               fig.width = 9, fig.height = 3, fig.retina = 3,
               warning = FALSE, message = FALSE)
options(knitr.kable.NA = '')
source("support_linmodr.R")
```

# Линейные модели с дискретными предикторами (дисперсионный анализ)

## Вы сможете

- Объяснить, в чем опасность множественных сравнений, и как с ними можно бороться
- Рассказать, как в дисперсионном анализе моделируются значения зависимой переменной
- Интерпретировать и описать результаты, записанные в таблице дисперсионного анализа
- Перечислить и проверить условия применимости дисперсионного анализа
- Провести множественные попарные сравнения при помощи post hoc теста Тьюки, представить и описать их результаты
- Построить график результатов дисперсионного анализа

---

## Дисперсионный анализ (Analysis Of Variance, ANOVA)

__Дисперсионный анализ в широком смысле__ --- анализ изменений непрерывной зависимой переменной в связи с разными источниками изменчивости (предикторами). 

Мы использовали его для тестирования значимости предикторов в линейных моделях.

--

__Дисперсионный анализ в узком смысле__ --- это частный случай, когда в линейной модели используются только дискретные предикторы (факторы). 

Он используется для сравнения средних значений зависимой переменной в дискретных группах, заданных факторами..

---

## Пример: яйца кукушек

Различаются ли размеры яиц кукушек в гнездах разных птиц-хозяев?

Датасет `cuckoos` из пакета `DAAG`:

- `species`  --- вид птиц-хозяев (фактор)
- `length` --- длина яиц кукушек в гнездах хозяев (зависимая переменная)

.small[Данные: Latter, 1902; источник: Tippett, 1931]

---

## Открываем данные

```{r, data-eggs}
library(DAAG)
data("cuckoos")
# Положим данные в переменную с коротким названием, чтобы меньше печатать
eggs <- cuckoos
head(eggs, 3)
# Сократим названия переменных
colnames(eggs) <- c('len', 'br', 'sp', 'id')
```

---

## Изменим названия уровней фактора, чтобы было легче понять о каких птицах речь

```{r, tidy=FALSE}
levels(eggs$sp)
levels(eggs$sp) <- c("ЛесЗав", "ЛугКон", "БелТряс", 
                        "Малин", "ЛесКон", "Крапив")
```

---

## Исследуем данные

```{r}
# Пропущенных значений нет
colSums(is.na(eggs))

# Данные не сбалансированы (размеры групп разные)
table(eggs$sp)
```

---

## Задание 1

Дополните код, чтобы построить график зависимости размера яиц кукушек (`len`) от вида птиц-хозяев (`sp`), в гнездах которых были обнаружены яйца. На графике должны быть изображены средние значения и их 95% доверительные интервалы, а цвет должен соответствовать виду птиц-хозяев.

```{r eval=FALSE}
library()
theme_set( )
# График средних с 95% доверительными интервалами
ggplot(data = , aes()) + 
  stat_summary(geom = , fun.data = )
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
library(ggplot2)
theme_set(theme_bw(base_size = 14))
# График средних с 95% доверительными интервалами
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

---

## Решение 1

```{r gg-mean-conf-limit, echo=TRUE, purl=FALSE}
```

---

## "Некрасивый" порядок уровней на графике

На этом графике некрасивый порядок уровней: средние для разных уровней фактора `eggs$sp` расположены, как кажется, хаотично.

Порядок групп на графике определяется порядком уровней фактора.

```{r purl=FALSE}
# "старый" порядок уровней
levels(eggs$sp)
```

```{r gg-mean-conf-limit, echo=FALSE, purl=FALSE}
```

---

## Меняем порядок уровней

Давайте изменим порядок уровней в факторе `eggs$sp` так, чтобы он соответствовал возрастанию средних значений длины яиц `eggs$len`.

```{r}
# "старый" порядок уровней
levels(eggs$sp)
# переставляем уровни в порядке следования средних значений 
eggs$sp <- reorder(eggs$sp, eggs$len, FUN = mean)
# "новый" порядок уровней стал таким
levels(eggs$sp)
```

---

## График с новым порядком уровней

С новым порядком уровней нам легче визуально сравнивать друг с другом категории.

Поскольку, изменив порядок уровней, мы внесли изменения в исходные данные, придется полностью обновить график (т.к.`ggplot()` хранит данные внутри графика).

```{r gg-new-levels}
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal)
```

---

## Понравившийся график, если понадобится, можно в любой момент довести до ума, а остальные удалить

```{r gg-mean-conf-limit-coloured-labs, purl=FALSE}
ggplot(data = eggs, aes(x = sp, y = len, colour = sp)) + 
  stat_summary(geom = "pointrange", fun.data = mean_cl_normal) +
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") + 
  scale_colour_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек",
                       "Малиновка", "Белая\nтрясогузка",
                       "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
```

---

class: middle, center, inverse

# Множественные сравнения

---

## Множественные сравнения

Мы могли бы сравнить длину яиц в гнездах резных хозяев при помощи t-критерия. 

У нас всего 6 групп. Сколько возможно между ними попарных сравнений?

```{r gg-mean-conf-limit-coloured-labs, echo=FALSE, purl=FALSE}
```

--

Всего возможно 15 сравнений.

Если для каждого сравнения вероятность ошибки первого рода будет $\alpha_{per\ comparison} = 0.05$, то для группы из 15 сравнений --- ?

--

Если предположить, что сравнения независимы (это не так), то $\alpha_{family\ wise} = 1 - (1 - 0.05) ^ {15} = 0.54$. Мы рискуем найти различия там где их нет с 54% вероятностью!

--

Для зависимых сравнений вероятность будет немного меньше, но все равно значительно больше $0.05$

---

## Поправка Бонферрони --- очень жесткий способ коррекции.

Если нужно много сравнений, можно снизить $\alpha _{per\ comparison}$ до общепринятого уровня

$$\alpha _{per\ comparison} = \frac{\alpha _{family\ wise}}{n}$$

--

Например, если хотим зафиксировать $\alpha _{family\ wise} = 0.05$

С поправкой Бонферрони $\alpha _{per\ comparison} = 0.05 / 15 = 0.003$

Это очень жесткая поправка! Мы рискуем не найти достоверных различий, даже там, где они есть...

Но есть выход. Вместо множества попарных сравнений можно использовать один тест --- дисперсионный анализ (analysis of variation, ANOVA).

---

class: middle, center, inverse

# Линейные модели с дискретными предикторами

---

## Для кодирования дискретных факторов в R используются две параметризации

.pull-left[

__Параметризация индикаторных переменных__ (dummy coding, treatment parametrization, reference cell model) в R обозначается __contr.treatment__.

С ней вы уже знакомы. Используется по умолчанию в R.

]

.pull-right[

__Параметризация эффектов__ (effects coding, sum-to-zero  parameterization) в R обозначается __contr.sum__.

"Классическая" параметризация для дисперсионного анализа. Нужна, если хочется использовать т.наз. III тип сумм квадратов в многофакторном дисперсионном анализе со взаимодействием факторов.

]

---

class: middle, center, inverse

# Параметризация индикаторных переменных

---

## Переменные-индикаторы

sp | spЛугКон <br/> $x_1$ | spМалин <br/> $x_2$ | spБелТряс <br/> $x_3$ | spЛесКон <br/> $x_4$ | spЛесЗав <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ---- 
Крапив   | 0 | 0 | 0 | 0 | 0
ЛугКон   | 1 | 0 | 0 | 0 | 0
Малин    | 0 | 1 | 0 | 0 | 0
БелТряс  | 0 | 0 | 1 | 0 | 0
ЛесКон   | 0 | 0 | 0 | 1 | 0
ЛесЗав   | 0 | 0 | 0 | 0 | 1

Переменных-индикаторов всегда на одну меньше, чем число уровней фактора.

Уровень "`r levels(eggs$sp)[1]`" будет базовым: для его кодирования не нужна отдельная переменная.

---

## Уравнение модели в параметризации индикаторов

sp | spЛугКон <br/> $x_1$ | spМалин <br/> $x_2$ | spБелТряс <br/> $x_3$ | spЛесКон <br/> $x_4$ | spЛесЗав <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ---- 
Крапив   | 0 | 0 | 0 | 0 | 0
ЛугКон   | 1 | 0 | 0 | 0 | 0
Малин    | 0 | 1 | 0 | 0 | 0
БелТряс  | 0 | 0 | 1 | 0 | 0
ЛесКон   | 0 | 0 | 0 | 1 | 0
ЛесЗав   | 0 | 0 | 0 | 0 | 1

$$y _{i} = b_0 + b_1 x _{1i} + \ldots + b_5 x_{5i} + e_{i}$$

- $b_0$ --- это среднее значение отклика для базового уровня фактора.
- $b_1, ..., b_5$ --- это отклонения от базового уровня для средних с другими уровнями фактора.

---

## Коэффициенты модели в параметризации индикаторов

sp | spЛугКон <br/> $x_1$ | spМалин <br/> $x_2$ | spБелТряс <br/> $x_3$ | spЛесКон <br/> $x_4$ | spЛесЗав <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ---- 
Крапив   | 0 | 0 | 0 | 0 | 0
ЛугКон   | 1 | 0 | 0 | 0 | 0
Малин    | 0 | 1 | 0 | 0 | 0
БелТряс  | 0 | 0 | 1 | 0 | 0
ЛесКон   | 0 | 0 | 0 | 1 | 0
ЛесЗав   | 0 | 0 | 0 | 0 | 1

```{r}
mod_treatment <- lm(len ~ sp, data = eggs)
round(coef(mod_treatment), 2)
```

---


## Уравнение модели в параметризации индикаторов

sp | spЛугКон <br/> $x_1$ | spМалин <br/> $x_2$ | spБелТряс <br/> $x_3$ | spЛесКон <br/> $x_4$ | spЛесЗав <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ---- 
Крапив   | 0 | 0 | 0 | 0 | 0
ЛугКон   | 1 | 0 | 0 | 0 | 0
Малин    | 0 | 1 | 0 | 0 | 0
БелТряс  | 0 | 0 | 1 | 0 | 0
ЛесКон   | 0 | 0 | 0 | 1 | 0
ЛесЗав   | 0 | 0 | 0 | 0 | 1

```{r purl=FALSE}
round(coef(mod_treatment), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_treatment), 2)
```

$$\widehat{len}_i = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} + 1.44 sp_{\text{Малин}\ i} + 1.77 sp_{\text{БелТряс}\ i} + \\ + 1.96 sp_{\text{ЛесКон}\ i} + 1.99 sp_{\text{ЛесЗав}\ i}$$

---

## Уравнение модели в параметризации индикаторов

$$\widehat{len}_i = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} + 1.44 sp_{\text{Малин}\ i} + 1.77 sp_{\text{БелТряс}\ i} + \\ + 1.96 sp_{\text{ЛесКон}\ i} + 1.99 sp_{\text{ЛесЗав}\ i}$$
--

Первый коэффициент --- средний размер яиц кукушек в гнездах крапивников (на базовом уровне):

- $\widehat{len}_{\text{Крапив}} = `r cf[1]`$

--

Другие коэффициенты --- разница размеров яиц кукушек в гнездах других хозяев и в гнездах крапивников (отклонения от базового уровня).

--

Если их прибавить к базовому уровню, то получим предсказанные значения для других видов:

--

- $\widehat{len}_{\text{ЛугКон}\ i} = 21.12 + 1.17 sp_{\text{ЛугКон}\ i} = `r sum(cf[1:2])`$

--

- $\widehat{len}_{\text{Малин}\ i} = 21.12 + 1.44 sp_{\text{Малин}\ i} = `r sum(cf[c(1, 3)])`$

--

- $\widehat{len}_{\text{БелТряс}\ i} = 21.12 + 1.77 sp_{\text{БелТряс}\ i} = `r sum(cf[c(1, 4)])`$
- $\widehat{len}_{\text{ЛесКон}\ i} = 21.12 + 1.96 sp_{\text{ЛесКон}\ i}= `r sum(cf[c(1, 5)])`$
- $\widehat{len}_{\text{ЛесЗав}\ i} = 21.12 + 1.99 sp_{\text{ЛесЗав}\ i} = `r sum(cf[c(1, 6)])`$

---

class: middle, center, inverse

# Параметризация эффектов

---

## Переменные-эффекты

sp | sp1 <br/> $x_1$ | sp2 <br/> $x_2$ | sp3 <br/> $x_3$ | sp4 <br/> $x_4$ | sp5 <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ----
Крапив   |  1 |  0  |  0 |  0 |  0
ЛугКон   |  0 |  1  |  0 |  0 |  0
Малин    |  0 |  0  |  1 |  0 |  0
БелТряс  |  0 |  0  |  0 |  1 |  0
ЛесКон   |  0 |  0  |  0 |  0 |  1
ЛесЗав   | -1 | -1  | -1 | -1 | -1

Переменных-эффектов всегда на одну меньше, чем число уровней фактора.

Переменные закодированы при помощи -1, 0 и 1 (сумма кодов для возможных состояний одной переменной равна нулю).

Для последней группы все переменные-эффекты будут равны $-1$.

---

## Уравнение модели в параметризации эффектов


sp | sp1 <br/> $x_1$ | sp2 <br/> $x_2$ | sp3 <br/> $x_3$ | sp4 <br/> $x_4$ | sp5 <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ----
Крапив   |  1 |  0  |  0 |  0 |  0
ЛугКон   |  0 |  1  |  0 |  0 |  0
Малин    |  0 |  0  |  1 |  0 |  0
БелТряс  |  0 |  0  |  0 |  1 |  0
ЛесКон   |  0 |  0  |  0 |  0 |  1
ЛесЗав   | -1 | -1  | -1 | -1 | -1


$$y _{i} = b_0 + b_1 x _{1i} + \ldots + b_5 x_{5i} + e_{i}$$

- $b_0$ --- это общее среднее значение отклика.
- $b_1, ..., b_5$ --- это отклонения от общего среднего для средних с другими уровнями фактора, кроме последнего.
- для последнего уровня фактора отклонения от общего среднего --- это коэффициенты $b_1, ..., b_5$, взятые с противоположным знаком.

---

## Коэффициенты модели в параметризации эффектов

sp | sp1 <br/> $x_1$ | sp2 <br/> $x_2$ | sp3 <br/> $x_3$ | sp4 <br/> $x_4$ | sp5 <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ----
Крапив   |  1 |  0  |  0 |  0 |  0
ЛугКон   |  0 |  1  |  0 |  0 |  0
Малин    |  0 |  0  |  1 |  0 |  0
БелТряс  |  0 |  0  |  0 |  1 |  0
ЛесКон   |  0 |  0  |  0 |  0 |  1
ЛесЗав   | -1 | -1  | -1 | -1 | -1

```{r}
mod_sum <- lm(len ~ sp, data = eggs, contrasts = list(sp = contr.sum))
round(coef(mod_sum), 2)
```

Коэффициенты моделей в разных параметризациях будут разными, но предсказания будут совершенно одинаковыми.

---

## Уравнение линейной модели в параметризации эффектов

sp | sp1 <br/> $x_1$ | sp2 <br/> $x_2$ | sp3 <br/> $x_3$ | sp4 <br/> $x_4$ | sp5 <br/> $x_5$
---- | ---- | ---- | ---- | ---- | ----
Крапив   |  1 |  0  |  0 |  0 |  0
ЛугКон   |  0 |  1  |  0 |  0 |  0
Малин    |  0 |  0  |  1 |  0 |  0
БелТряс  |  0 |  0  |  0 |  1 |  0
ЛесКон   |  0 |  0  |  0 |  0 |  1
ЛесЗав   | -1 | -1  | -1 | -1 | -1

```{r purl=FALSE}
round(coef(mod_sum), 2)
```
```{r echo=FALSE}
cf <- round(coef(mod_sum), 2)
```

$$\widehat{len}_i = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + 0.38 sp_{4\ i} + 0.57 sp_{5\ i}$$

---

## Уравнение линейной модели в параметризации эффектов


$$\widehat{len}_i = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + 0.38 sp_{4\ i} + 0.57 sp_{5\ i}$$

--

Первый коэффициент --- средний размер яиц кукушек по всем данным:

- $\overline{len} = `r cf[1]`$

--



.small[Другие коэффициенты --- отличие размеров яиц в гнездах хозяев от общего среднего.
Для всех хозяев, кроме последнего, эти отличия будут взяты без изменения знака:]

--

.small[
- $\widehat{len}_{\text{Крапив}\ i} = 22.51 -1.39 sp_{1\ i} = `r sum(cf[1:2])`$
]

--

.small[
- $\widehat{len}_{\text{ЛугКон}\ i} = 22.51 -0.22 sp_{2\ i} = `r sum(cf[c(1, 3)])`$
]

--

.small[
- $\widehat{len}_{\text{Малин}\ i} = 22.51 + 0.05 sp_{3\ i} = `r sum(cf[c(1, 4)])`$
- $\widehat{len}_{\text{БелТряс}\ i} = 22.51 + 0.38 sp_{4\ i} = `r sum(cf[c(1, 5)])`$
- $\widehat{len}_{\text{ЛесКон}\ i} = 22.51 + 0.57 sp_{5\ i} = `r sum(cf[c(1, 6)])`$
]

--

.small[Для последнего уровня фактора отличия будут взяты с противоположным знаком, т.к. все переменные-эффекты для него будут принимать значение -1:]

.small[
- $\widehat{len}_{\text{ЛесЗав}\ i} = 22.51 -1.39 sp_{1\ i} -0.22 sp_{2\ i} + 0.05 sp_{3\ i} + \\+ 0.38 sp_{4\ i} + 0.57 sp_{5\ i} = `r cf[1] + sum(-cf[2:6])`$
]

---

class: middle, center, inverse

# t-тесты значимости коэффициентов

---

## t-тесты значимости коэффициентов не информативны в моделях с дискретными предикторами

- Для модели __в параметризации индикаторов__ t-тесты коэффициентов показывают значимость отличий средних в группах от среднего на базовом уровне.
- По значениям коэффициентов нельзя сказать влияет ли дискретный фактор целиком (исключение --- фактор с двумя градациями).

```{r}
coef(summary(mod_treatment))
```

---

## t-тесты значимости коэффициентов не информативны в моделях с дискретными предикторами

- Для модели __в параметризации эффектов__ t-тесты коэффициентов показывают значимость отличий средних в группах от общего среднего -- это сравнение редко имеет смысл.

```{r}
coef(summary(mod_sum))
```


---

class: middle, center, inverse

# Дисперсионный анализ

```{r echo=FALSE, purl=FALSE}
library(dplyr)
dat_smr <- eggs %>% group_by(sp) %>% summarise(mean = mean(len)) 
dat <- merge(eggs, dat_smr)
dat$sp <- as.numeric(dat$sp) + runif(nrow(dat), -0.15, 0.15)
d_lev <- levels(eggs$sp)
dat_smr$sp <- as.numeric(dat_smr$sp)

lims <- range(eggs$len) + 0.15 * c(-1, 1)
yannot <- lims[1] + 0.5
set.seed(83)
gmean <- mean(eggs$len, na.rm = TRUE)

# 35
id <- 9
Y <- dat$len[id]
Y_hat <-dat$mean[id]
X <- dat$sp[id]



pl <- ggplot(data = dat, aes(x = sp, y = len)) + theme(legend.position = 'none', axis.text.x = element_text(angle = 30, vjust = .8, hjust = .8)) + ylim(lims[1], lims[2]) + scale_x_continuous(breaks = 1:6, labels = d_lev)

# # Общая изменчивость (отклонения от общего среднего)
pl_tot <- pl + 
  geom_segment(aes(xend = sp, yend = gmean), colour = 'grey70', size = 0.75) +
  geom_hline(yintercept = gmean) + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[t] == sum((bar(y) - y[i]))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Общая изм-ть')
# pl_tot

pl_all <- pl + 
  geom_segment(aes(xend = sp, yend = gmean), colour = 'grey70') +
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_hline(yintercept = gmean) + 
  # annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70', size = 1.75) + 
  annotate('segment', x = X, y = Y, xend = X, yend = Y_hat, colour = '#009E73', size = 1.75) +
  annotate('segment', x = X, y = Y_hat, xend = X, yend = gmean, colour = '#E69F00', size = 1.75) +
  geom_point(size = 1) +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)
# pl_all
pl_no <- pl + 
  geom_hline(yintercept = gmean, linetype = 'dashed') + 
  geom_point(data = dat_smr, y = gmean, size = 19, shape = 95, colour = 'dodgerblue1') +
  annotate('segment', x = X, y = Y, xend = X, yend = gmean, colour = 'grey70') + 
  annotate('segment', x = X + 0.02, y = Y, xend = X + 0.02, yend = gmean, colour = '#009E73') +
  geom_point(size = 1) +
  annotate('text', label = 'Общее\nсреднее', 
           x = 0,  y = gmean, hjust = -0.1, size = 4)
# pl_no

# library(plyr)
# Межгрупповая изменчивость (связанная с фактором)
pl_x <- pl + 
  geom_hline(aes(yintercept = gmean)) + 
  geom_segment(data = dat_smr, aes(x = sp, y = mean, xend = sp, yend = gmean), colour = '#E69F00', size = 0.75) +
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[x] == sum((bar(y) - hat(y)[i]))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Факторная изм-ть')
# pl_x
# Внутригрупповая изменчивость (случайная)
pl_res <- pl + 
  geom_segment(data = dat, aes(xend = sp, yend = mean), colour = '#009E73', size = 0.75) +
  # geom_hline(yintercept = gmean, linetype = 'dashed') + 
  geom_point(data = dat_smr, aes(y = mean), size = 19, shape = 95, colour = 'dodgerblue1') + 
  geom_point(size = 1) +
  # annotate('text', label = 'SS[e] == sum(sum((y [i] - hat(y)[i])))^2', parse = TRUE, x = 6,  y = yannot, hjust = 1, size = 6) +
  ggtitle('Случайная изм-ть')  + theme(axis.title.y = element_blank())
# pl_res
```

---

## Общая изменчивость

```{r gg-tot, echo=FALSE, fig.height=3.5, purl=FALSE}
pl_tot +  annotate('text', label = 'Общее\nсреднее', 
           x = -0.5,  y = gmean, hjust = -0.1, size = 4)
```

Общая изменчивость SS~t~ --- это сумма квадратов отклонений наблюдаемых значений $y_i$ от общего среднего $\bar y$

---

## Факторная (межгрупповая) изменчивость


```{r gg-x, echo=FALSE, fig.height=3.5, purl=FALSE}
pl_x +  annotate('text', label = 'Общее\nсреднее', 
           x = -0.5,  y = gmean, hjust = -0.1, size = 4)
```

Отклонения внутригрупповых средних от общего среднего в генеральной совокупности --- это эффект фактора $\alpha_j = \mu_j - \mu$, где $j = 1, 2, ..., p$ --- это одна из $p$ групп. 

Мы оцениваем эффект фактора по реальным данным $\bar{y}_j-\bar{y}$

---

## Структура общей изменчивости

$$SS_t = SS_x + SS_e$$


```{r gg-ss, echo=FALSE, fig.width=12, fig.height=4}
library(cowplot)
plot_grid(
pl_tot + annotate('text', label = 'Общее\nсреднее', 
           x = -1,  y = gmean, hjust = -0.1, size = 4),
pl_x  + theme(axis.title.y = element_blank()),
pl_res,
nrow = 1, rel_widths = c(1.1, 1, 1))
```

Общая изменчивость | Факторная изменчивость | Остаточная изменчивость
---- |----|----
... | ... | ...
$SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$ | $SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$ | $SS_{e}= \sum\sum{(\bar{y}_{j}-y_{ij})^2}$
$df_{t} = n - 1$ | $df_{x} = p - 1$ |  $df_{e} = n - p$

---

## От изменчивостей к дисперсиям


$$SS_t = SS_x + SS_e \qquad MS_t \ne MS_x + MS_e$$


```{r gg-ss, echo=FALSE, fig.width=12, fig.height=4}
```

Общая дисперсия | Факторная дисперсия | Остаточная дисперсия
---- |----|----
$MS_{t} = \frac {SS_{t}}{df_{t}}$ | $MS_{x} = \frac {SS_{x}}{df_{x}}$ | $MS_{e} = \frac{SS_{e}}{df_{e}}$
$SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$ | $SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$ | $SS_{e}= \sum\sum{(\bar{y}_{j}-y_{ij})^2}$
$df_{t} = n - 1$ | $df_{x} = p - 1$ |  $df_{e} = n - p$

???

Они не зависят от числа наблюдений в выборке, в отличие от $SSx$ и $SS_e$
С их помощью можно проверить гипотезу о наличии связи между предиктором и откликом


---

## $MS_x$ и $MS_e$ <br/> помогают тестировать значимость фактора

Если дисперсии остатков в группах равны и фактор имеет фиксированное число градаций:

$E(MS_x) = \sigma^2 +  \sum n_i \frac{(\mu_i - \mu)^2}{p - 1} = \sigma^2 +  \sigma^2_x$

$E(MS_e) = \sigma^2$

--

Если зависимости нет, то $\mu_1 = \ldots = \mu_p$ --- средние равны во всех $p$ группах, и тогда $MS_x \sim MS_e$.

--

- $H_0: \mu_1 = \ldots = \mu_p$ --- средние во всех $p$ группах равны.
- $H_A: \exists\; i, j: \mu_i \ne \mu_j$ --- __хотя бы одно__ среднее отличается от общего среднего.

$$F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$
---

## Тестирование значимости фактора при помощи F-критерия

- $H_0: \mu_1 = \ldots = \mu_p$ --- средние во всех $p$ группах равны.
- $H_A: \exists\; i, j: \mu_i \ne \mu_j$ --- __хотя бы одно__ среднее отличается от общего среднего.

$$F_{df_x, df_e} = \frac{MS _{x}}{MS_{e}}$$

В однофакторном дисперсионном анализе $df_{x} = p - 1$ и $df_{e} = n - p$.

```{r f-distribution, echo=FALSE, purl=FALSE, fig.width=7}
library(car)
df_1 <- 5
df_2 <- 114
F_val <- Anova(mod_treatment)[1, 3]
F_crit <- qf(p = 0.05, df1 = df_1, df2 = df_2, lower.tail = F)

dfr <- data.frame(f = seq(-0.3, 11, 0.01))
ggplot(dfr, aes(x = f)) + 
  stat_function(fun = df, args = list(df1 = df_1, df2 = 114), size = 1.3) + 
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = qf(p = 0.95, df1 = df_1, df2 = 114), color = "red", linetype = "dashed") + 
  annotate("text", label = "F при α = 0.05", x = qf(p = 0.95, df1 = df_1, df2 = 114), y = 1, hjust = 1.1) +
  geom_vline(xintercept = F_val, linetype = "dashed") +
  annotate("text", label = "F", x = F_val, y = 1, hjust = -1) +
  labs(title = paste0("F-распределение, df1 = ", df_1, ", df2 = ", df_2), x = "F", y = "Плотность вероятности") + ylim(0, 1.1)
```


---

## Результаты дисперсионного анализа часто представляют <br/> в виде таблицы

Источник изменчивости|SS|df|MS|F
----- | ----- | ----- | ----- | ----- 
Название фактора | $SS_{x}=\sum{n_j(\bar{y}_j-\bar{y})^2}$ | $df _x = p - 1$ | $MS _x = \frac{SS _x}{df _x}$ | $F _{df _x df _e} = \frac{MS _x}{MS _e}$
Случайная | $SS_{e}= \sum\sum{(\bar{y}_j-y_{ij})^2}$ | $df _e = n - p$ | $MS _e = \frac{SS _e}{df _e}$ |
Общая | $SS_{t}= \sum\sum{(\bar{y}-y_{ij})^2}$ | $df _t = n - 1$ |  


Минимальное описание результатов в тексте должно содержать $F _{df _x, df _e}$ и $p$.

---

## Делаем дисперсионный анализ в R

В R есть много функций для дисперсионного анализа. Мы рекомендуем `Anova()` (__с большой буквы__) из пакета `car`. 

Зачем? Эта функция умеет тестировать влияние факторов в определенном порядке. Когда факторов будет больше одного, это станет важно для результатов.

```{r, message=FALSE}
library(car)
eggs_anova <- Anova(mod_treatment)
eggs_anova
```

---

## Результаты дисперсионного анализа

- Можно описать в тексте:

```{r, echo=FALSE}
result <- eggs_anova
dfs <- paste0(result$Df, collapse= ",")
fval <- round(result$'F value'[1], 2)
sign <- ifelse(result$'Pr(>F)'[1] <= 0.01, "$p < 0.01$", ifelse(result$'Pr(>F)'[1] <= 0.05, "$p < 0.05$", ""))
```

Длина яиц кукушек в гнездах разных птиц-хозяев значимо различается <br/> ( $F _{ `r dfs`} = `r fval`$, `r sign`).

- Можно представить в виде таблицы:

Длина яиц кукушек значимо различалась в гнездах разных птиц-хозяев (Табл. 1).

```{r echo=FALSE, results='asis', purl=FALSE}
library(kableExtra)
library(tibble)
smr <- fix_Anova(eggs_anova,
                 rown = c("Хозяин", "Остаточная"), 
                 coln = c("SS", "df", "F", "P"))

smr %>% 
  rownames_to_column(var = "Источник изменчивости") %>% 
  kable(caption = "Табл. 1. Результаты дисперсионного анализа длины яиц кукушек в гнездах разных птиц-хозяев. SS --- суммы квадратов отклонений, df --- число степеней свободы, F --- значение F-критерия, P --- уровень значимости.", label = "tab:oneanova") %>%
  kable_styling(full_width = TRUE)
```

---

class: middle, center, inverse

# Условия примененимости дисперсионного анализа

---

## Результатам тестов можно верить, если выполняются условия применимости

Условия применимости дисперсионного анализа:

- Случайность и независимость  наблюдений внутри групп
- Нормальное распределение остатков
- Гомогенность дисперсий остатков
- Отсутствие коллинеарности факторов (независимость групп)

--

### Другие ограничения:

- Лучше работает, если размеры групп примерно одинаковы (т.наз. сбалансированный дисперсионный комплекс)
- Устойчив к отклонениям от нормального распределения (при равных объемах групп или при больших выборках)

---

## Проверяем выполнение условий применимости

```{r}
# Данные для графиков остатков
mod_diag <- fortify(mod_treatment)
```

--

### 1) График расстояния Кука

```{r gg-cooksd}
ggplot(mod_diag, aes(x = 1:nrow(mod_diag), y = .cooksd)) +
  geom_bar(stat = "identity")
```

--

- Выбросов нет

---

## 2) График остатков от предсказанных значений

```{r gg-resid-fitted, eval=FALSE, purl=FALSE}
ggplot(mod_diag, aes(x = .fitted, y = .stdresid)) + geom_jitter()
```

--

Но у нас один единственный дискретный предиктор, поэтому удобнее сразу боксплот остатков в зависимости от дискретного предиктора

### 3) Графики остатков от предикторов в модели и не в модели

```{r gg-resid-in-model}
ggplot(mod_diag, aes(x = sp, y = .stdresid)) + geom_boxplot()
```
--

- Дисперсии почти одинаковые. Может быть, в одной из групп чуть больше

---

## 4) Квантильный график остатков

```{r qq-plot, fig.height=5}
library(car)
qqPlot(mod_treatment, id = FALSE)
```

--

- Распределение остатков немного отличается от нормального

---

class: middle, center, inverse

# График предсказаний модели

---

## Данные для графика при помощи `predict()`

```{r}
MyData <- data.frame(sp = factor(levels(eggs$sp), levels = levels(eggs$sp)))

MyData <- data.frame(
  MyData, 
  predict(mod_treatment, newdata = MyData, interval = "confidence"))

MyData
```

---

## Задание 2

Создайте MyData вручную:

- предсказанные значения 
- стандартные ошибки
- верхнюю и нижнюю границы доверительных интервалов

```{r eval=FALSE}
MyData <- data.frame(sp = factor(levels(eggs$sp), 
                                 levels = levels(eggs$sp)))

X <- model.matrix()
betas <- 
MyData$fit <-  %*% 
MyData$se <- sqrt(diag(X %*% vcov(mod_treatment) %*% t(X)))
t_crit <- qt(p = , df = nrow() - length(coef()))
MyData$lwr <- MyData$ -  * MyData$
MyData$upr <- MyData$ +  * MyData$

```

---

## Решение 2

```{r purl=FALSE}
MyData <- data.frame(sp = factor(levels(eggs$sp), 
                                 levels = levels(eggs$sp)))
X <- model.matrix(~sp, data = MyData)
betas <- coef(mod_treatment)
MyData$fit <- X %*% betas
MyData$se <- sqrt(diag(X %*% vcov(mod_treatment) %*% t(X)))
t_crit <- qt(p = 0.975, df = nrow(eggs) - length(coef(mod_treatment)))
MyData$lwr <- MyData$fit - t_crit * MyData$se
MyData$upr <- MyData$fit + t_crit * MyData$se
MyData
```

---

## Задание 3

Дополните код, чтобы получить столбчатый график с предсказаниями линейной модели.
Заливкой покажите вид птиц-хозяев. Подпишите оси. Спрячьте легенду.

```{r eval=FALSE}
gg_bars <- ggplot(data = , aes(x = , y = )) +
  geom_bar(stat = "", aes(), width = 0.5) +
  geom_errorbar(aes(ymin = , ymax = ), width = 0.1) +
  labs( = "Вид хозяев",  = "Длина яиц кукушек, мм") +
  scale_fill_brewer(name = "Вид \nхозяев", palette = "Dark2") +
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек",
                       "Малиновка", "Белая\nтрясогузка",
                       "Лесной\nконек","Лесная\nзавирушка")) +
  theme(  = "none")
gg_bars
```

```{r bar-plot, echo=FALSE, eval=TRUE, purl=FALSE}
gg_bars <- ggplot(data = MyData, aes(x = sp, y = fit)) + 
  geom_bar(stat = "identity", aes(fill = sp), width = 0.5) +
  geom_errorbar(aes(ymin = lwr, ymax = upr), width = 0.1) + 
  labs(x = "Вид хозяев", y = "Длина яиц кукушек, мм") +
  scale_fill_brewer(name = "Вид \nхозяев", palette = "Dark2") + 
  scale_x_discrete(labels = c("Крапивник", "Луговой\nконек",
                        "Малиновка", "Белая\nтрясогузка",
                        "Лесной\nконек", "Лесная\nзавирушка")) + 
  theme(legend.position = "none")
gg_bars
```

---

## Решение 3

### Столбчатый график

```{r bar-plot, echo=TRUE, eval=TRUE, purl=FALSE}
```

--

Но какие именно из этих средних значений значимо различаются?

---

class: middle, center, inverse

# Пост хок тесты

---

## Как понять, какие именно группы различаются

Дисперсионный анализ говорит нам только, есть ли влияние фактора, но не говорит, какие именно группы различаются.

Коэффициенты линейной модели в `summary(mod_treatment)` содержат лишь часть ответа --- сравнение средних значених всех групп со средним на базовом уровне.

Если нас интересуют другие возможные попарные сравнения, нужно сделать пост хок тест.

---

## Есть два способа понять, какие именно группы различаются

--

.pull-left[

.center[__Линейные контрасты__ (linear contrasts)]

- Гипотезы о межгрупповых различиях тестируются при помощи комбинаций из коэффициентов линейной модели.
- Набор гипотез (и сравнений) должен быть определен заранее.
- Делать можно вне зависимости от результатов дисперсионного анализа.

Этот способ за рамками курса.
]

--

.pull-right[
.center[__Post hoc__ тесты]

- Сравниваются все возможные группы.
- Нет четких заранее сформулированных гипотез.
- Делать можно, только если влияние соответствующего фактора оказалось значимым.

Этот способ мы обсудим.
]

---

## Разновидности пост хок тестов

Тесты без поправки на число сравнений:

- Наименьшая значимая разница Фишера (Fisher's Least Significant Difference)

--

Тесты с поправкой для уровня значимости $\alpha$:

- Поправка Бонферрони (Bonferroni correction)
- Поправка Сидака (Sidak's correction)

--

Тесты, основанные на распределении стьюдентизированного размаха:

- Тест Тьюки (Tukey's Honest Significant Difference, HSD)
- Тест Стьюдента-Ньюмена-Кьюлса (Student-Newman-Kewls test, SNK)
- Тест Даннета (Dunnet's test) --- используется для сравнения с контрольной группой.

--

Тесты, основанные на F-тестах:

- Критерий Дункана (Dunkan's test)
- Тест Шеффе (Scheffe's test)

---

## Наименьшая значимая разница Фишера <br/> Fisher's Least Significant Difference

Используется t-критерий с $df = df_e = n - p$:

<br/>

$$t = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$
--

- Подразумевается равенство дисперсий в сравниваемых группах

- Не вносится поправка для уровня значимости, учитывающая множественность сравнений. (Считается, что тест "защищен" от ошибок I рода, т.к. выполняется после того, как в ANOVA была отвергнута гипотеза о равенстве всех внутригрупповых средних).

--

__Осторожно!__ Этот тест слишком мягок, высока вероятность появления ошибок II рода (т.е. тест находит различия там, где их нет).

---

## После ANOVA часто приходится сравнивать несколько групп

Фактор в дисперсионном анализе может задавать больше двух групп. (Например, фактор вид птицы-хозяина в нашем примере).

--

На самом деле __t-распределение__ не годится для случая, когда приходится сравнивать больше, чем две группы одновременно.

Вспомните, __t-распределение__ --- это распределение стандартизованной разницы <br/> средних значений __из двух выборок__, взятых из одной генеральной совокупности.

--

<br/>

Нужен способ описать __более сложное распределение --- для любого числа выборок__.

---

## Три выборки

Представьте, что мы берем из одной и той же генеральной совокупности три выборки.

Средние значения $\bar y_1$, $\bar y_2$ и $\bar y_3$ в каждой из этих выборок скорее всего окажутся разными и не будут похожи на генеральное среднее $\mu$.

Как оценить, какой может быть эта разница? Нужно построить распределение. Но какое?

--

<br/>

1. Возьмем $m$ выборок из одной генеральной совокупности

--

2. Отсортируем выборочные средние: $\bar y_{1} \ge \bar y_2 \ge \ldots \ge \bar y_{m}$

Это можно записать как $\bar y_{max} \ge \bar y_2 \ge \ldots \ge \bar y_{min}$

--

3. Вычислим разницу максимального и минимального средних $\bar y_{max} - \bar y_{min}$  

--

Если повторить 1--3 много раз, то получится распределение, которое показывает, чему может быть равна разница средних значений в выборках из одной генеральной совокупности. 

Такое распределение можно построить для любого числа выборок $m$.

---

## Распределение стьюдентизированного размаха <br/> Studentized range distribution

Это распределение стандартизованной разницы минимального и максимального средних __для любого числа выборок__ из одной генеральной совокупности (форма зависит от $df$ и от числа выборок $m$).


```{r gg-tukey-distr, echo=FALSE, purl=FALSE}
# https://en.wikipedia.org/wiki/Studentized_range_distribution
# https://commons.wikimedia.org/wiki/File:StudentizedRangePDF.svg
dtukey <- function(q, nmeans, df) {
    delta = 0.001
    return (ptukey(q+delta, nmeans, df) - ptukey(q, nmeans, df)) / delta
}

ggplot(data = data.frame(x = 0:7), aes(x = x)) +
  stat_function(fun = dtukey, args = list(nmeans = 2, df = 10), 
                aes(colour = 'm = 2, df = 10'))+
    stat_function(fun = dtukey, args = list(nmeans = 2, df = 100), 
                  aes(colour = 'm = 2, df = 100'))+
  stat_function(fun = dtukey, args = list(nmeans = 3, df = 10), 
                aes(colour = 'm = 3, df = 10'))+
    stat_function(fun = dtukey, args = list(nmeans = 3, df = 100), 
                aes(colour = 'm = 3, df = 100'))+
  stat_function(fun = dtukey, args = list(nmeans = 5, df = 10), 
                aes(colour = 'm = 5, df = 10'))+
  stat_function(fun = dtukey, args = list(nmeans = 5, df = 100), 
                aes(colour = 'm = 5, df = 100')) +
  scale_colour_brewer('', palette = 'Paired') +
  labs(x = 'q', y = 'Плотность вероятности') +
  theme(legend.position = c(0.8, 0.6), legend.background = element_blank())
```


Формула для случая равных дисперсий и разных объемов групп:

$$q = \frac{\bar{y}_{max} - \bar{y}_{min}}{\sqrt{s^2\frac{1}{2} \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$
---

## Cтьюдентизированный t-критерий консервативнее обычного

.pull-left[

.center[Обычный t-критерий]

$$t = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$
]
.pull-right[
.center[Стьюдентизированный t-критерий]

$$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \;\frac{1}{2}  \; \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

<!-- $$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e \;\tikzmarkin<2>{factor} \frac{1}{2} \tikzmarkend{factor} \; \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$-->
При этом $\bar{y}_i > \bar{y}_j$, т.е. вычитается из большего меньшее среднее.

]

--

<br/>

.center[Значение $q$ будет в 1.414 раз больше, чем $t$.

$$q = \frac{t}{\sqrt{\; \frac{1}{2}}} = \sqrt{2} \cdot t = 1.414 \cdot t$$

]

---

## Тест Тьюки (Tukey's Honest Significant Difference)

Используется стьюдентизированный t-критерий  
с $df = df_e = n - p$ и $m = p$ (общее число групп):

$$q = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MS_e\frac{1}{2} \large(\frac{1}{n_i} + \frac{1}{n_j}\large)}}$$

Требуется равенство дисперсий.

---

## Пост хок тесты различаются по степени консервативности


Если посмотреть на критические значения t при сравнении средних при $\alpha = 0.05$ ($m = 4$ группы по 6 наблюдений, $df_e = 20$), становится понятно, что тест Тьюки --- разумный компромисс среди пост хок тестов.


Тест | Критическое значение
---- | -----
Шеффе<sup>a</sup> | 3.05
Бонферрони (4 группы) |  2.93
Тьюки (HSD)<sup>b</sup> |  2.80
Бонферрони (3 группы) |  2.63
Даннет<sup>b<sup/> |  2.54
Дункан<sup>a, b</sup> |  2.22
Фишер (LSD) |  2.09

<sup>a</sup> --- Значение $t$ соответствующее $F$.

<sup>b</sup> --- Для сопоставимости внесена поправка $\sqrt{2}$. 

---

## Пост хок тест Тьюки в R

- `glht()` --- "general linear hypotheses testing"
- `linfct` --- аргумент, задающий гипотезу для тестирования

- `mcp()` --- функция, чтобы задавать множественные сравнения (обычные пост хоки)
- `sp` = "Tukey" --- тест Тьюки по фактору `sp`

```{r, message=FALSE}
library(multcomp)
eggs_posthoc <- glht(mod_treatment, linfct = mcp(sp = "Tukey"))
```

---

## Результаты попарных сравнений (тест Тьюки)

Таблица результатов пост хок теста практически нечитабельна. 
\small

```{r}
summary(eggs_posthoc)
```

---

## Результаты пост хок теста

Результаты пост хок теста можно привести в виде текста...

- Размер яиц кукушек в гнездах крапивника значимо меньше, чем в гнездах лугового конька (тест Тьюки, $p < 0.01$). Размер яиц кукушек в гнездах лесной завирушки, белой трясогузки, малиновки и лесного конька не различается, но яйца кукушек в гнездах этих хозяев крупнее, чем в гнездах у лугового конька или крапивника (тест Тьюки, от $p < 0.01$ до $0.05$).

...или построить график


---

## Можно привести результаты пост хок теста на столбчатом графике

Значимо различающиеся группы обозначим разными буквами

```{r gg-coded-bars}
gg_bars_coded <- gg_bars + 
  geom_text(aes(y = 1.6,  label = c("A", "B", "BC", "BC", "C", "C")), 
            colour = "white", size = 7)
gg_bars_coded
```

---

## Take home messages

- Дисперсионный анализ --- линейная модель с дискретными предикторами, существует в нескольких параметризациях, которые отличаются трактовками коэффициентов
- При помощи дисперсионного анализа можно проверить гипотезу о равенстве средних значений в группах

--

- Условия применимости дисперсионного анализа
    - Случайность и независимость групп и наблюдений внутри групп
    - Нормальное распределение в группах
    - Гомогенность дисперсий в группах

--

- При множественных попарных сравнениях увеличивается вероятность ошибки первого рода, поэтому нужно вносить поправку для уровня значимости
- Post hoc тесты --- это попарные сравнения после дисперсионного анализа, которые позволяют сказать, какие именно средние различаются

---

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 173--207
- Logan, 2010, pp. 254--282
- [Open Intro to Statistics](http://www.openintro.org/stat/), pp.236--246 
- Sokal, Rohlf, 1995, pp. 179--260
- Zar, 2010, pp. 189-207
